<!DOCTYPE html>
<!-- saved from url=(0135)https://medium.com/the-ai-forum/implementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563 -->
<html lang="en" data-rh="lang" class="mdl-js"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI | by Plaban Nayak | The AI Forum | Mar, 2024 | Medium</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-03-03T12:40:53.244Z"><meta data-rh="true" name="title" content="Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI | by Plaban Nayak | The AI Forum | Mar, 2024 | Medium"><meta data-rh="true" property="og:title" content="Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI"><meta data-rh="true" property="al:android:url" content="medium://p/30d63e222563"><meta data-rh="true" property="al:ios:url" content="medium://p/30d63e222563"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="In contrast to alternative methods of integrating domain-specific data into LLM customization, RAG is simple and cost-effective. Organizations can deploy RAG without needing to customize the model…"><meta data-rh="true" property="og:description" content="What happens in Native RAG ?"><meta data-rh="true" property="og:url" content="https://medium.com/the-ai-forum/implementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563"><meta data-rh="true" property="al:web:url" content="https://medium.com/the-ai-forum/implementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563"><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:721/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg"><meta data-rh="true" property="article:author" content="https://nayakpplaban.medium.com"><meta data-rh="true" name="author" content="Plaban Nayak"><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" property="twitter:title" content="Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI"><meta data-rh="true" name="twitter:site" content="@Medium"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/30d63e222563"><meta data-rh="true" property="twitter:description" content="What happens in Native RAG ?"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:721/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="26 min read"><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/unbound.css"><link data-rh="true" rel="author" href="https://nayakpplaban.medium.com/"><link data-rh="true" rel="canonical" href="https://medium.com/the-ai-forum/implementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/30d63e222563"><script async="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/branch-latest.min.js.tải xuống"></script><script async="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/shim.js.tải xuống"></script><style type="text/css" data-fela-rehydration="530" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="530" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-webkit-keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-webkit-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{fill:rgba(0, 0, 0, 1)}.av{height:22px}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.dv{margin-left:8px}.dw{color:#6B6B6B}.dx{font-size:13px}.dy{height:100%}.dz{height:25px}.ea{fill:rgba(41, 41, 41, 1)}.ed{margin-right:32px}.ee{position:relative}.ef{fill:#6B6B6B}.ei{background:transparent}.ej svg{margin-left:4px}.ek svg{fill:#6B6B6B}.em{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.eo{position:absolute}.eq{box-sizing:border-box}.ew{margin:0 24px}.fa{background:rgba(255, 255, 255, 1)}.fb{border:1px solid #F2F2F2}.fc{box-shadow:0 1px 4px #F2F2F2}.fd{max-height:100vh}.fe{overflow-y:auto}.ff{left:0}.fg{top:calc(100vh + 100px)}.fh{bottom:calc(100vh + 100px)}.fi{width:10px}.fj{pointer-events:none}.fk{word-break:break-word}.fl{word-wrap:break-word}.fm:after{display:block}.fn:after{content:""}.fo:after{clear:both}.fp{line-height:1.23}.fq{letter-spacing:0}.fr{font-style:normal}.fs{font-weight:700}.gs{@media all and (max-width: 551.98px):8px}.gt{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.gu{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.gv{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.gw{@media all and (min-width: 1080px):16px}.hc{align-items:baseline}.hd{width:48px}.he{height:48px}.hf{border:2px solid rgba(255, 255, 255, 1)}.hg{z-index:0}.hh{box-shadow:none}.hi{border:1px solid rgba(0, 0, 0, 0.05)}.hj{margin-left:-12px}.hk{width:28px}.hl{height:28px}.hm{z-index:1}.hn{width:24px}.ho{margin-bottom:2px}.hp{flex-wrap:nowrap}.hq{font-size:16px}.hr{line-height:24px}.ht{margin:0 8px}.hu{display:inline}.hv{color:rgba(26, 137, 23, 1)}.hw{fill:rgba(26, 137, 23, 1)}.hx:disabled{opacity:0.3}.ia{flex:0 0 auto}.id{flex-wrap:wrap}.ig{white-space:pre-wrap}.ih{margin-right:4px}.ii{overflow:hidden}.ij{max-height:20px}.ik{text-overflow:ellipsis}.il{display:-webkit-box}.im{-webkit-line-clamp:1}.in{-webkit-box-orient:vertical}.io{word-break:break-all}.iq{padding-left:8px}.ir{padding-right:8px}.js> *{flex-shrink:0}.jt{overflow-x:scroll}.ju::-webkit-scrollbar{display:none}.jv{scrollbar-width:none}.jw{-ms-overflow-style:none}.jx{width:74px}.jy{flex-direction:row}.jz{z-index:2}.kc{-webkit-user-select:none}.kd{border:0}.ke{cursor:progress}.kf{fill:rgba(117, 117, 117, 1)}.ki{opacity:0.25}.kj{outline:0}.kk{user-select:none}.kl> svg{pointer-events:none}.ku{margin-left:4px}.kv{margin-top:0px}.kw{opacity:1}.kx{padding:4px 0}.la{width:16px}.lb{padding:8px 2px}.le svg path{fill:#6B6B6B}.lf path{fill:#242424}.lg{display:inline-flex}.lm{max-width:100%}.ln svg{color:#6B6B6B}.me{margin-left:auto}.mf{margin-right:auto}.mg{max-width:721px}.mm{clear:both}.mo{cursor:zoom-in}.mp{z-index:auto}.mr{height:auto}.ms{margin-top:10px}.mt{text-align:center}.mu{max-width:728px}.mx{line-height:1.12}.my{letter-spacing:-0.022em}.mz{font-weight:600}.nu{margin-bottom:-0.28em}.nv{line-height:1.58}.nw{letter-spacing:-0.004em}.nx{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.os{margin-bottom:-0.46em}.oy{list-style-type:decimal}.oz{margin-left:30px}.pa{padding-left:0px}.pg{font-style:italic}.ph{list-style-type:disc}.pi{text-decoration:underline}.po{overflow-x:auto}.pp{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.pq{padding:32px}.pr{border:1px solid #E5E5E5}.ps{line-height:1.4}.pt{margin-top:-0.2em}.pu{margin-bottom:-0.2em}.pv{white-space:pre}.pw{min-width:fit-content}.px{max-width:654px}.py{margin-top:16px}.qe{box-shadow:inset 0 0 0 1px #F2F2F2}.qf{padding:0px}.qg{padding:16px 20px}.qh{flex:1 1 auto}.qj{max-height:40px}.qk{-webkit-line-clamp:2}.ql{margin-top:8px}.qm{margin-top:12px}.qn{width:160px}.qo{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*OyIFAlFSDMKxJweG)}.qp{background-origin:border-box}.qq{background-size:cover}.qr{height:167px}.qs{background-position:50% 50%}.qt{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*R1ylI_wPNbMDWW6O)}.qu{margin-bottom:26px}.qv{margin-top:6px}.qw{margin-right:8px}.qx{padding:8px 16px}.qy{border-radius:100px}.qz{transition:background 300ms ease}.rb{white-space:nowrap}.rc{border-top:none}.ri{height:52px}.rj{max-height:52px}.rk{box-sizing:content-box}.rl{position:static}.rn{max-width:155px}.rt{margin-right:20px}.rz{align-items:flex-end}.sa{width:76px}.sb{height:76px}.sc{border:2px solid #F9F9F9}.sd{height:72px}.se{width:72px}.sf{margin-left:-16px}.sg{width:36px}.sh{height:36px}.si{color:#F2F2F2}.sj{fill:#F2F2F2}.sk{background:#F2F2F2}.sl{border-color:#F2F2F2}.sr:disabled{cursor:inherit !important}.ss:disabled{opacity:0.1}.st:disabled:hover{background:rgba(25, 25, 25, 1)}.su:disabled:hover{border-color:rgba(25, 25, 25, 1)}.sv{border-radius:99em}.sw{width:auto}.sx{border-width:1px}.sy{border-style:solid}.sz{text-decoration:none}.ta{stroke:#F2F2F2}.tb{font-weight:500}.tc{font-size:24px}.td{line-height:30px}.te{letter-spacing:-0.016em}.tf{height:0px}.tg{border-bottom:solid 1px #E5E5E5}.th{margin-top:72px}.ti{padding:24px 0}.tj{margin-bottom:0px}.tk{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.eg:hover{color:#242424}.eh:hover{fill:#242424}.el:hover svg{fill:#242424}.ep:hover{background-color:rgba(0, 0, 0, 0.1)}.hs:hover{text-decoration:underline}.hy:hover:not(:disabled){color:rgba(15, 115, 12, 1)}.hz:hover:not(:disabled){fill:rgba(15, 115, 12, 1)}.kh:hover{fill:rgba(117, 117, 117, 1)}.ky:hover{fill:#000000}.kz:hover p{color:#000000}.lc:hover:not(:disabled) svg path{fill:#000000}.lo:hover svg{color:#000000}.ra:hover{background-color:#F2F2F2}.sm:hover{background:#F2F2F2}.sn:hover{border-color:#F2F2F2}.so:hover{cursor:wait}.sp:hover{color:#F2F2F2}.sq:hover{fill:#F2F2F2}.bc:focus-within path{fill:#242424}.kg:focus{fill:rgba(117, 117, 117, 1)}.ld:focus svg path{fill:#000000}.lp:focus svg{color:#000000}.mq:focus{transform:scale(1.01)}.km:active{border-style:none}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ec{display:flex}.ev{margin-bottom:68px}.ez{max-width:680px}.gn{font-size:42px}.go{margin-top:1.19em}.gp{margin-bottom:32px}.gq{line-height:52px}.gr{letter-spacing:-0.011em}.hb{align-items:center}.je{border-top:solid 1px #F2F2F2}.jf{border-bottom:solid 1px #F2F2F2}.jg{margin:32px 0 0}.jh{padding:3px 8px}.jq> *{margin-right:24px}.jr> :last-child{margin-right:0}.kt{margin-top:0px}.ll{margin:0}.ml{margin-top:40px}.nq{font-size:24px}.nr{margin-top:1.95em}.ns{line-height:30px}.nt{letter-spacing:-0.016em}.oo{font-size:20px}.op{margin-top:0.94em}.oq{line-height:32px}.or{letter-spacing:-0.003em}.ox{margin-top:2.14em}.pf{margin-top:1.14em}.pn{margin-top:56px}.qd{margin-top:32px}.rh{margin-bottom:88px}.rs{display:inline-block}.ry{padding-top:72px}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ks{margin-top:0px}.mv{margin-left:auto}.mw{text-align:center}.rr{display:inline-block}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.kr{margin-top:0px}.rq{display:inline-block}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.kp{margin-top:0px}.kq{margin-right:0px}.qi{padding:10px 12px 10px}.rp{display:inline-block}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.ds{justify-content:center}.er{margin-bottom:4px}.ft{font-size:32px}.fu{margin-top:1.01em}.fv{margin-bottom:24px}.fw{line-height:38px}.fx{letter-spacing:-0.014em}.gx{align-items:flex-start}.ib{flex-direction:column}.ie{margin-bottom:2px}.is{margin:24px -24px 0}.it{padding:0}.ji> *{margin-right:8px}.jj> :last-child{margin-right:24px}.ka{margin-left:0px}.kn{margin-top:0px}.ko{margin-right:0px}.lh{margin:0}.lq{border:1px solid #F2F2F2}.lr{border-radius:99em}.ls{padding:0px 16px 0px 12px}.lt{height:38px}.lu{align-items:center}.lw svg{margin-right:8px}.mh{margin-top:32px}.na{font-size:20px}.nb{margin-top:1.2em}.nc{line-height:24px}.nd{letter-spacing:0}.ny{font-size:18px}.nz{margin-top:0.67em}.oa{line-height:28px}.ob{letter-spacing:-0.003em}.ot{margin-top:1.56em}.pb{margin-top:1.34em}.pj{margin-top:40px}.pz{margin-top:24px}.rd{margin-bottom:80px}.ro{display:inline-block}.ru{padding-top:48px}.lv:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.eb{display:flex}.eu{margin-bottom:68px}.ey{max-width:680px}.gi{font-size:42px}.gj{margin-top:1.19em}.gk{margin-bottom:32px}.gl{line-height:52px}.gm{letter-spacing:-0.011em}.ha{align-items:center}.ja{border-top:solid 1px #F2F2F2}.jb{border-bottom:solid 1px #F2F2F2}.jc{margin:32px 0 0}.jd{padding:3px 8px}.jo> *{margin-right:24px}.jp> :last-child{margin-right:0}.lk{margin:0}.mk{margin-top:40px}.nm{font-size:24px}.nn{margin-top:1.95em}.no{line-height:30px}.np{letter-spacing:-0.016em}.ok{font-size:20px}.ol{margin-top:0.94em}.om{line-height:32px}.on{letter-spacing:-0.003em}.ow{margin-top:2.14em}.pe{margin-top:1.14em}.pm{margin-top:56px}.qc{margin-top:32px}.rg{margin-bottom:88px}.rx{padding-top:72px}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.du{justify-content:center}.et{margin-bottom:68px}.ex{max-width:680px}.gd{font-size:42px}.ge{margin-top:1.19em}.gf{margin-bottom:32px}.gg{line-height:52px}.gh{letter-spacing:-0.011em}.gz{align-items:center}.iw{border-top:solid 1px #F2F2F2}.ix{border-bottom:solid 1px #F2F2F2}.iy{margin:32px 0 0}.iz{padding:3px 8px}.jm> *{margin-right:24px}.jn> :last-child{margin-right:0}.lj{margin:0}.mj{margin-top:40px}.ni{font-size:24px}.nj{margin-top:1.95em}.nk{line-height:30px}.nl{letter-spacing:-0.016em}.og{font-size:20px}.oh{margin-top:0.94em}.oi{line-height:32px}.oj{letter-spacing:-0.003em}.ov{margin-top:2.14em}.pd{margin-top:1.14em}.pl{margin-top:56px}.qb{margin-top:32px}.rf{margin-bottom:88px}.rw{padding-top:72px}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dt{justify-content:center}.es{margin-bottom:4px}.fy{font-size:32px}.fz{margin-top:1.01em}.ga{margin-bottom:24px}.gb{line-height:38px}.gc{letter-spacing:-0.014em}.gy{align-items:flex-start}.ic{flex-direction:column}.if{margin-bottom:2px}.iu{margin:24px 0 0}.iv{padding:0}.jk> *{margin-right:8px}.jl> :last-child{margin-right:8px}.kb{margin-left:0px}.li{margin:0}.lx{border:1px solid #F2F2F2}.ly{border-radius:99em}.lz{padding:0px 16px 0px 12px}.ma{height:38px}.mb{align-items:center}.md svg{margin-right:8px}.mi{margin-top:32px}.ne{font-size:20px}.nf{margin-top:1.2em}.ng{line-height:24px}.nh{letter-spacing:0}.oc{font-size:18px}.od{margin-top:0.67em}.oe{line-height:28px}.of{letter-spacing:-0.003em}.ou{margin-top:1.56em}.pc{margin-top:1.34em}.pk{margin-top:40px}.qa{margin-top:24px}.re{margin-bottom:80px}.rv{padding-top:48px}.mc:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="print">.rm{display:none}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.ip{max-height:none}</style><style type="text/css" data-fela-rehydration="530" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.mn{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg"],"url":"https:\u002F\u002Fmedium.com\u002Fthe-ai-forum\u002Fimplementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563","dateCreated":"2024-03-03T12:40:53.244Z","datePublished":"2024-03-03T12:40:53.244Z","dateModified":"2024-03-11T08:05:59.507Z","headline":"Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI","name":"Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI","description":"In contrast to alternative methods of integrating domain-specific data into LLM customization, RAG is simple and cost-effective. Organizations can deploy RAG without needing to customize the model…","identifier":"30d63e222563","author":{"@type":"Person","name":"Plaban Nayak","url":"https:\u002F\u002Fnayakpplaban.medium.com"},"creator":["Plaban Nayak"],"publisher":{"@type":"Organization","name":"The AI Forum","url":"https:\u002F\u002Fmedium.com\u002Fthe-ai-forum","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:385\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002Fthe-ai-forum\u002Fimplementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563"}</script><script async="true" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/js" data-rh="true"></script><script data-rh="true">window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-7JY7T788PK');</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script><style>@-webkit-keyframes swal2-show{0%{-webkit-transform:scale(.7);transform:scale(.7)}45%{-webkit-transform:scale(1.05);transform:scale(1.05)}80%{-webkit-transform:scale(.95);transform:scale(.95)}100%{-webkit-transform:scale(1);transform:scale(1)}}@keyframes swal2-show{0%{-webkit-transform:scale(.7);transform:scale(.7)}45%{-webkit-transform:scale(1.05);transform:scale(1.05)}80%{-webkit-transform:scale(.95);transform:scale(.95)}100%{-webkit-transform:scale(1);transform:scale(1)}}@-webkit-keyframes swal2-hide{0%{-webkit-transform:scale(1);transform:scale(1);opacity:1}100%{-webkit-transform:scale(.5);transform:scale(.5);opacity:0}}@keyframes swal2-hide{0%{-webkit-transform:scale(1);transform:scale(1);opacity:1}100%{-webkit-transform:scale(.5);transform:scale(.5);opacity:0}}@-webkit-keyframes swal2-animate-success-line-tip{0%{top:1.1875em;left:.0625em;width:0}54%{top:1.0625em;left:.125em;width:0}70%{top:2.1875em;left:-.375em;width:3.125em}84%{top:3em;left:1.3125em;width:1.0625em}100%{top:2.8125em;left:.875em;width:1.5625em}}@keyframes swal2-animate-success-line-tip{0%{top:1.1875em;left:.0625em;width:0}54%{top:1.0625em;left:.125em;width:0}70%{top:2.1875em;left:-.375em;width:3.125em}84%{top:3em;left:1.3125em;width:1.0625em}100%{top:2.8125em;left:.875em;width:1.5625em}}@-webkit-keyframes swal2-animate-success-line-long{0%{top:3.375em;right:2.875em;width:0}65%{top:3.375em;right:2.875em;width:0}84%{top:2.1875em;right:0;width:3.4375em}100%{top:2.375em;right:.5em;width:2.9375em}}@keyframes swal2-animate-success-line-long{0%{top:3.375em;right:2.875em;width:0}65%{top:3.375em;right:2.875em;width:0}84%{top:2.1875em;right:0;width:3.4375em}100%{top:2.375em;right:.5em;width:2.9375em}}@-webkit-keyframes swal2-rotate-success-circular-line{0%{-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}5%{-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}12%{-webkit-transform:rotate(-405deg);transform:rotate(-405deg)}100%{-webkit-transform:rotate(-405deg);transform:rotate(-405deg)}}@keyframes swal2-rotate-success-circular-line{0%{-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}5%{-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}12%{-webkit-transform:rotate(-405deg);transform:rotate(-405deg)}100%{-webkit-transform:rotate(-405deg);transform:rotate(-405deg)}}@-webkit-keyframes swal2-animate-error-x-mark{0%{margin-top:1.625em;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}50%{margin-top:1.625em;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}80%{margin-top:-.375em;-webkit-transform:scale(1.15);transform:scale(1.15)}100%{margin-top:0;-webkit-transform:scale(1);transform:scale(1);opacity:1}}@keyframes swal2-animate-error-x-mark{0%{margin-top:1.625em;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}50%{margin-top:1.625em;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}80%{margin-top:-.375em;-webkit-transform:scale(1.15);transform:scale(1.15)}100%{margin-top:0;-webkit-transform:scale(1);transform:scale(1);opacity:1}}@-webkit-keyframes swal2-animate-error-icon{0%{-webkit-transform:rotateX(100deg);transform:rotateX(100deg);opacity:0}100%{-webkit-transform:rotateX(0);transform:rotateX(0);opacity:1}}@keyframes swal2-animate-error-icon{0%{-webkit-transform:rotateX(100deg);transform:rotateX(100deg);opacity:0}100%{-webkit-transform:rotateX(0);transform:rotateX(0);opacity:1}}body.swal2-toast-shown .swal2-container{background-color:transparent}body.swal2-toast-shown .swal2-container.swal2-shown{background-color:transparent}body.swal2-toast-shown .swal2-container.swal2-top{top:0;right:auto;bottom:auto;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}body.swal2-toast-shown .swal2-container.swal2-top-end,body.swal2-toast-shown .swal2-container.swal2-top-right{top:0;right:0;bottom:auto;left:auto}body.swal2-toast-shown .swal2-container.swal2-top-left,body.swal2-toast-shown .swal2-container.swal2-top-start{top:0;right:auto;bottom:auto;left:0}body.swal2-toast-shown .swal2-container.swal2-center-left,body.swal2-toast-shown .swal2-container.swal2-center-start{top:50%;right:auto;bottom:auto;left:0;-webkit-transform:translateY(-50%);transform:translateY(-50%)}body.swal2-toast-shown .swal2-container.swal2-center{top:50%;right:auto;bottom:auto;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%)}body.swal2-toast-shown .swal2-container.swal2-center-end,body.swal2-toast-shown .swal2-container.swal2-center-right{top:50%;right:0;bottom:auto;left:auto;-webkit-transform:translateY(-50%);transform:translateY(-50%)}body.swal2-toast-shown .swal2-container.swal2-bottom-left,body.swal2-toast-shown .swal2-container.swal2-bottom-start{top:auto;right:auto;bottom:0;left:0}body.swal2-toast-shown .swal2-container.swal2-bottom{top:auto;right:auto;bottom:0;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}body.swal2-toast-shown .swal2-container.swal2-bottom-end,body.swal2-toast-shown .swal2-container.swal2-bottom-right{top:auto;right:0;bottom:0;left:auto}body.swal2-toast-column .swal2-toast{flex-direction:column;align-items:stretch}body.swal2-toast-column .swal2-toast .swal2-actions{flex:1;align-self:stretch;height:2.2em;margin-top:.3125em}body.swal2-toast-column .swal2-toast .swal2-loading{justify-content:center}body.swal2-toast-column .swal2-toast .swal2-input{height:2em;margin:.3125em auto;font-size:1em}body.swal2-toast-column .swal2-toast .swal2-validation-message{font-size:1em}.swal2-popup.swal2-toast{flex-direction:row;align-items:center;width:auto;padding:.625em;box-shadow:0 0 .625em #d9d9d9;overflow-y:hidden}.swal2-popup.swal2-toast .swal2-header{flex-direction:row}.swal2-popup.swal2-toast .swal2-title{flex-grow:1;justify-content:flex-start;margin:0 .6em;font-size:1em}.swal2-popup.swal2-toast .swal2-footer{margin:.5em 0 0;padding:.5em 0 0;font-size:.8em}.swal2-popup.swal2-toast .swal2-close{position:initial;width:.8em;height:.8em;line-height:.8}.swal2-popup.swal2-toast .swal2-content{justify-content:flex-start;font-size:1em}.swal2-popup.swal2-toast .swal2-icon{width:2em;min-width:2em;height:2em;margin:0}.swal2-popup.swal2-toast .swal2-icon-text{font-size:2em;font-weight:700;line-height:1em}.swal2-popup.swal2-toast .swal2-icon.swal2-success .swal2-success-ring{width:2em;height:2em}.swal2-popup.swal2-toast .swal2-icon.swal2-error [class^=swal2-x-mark-line]{top:.875em;width:1.375em}.swal2-popup.swal2-toast .swal2-icon.swal2-error [class^=swal2-x-mark-line][class$=left]{left:.3125em}.swal2-popup.swal2-toast .swal2-icon.swal2-error [class^=swal2-x-mark-line][class$=right]{right:.3125em}.swal2-popup.swal2-toast .swal2-actions{height:auto;margin:0 .3125em}.swal2-popup.swal2-toast .swal2-styled{margin:0 .3125em;padding:.3125em .625em;font-size:1em}.swal2-popup.swal2-toast .swal2-styled:focus{box-shadow:0 0 0 .0625em #fff,0 0 0 .125em rgba(50,100,150,.4)}.swal2-popup.swal2-toast .swal2-success{border-color:#a5dc86}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-circular-line]{position:absolute;width:2em;height:2.8125em;-webkit-transform:rotate(45deg);transform:rotate(45deg);border-radius:50%}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-circular-line][class$=left]{top:-.25em;left:-.9375em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);-webkit-transform-origin:2em 2em;transform-origin:2em 2em;border-radius:4em 0 0 4em}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-circular-line][class$=right]{top:-.25em;left:.9375em;-webkit-transform-origin:0 2em;transform-origin:0 2em;border-radius:0 4em 4em 0}.swal2-popup.swal2-toast .swal2-success .swal2-success-ring{width:2em;height:2em}.swal2-popup.swal2-toast .swal2-success .swal2-success-fix{top:0;left:.4375em;width:.4375em;height:2.6875em}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-line]{height:.3125em}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-line][class$=tip]{top:1.125em;left:.1875em;width:.75em}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-line][class$=long]{top:.9375em;right:.1875em;width:1.375em}.swal2-popup.swal2-toast.swal2-show{-webkit-animation:showSweetToast .5s;animation:showSweetToast .5s}.swal2-popup.swal2-toast.swal2-hide{-webkit-animation:hideSweetToast .2s forwards;animation:hideSweetToast .2s forwards}.swal2-popup.swal2-toast .swal2-animate-success-icon .swal2-success-line-tip{-webkit-animation:animate-toast-success-tip .75s;animation:animate-toast-success-tip .75s}.swal2-popup.swal2-toast .swal2-animate-success-icon .swal2-success-line-long{-webkit-animation:animate-toast-success-long .75s;animation:animate-toast-success-long .75s}@-webkit-keyframes showSweetToast{0%{-webkit-transform:translateY(-.625em) rotateZ(2deg);transform:translateY(-.625em) rotateZ(2deg);opacity:0}33%{-webkit-transform:translateY(0) rotateZ(-2deg);transform:translateY(0) rotateZ(-2deg);opacity:.5}66%{-webkit-transform:translateY(.3125em) rotateZ(2deg);transform:translateY(.3125em) rotateZ(2deg);opacity:.7}100%{-webkit-transform:translateY(0) rotateZ(0);transform:translateY(0) rotateZ(0);opacity:1}}@keyframes showSweetToast{0%{-webkit-transform:translateY(-.625em) rotateZ(2deg);transform:translateY(-.625em) rotateZ(2deg);opacity:0}33%{-webkit-transform:translateY(0) rotateZ(-2deg);transform:translateY(0) rotateZ(-2deg);opacity:.5}66%{-webkit-transform:translateY(.3125em) rotateZ(2deg);transform:translateY(.3125em) rotateZ(2deg);opacity:.7}100%{-webkit-transform:translateY(0) rotateZ(0);transform:translateY(0) rotateZ(0);opacity:1}}@-webkit-keyframes hideSweetToast{0%{opacity:1}33%{opacity:.5}100%{-webkit-transform:rotateZ(1deg);transform:rotateZ(1deg);opacity:0}}@keyframes hideSweetToast{0%{opacity:1}33%{opacity:.5}100%{-webkit-transform:rotateZ(1deg);transform:rotateZ(1deg);opacity:0}}@-webkit-keyframes animate-toast-success-tip{0%{top:.5625em;left:.0625em;width:0}54%{top:.125em;left:.125em;width:0}70%{top:.625em;left:-.25em;width:1.625em}84%{top:1.0625em;left:.75em;width:.5em}100%{top:1.125em;left:.1875em;width:.75em}}@keyframes animate-toast-success-tip{0%{top:.5625em;left:.0625em;width:0}54%{top:.125em;left:.125em;width:0}70%{top:.625em;left:-.25em;width:1.625em}84%{top:1.0625em;left:.75em;width:.5em}100%{top:1.125em;left:.1875em;width:.75em}}@-webkit-keyframes animate-toast-success-long{0%{top:1.625em;right:1.375em;width:0}65%{top:1.25em;right:.9375em;width:0}84%{top:.9375em;right:0;width:1.125em}100%{top:.9375em;right:.1875em;width:1.375em}}@keyframes animate-toast-success-long{0%{top:1.625em;right:1.375em;width:0}65%{top:1.25em;right:.9375em;width:0}84%{top:.9375em;right:0;width:1.125em}100%{top:.9375em;right:.1875em;width:1.375em}}body.swal2-shown:not(.swal2-no-backdrop):not(.swal2-toast-shown){overflow:hidden}body.swal2-height-auto{height:auto!important}body.swal2-no-backdrop .swal2-shown{top:auto;right:auto;bottom:auto;left:auto;background-color:transparent}body.swal2-no-backdrop .swal2-shown>.swal2-modal{box-shadow:0 0 10px rgba(0,0,0,.4)}body.swal2-no-backdrop .swal2-shown.swal2-top{top:0;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}body.swal2-no-backdrop .swal2-shown.swal2-top-left,body.swal2-no-backdrop .swal2-shown.swal2-top-start{top:0;left:0}body.swal2-no-backdrop .swal2-shown.swal2-top-end,body.swal2-no-backdrop .swal2-shown.swal2-top-right{top:0;right:0}body.swal2-no-backdrop .swal2-shown.swal2-center{top:50%;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%)}body.swal2-no-backdrop .swal2-shown.swal2-center-left,body.swal2-no-backdrop .swal2-shown.swal2-center-start{top:50%;left:0;-webkit-transform:translateY(-50%);transform:translateY(-50%)}body.swal2-no-backdrop .swal2-shown.swal2-center-end,body.swal2-no-backdrop .swal2-shown.swal2-center-right{top:50%;right:0;-webkit-transform:translateY(-50%);transform:translateY(-50%)}body.swal2-no-backdrop .swal2-shown.swal2-bottom{bottom:0;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}body.swal2-no-backdrop .swal2-shown.swal2-bottom-left,body.swal2-no-backdrop .swal2-shown.swal2-bottom-start{bottom:0;left:0}body.swal2-no-backdrop .swal2-shown.swal2-bottom-end,body.swal2-no-backdrop .swal2-shown.swal2-bottom-right{right:0;bottom:0}.swal2-container{display:flex;position:fixed;top:0;right:0;bottom:0;left:0;flex-direction:row;align-items:center;justify-content:center;padding:10px;background-color:transparent;z-index:1060;overflow-x:hidden;-webkit-overflow-scrolling:touch}.swal2-container.swal2-top{align-items:flex-start}.swal2-container.swal2-top-left,.swal2-container.swal2-top-start{align-items:flex-start;justify-content:flex-start}.swal2-container.swal2-top-end,.swal2-container.swal2-top-right{align-items:flex-start;justify-content:flex-end}.swal2-container.swal2-center{align-items:center}.swal2-container.swal2-center-left,.swal2-container.swal2-center-start{align-items:center;justify-content:flex-start}.swal2-container.swal2-center-end,.swal2-container.swal2-center-right{align-items:center;justify-content:flex-end}.swal2-container.swal2-bottom{align-items:flex-end}.swal2-container.swal2-bottom-left,.swal2-container.swal2-bottom-start{align-items:flex-end;justify-content:flex-start}.swal2-container.swal2-bottom-end,.swal2-container.swal2-bottom-right{align-items:flex-end;justify-content:flex-end}.swal2-container.swal2-grow-fullscreen>.swal2-modal{display:flex!important;flex:1;align-self:stretch;justify-content:center}.swal2-container.swal2-grow-row>.swal2-modal{display:flex!important;flex:1;align-content:center;justify-content:center}.swal2-container.swal2-grow-column{flex:1;flex-direction:column}.swal2-container.swal2-grow-column.swal2-bottom,.swal2-container.swal2-grow-column.swal2-center,.swal2-container.swal2-grow-column.swal2-top{align-items:center}.swal2-container.swal2-grow-column.swal2-bottom-left,.swal2-container.swal2-grow-column.swal2-bottom-start,.swal2-container.swal2-grow-column.swal2-center-left,.swal2-container.swal2-grow-column.swal2-center-start,.swal2-container.swal2-grow-column.swal2-top-left,.swal2-container.swal2-grow-column.swal2-top-start{align-items:flex-start}.swal2-container.swal2-grow-column.swal2-bottom-end,.swal2-container.swal2-grow-column.swal2-bottom-right,.swal2-container.swal2-grow-column.swal2-center-end,.swal2-container.swal2-grow-column.swal2-center-right,.swal2-container.swal2-grow-column.swal2-top-end,.swal2-container.swal2-grow-column.swal2-top-right{align-items:flex-end}.swal2-container.swal2-grow-column>.swal2-modal{display:flex!important;flex:1;align-content:center;justify-content:center}.swal2-container:not(.swal2-top):not(.swal2-top-start):not(.swal2-top-end):not(.swal2-top-left):not(.swal2-top-right):not(.swal2-center-start):not(.swal2-center-end):not(.swal2-center-left):not(.swal2-center-right):not(.swal2-bottom):not(.swal2-bottom-start):not(.swal2-bottom-end):not(.swal2-bottom-left):not(.swal2-bottom-right):not(.swal2-grow-fullscreen)>.swal2-modal{margin:auto}@media all and (-ms-high-contrast:none),(-ms-high-contrast:active){.swal2-container .swal2-modal{margin:0!important}}.swal2-container.swal2-fade{transition:background-color .1s}.swal2-container.swal2-shown{background-color:rgba(0,0,0,.4)}.swal2-popup{display:none;position:relative;flex-direction:column;justify-content:center;width:32em;max-width:100%;padding:1.25em;border-radius:.3125em;background:#fff;font-family:inherit;font-size:1rem;box-sizing:border-box}.swal2-popup:focus{outline:0}.swal2-popup.swal2-loading{overflow-y:hidden}.swal2-popup .swal2-header{display:flex;flex-direction:column;align-items:center}.swal2-popup .swal2-title{display:block;position:relative;max-width:100%;margin:0 0 .4em;padding:0;color:#595959;font-size:1.875em;font-weight:600;text-align:center;text-transform:none;word-wrap:break-word}.swal2-popup .swal2-actions{flex-wrap:wrap;align-items:center;justify-content:center;margin:1.25em auto 0;z-index:1}.swal2-popup .swal2-actions:not(.swal2-loading) .swal2-styled[disabled]{opacity:.4}.swal2-popup .swal2-actions:not(.swal2-loading) .swal2-styled:hover{background-image:linear-gradient(rgba(0,0,0,.1),rgba(0,0,0,.1))}.swal2-popup .swal2-actions:not(.swal2-loading) .swal2-styled:active{background-image:linear-gradient(rgba(0,0,0,.2),rgba(0,0,0,.2))}.swal2-popup .swal2-actions.swal2-loading .swal2-styled.swal2-confirm{width:2.5em;height:2.5em;margin:.46875em;padding:0;border:.25em solid transparent;border-radius:100%;border-color:transparent;background-color:transparent!important;color:transparent;cursor:default;box-sizing:border-box;-webkit-animation:swal2-rotate-loading 1.5s linear 0s infinite normal;animation:swal2-rotate-loading 1.5s linear 0s infinite normal;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.swal2-popup .swal2-actions.swal2-loading .swal2-styled.swal2-cancel{margin-right:30px;margin-left:30px}.swal2-popup .swal2-actions.swal2-loading :not(.swal2-styled).swal2-confirm::after{display:inline-block;width:15px;height:15px;margin-left:5px;border:3px solid #999;border-radius:50%;border-right-color:transparent;box-shadow:1px 1px 1px #fff;content:'';-webkit-animation:swal2-rotate-loading 1.5s linear 0s infinite normal;animation:swal2-rotate-loading 1.5s linear 0s infinite normal}.swal2-popup .swal2-styled{margin:.3125em;padding:.625em 2em;font-weight:500;box-shadow:none}.swal2-popup .swal2-styled:not([disabled]){cursor:pointer}.swal2-popup .swal2-styled.swal2-confirm{border:0;border-radius:.25em;background:initial;background-color:#3085d6;color:#fff;font-size:1.0625em}.swal2-popup .swal2-styled.swal2-cancel{border:0;border-radius:.25em;background:initial;background-color:#aaa;color:#fff;font-size:1.0625em}.swal2-popup .swal2-styled:focus{outline:0;box-shadow:0 0 0 2px #fff,0 0 0 4px rgba(50,100,150,.4)}.swal2-popup .swal2-styled::-moz-focus-inner{border:0}.swal2-popup .swal2-footer{justify-content:center;margin:1.25em 0 0;padding:1em 0 0;border-top:1px solid #eee;color:#545454;font-size:1em}.swal2-popup .swal2-image{max-width:100%;margin:1.25em auto}.swal2-popup .swal2-close{position:absolute;top:0;right:0;justify-content:center;width:1.2em;height:1.2em;padding:0;transition:color .1s ease-out;border:none;border-radius:0;outline:initial;background:0 0;color:#ccc;font-family:serif;font-size:2.5em;line-height:1.2;cursor:pointer;overflow:hidden}.swal2-popup .swal2-close:hover{-webkit-transform:none;transform:none;color:#f27474}.swal2-popup>.swal2-checkbox,.swal2-popup>.swal2-file,.swal2-popup>.swal2-input,.swal2-popup>.swal2-radio,.swal2-popup>.swal2-select,.swal2-popup>.swal2-textarea{display:none}.swal2-popup .swal2-content{justify-content:center;margin:0;padding:0;color:#545454;font-size:1.125em;font-weight:300;line-height:normal;z-index:1;word-wrap:break-word}.swal2-popup #swal2-content{text-align:center}.swal2-popup .swal2-checkbox,.swal2-popup .swal2-file,.swal2-popup .swal2-input,.swal2-popup .swal2-radio,.swal2-popup .swal2-select,.swal2-popup .swal2-textarea{margin:1em auto}.swal2-popup .swal2-file,.swal2-popup .swal2-input,.swal2-popup .swal2-textarea{width:100%;transition:border-color .3s,box-shadow .3s;border:1px solid #d9d9d9;border-radius:.1875em;font-size:1.125em;box-shadow:inset 0 1px 1px rgba(0,0,0,.06);box-sizing:border-box}.swal2-popup .swal2-file.swal2-inputerror,.swal2-popup .swal2-input.swal2-inputerror,.swal2-popup .swal2-textarea.swal2-inputerror{border-color:#f27474!important;box-shadow:0 0 2px #f27474!important}.swal2-popup .swal2-file:focus,.swal2-popup .swal2-input:focus,.swal2-popup .swal2-textarea:focus{border:1px solid #b4dbed;outline:0;box-shadow:0 0 3px #c4e6f5}.swal2-popup .swal2-file::-webkit-input-placeholder,.swal2-popup .swal2-input::-webkit-input-placeholder,.swal2-popup .swal2-textarea::-webkit-input-placeholder{color:#ccc}.swal2-popup .swal2-file:-ms-input-placeholder,.swal2-popup .swal2-input:-ms-input-placeholder,.swal2-popup .swal2-textarea:-ms-input-placeholder{color:#ccc}.swal2-popup .swal2-file::-ms-input-placeholder,.swal2-popup .swal2-input::-ms-input-placeholder,.swal2-popup .swal2-textarea::-ms-input-placeholder{color:#ccc}.swal2-popup .swal2-file::placeholder,.swal2-popup .swal2-input::placeholder,.swal2-popup .swal2-textarea::placeholder{color:#ccc}.swal2-popup .swal2-range input{width:80%}.swal2-popup .swal2-range output{width:20%;font-weight:600;text-align:center}.swal2-popup .swal2-range input,.swal2-popup .swal2-range output{height:2.625em;margin:1em auto;padding:0;font-size:1.125em;line-height:2.625em}.swal2-popup .swal2-input{height:2.625em;padding:0 .75em}.swal2-popup .swal2-input[type=number]{max-width:10em}.swal2-popup .swal2-file{font-size:1.125em}.swal2-popup .swal2-textarea{height:6.75em;padding:.75em}.swal2-popup .swal2-select{min-width:50%;max-width:100%;padding:.375em .625em;color:#545454;font-size:1.125em}.swal2-popup .swal2-checkbox,.swal2-popup .swal2-radio{align-items:center;justify-content:center}.swal2-popup .swal2-checkbox label,.swal2-popup .swal2-radio label{margin:0 .6em;font-size:1.125em}.swal2-popup .swal2-checkbox input,.swal2-popup .swal2-radio input{margin:0 .4em}.swal2-popup .swal2-validation-message{display:none;align-items:center;justify-content:center;padding:.625em;background:#f0f0f0;color:#666;font-size:1em;font-weight:300;overflow:hidden}.swal2-popup .swal2-validation-message::before{display:inline-block;width:1.5em;min-width:1.5em;height:1.5em;margin:0 .625em;border-radius:50%;background-color:#f27474;color:#fff;font-weight:600;line-height:1.5em;text-align:center;content:'!';zoom:normal}@supports (-ms-accelerator:true){.swal2-range input{width:100%!important}.swal2-range output{display:none}}@media all and (-ms-high-contrast:none),(-ms-high-contrast:active){.swal2-range input{width:100%!important}.swal2-range output{display:none}}@-moz-document url-prefix(){.swal2-close:focus{outline:2px solid rgba(50,100,150,.4)}}.swal2-icon{position:relative;justify-content:center;width:5em;height:5em;margin:1.25em auto 1.875em;border:.25em solid transparent;border-radius:50%;line-height:5em;cursor:default;box-sizing:content-box;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;zoom:normal}.swal2-icon-text{font-size:3.75em}.swal2-icon.swal2-error{border-color:#f27474}.swal2-icon.swal2-error .swal2-x-mark{position:relative;flex-grow:1}.swal2-icon.swal2-error [class^=swal2-x-mark-line]{display:block;position:absolute;top:2.3125em;width:2.9375em;height:.3125em;border-radius:.125em;background-color:#f27474}.swal2-icon.swal2-error [class^=swal2-x-mark-line][class$=left]{left:1.0625em;-webkit-transform:rotate(45deg);transform:rotate(45deg)}.swal2-icon.swal2-error [class^=swal2-x-mark-line][class$=right]{right:1em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}.swal2-icon.swal2-warning{border-color:#facea8;color:#f8bb86}.swal2-icon.swal2-info{border-color:#9de0f6;color:#3fc3ee}.swal2-icon.swal2-question{border-color:#c9dae1;color:#87adbd}.swal2-icon.swal2-success{border-color:#a5dc86}.swal2-icon.swal2-success [class^=swal2-success-circular-line]{position:absolute;width:3.75em;height:7.5em;-webkit-transform:rotate(45deg);transform:rotate(45deg);border-radius:50%}.swal2-icon.swal2-success [class^=swal2-success-circular-line][class$=left]{top:-.4375em;left:-2.0635em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);-webkit-transform-origin:3.75em 3.75em;transform-origin:3.75em 3.75em;border-radius:7.5em 0 0 7.5em}.swal2-icon.swal2-success [class^=swal2-success-circular-line][class$=right]{top:-.6875em;left:1.875em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);-webkit-transform-origin:0 3.75em;transform-origin:0 3.75em;border-radius:0 7.5em 7.5em 0}.swal2-icon.swal2-success .swal2-success-ring{position:absolute;top:-.25em;left:-.25em;width:100%;height:100%;border:.25em solid rgba(165,220,134,.3);border-radius:50%;z-index:2;box-sizing:content-box}.swal2-icon.swal2-success .swal2-success-fix{position:absolute;top:.5em;left:1.625em;width:.4375em;height:5.625em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);z-index:1}.swal2-icon.swal2-success [class^=swal2-success-line]{display:block;position:absolute;height:.3125em;border-radius:.125em;background-color:#a5dc86;z-index:2}.swal2-icon.swal2-success [class^=swal2-success-line][class$=tip]{top:2.875em;left:.875em;width:1.5625em;-webkit-transform:rotate(45deg);transform:rotate(45deg)}.swal2-icon.swal2-success [class^=swal2-success-line][class$=long]{top:2.375em;right:.5em;width:2.9375em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}.swal2-progresssteps{align-items:center;margin:0 0 1.25em;padding:0;font-weight:600}.swal2-progresssteps li{display:inline-block;position:relative}.swal2-progresssteps .swal2-progresscircle{width:2em;height:2em;border-radius:2em;background:#3085d6;color:#fff;line-height:2em;text-align:center;z-index:20}.swal2-progresssteps .swal2-progresscircle:first-child{margin-left:0}.swal2-progresssteps .swal2-progresscircle:last-child{margin-right:0}.swal2-progresssteps .swal2-progresscircle.swal2-activeprogressstep{background:#3085d6}.swal2-progresssteps .swal2-progresscircle.swal2-activeprogressstep~.swal2-progresscircle{background:#add8e6}.swal2-progresssteps .swal2-progresscircle.swal2-activeprogressstep~.swal2-progressline{background:#add8e6}.swal2-progresssteps .swal2-progressline{width:2.5em;height:.4em;margin:0 -1px;background:#3085d6;z-index:10}[class^=swal2]{-webkit-tap-highlight-color:transparent}.swal2-show{-webkit-animation:swal2-show .3s;animation:swal2-show .3s}.swal2-show.swal2-noanimation{-webkit-animation:none;animation:none}.swal2-hide{-webkit-animation:swal2-hide .15s forwards;animation:swal2-hide .15s forwards}.swal2-hide.swal2-noanimation{-webkit-animation:none;animation:none}.swal2-rtl .swal2-close{right:auto;left:0}.swal2-animate-success-icon .swal2-success-line-tip{-webkit-animation:swal2-animate-success-line-tip .75s;animation:swal2-animate-success-line-tip .75s}.swal2-animate-success-icon .swal2-success-line-long{-webkit-animation:swal2-animate-success-line-long .75s;animation:swal2-animate-success-line-long .75s}.swal2-animate-success-icon .swal2-success-circular-line-right{-webkit-animation:swal2-rotate-success-circular-line 4.25s ease-in;animation:swal2-rotate-success-circular-line 4.25s ease-in}.swal2-animate-error-icon{-webkit-animation:swal2-animate-error-icon .5s;animation:swal2-animate-error-icon .5s}.swal2-animate-error-icon .swal2-x-mark{-webkit-animation:swal2-animate-error-x-mark .5s;animation:swal2-animate-error-x-mark .5s}@-webkit-keyframes swal2-rotate-loading{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes swal2-rotate-loading{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@media print{body.swal2-shown:not(.swal2-no-backdrop):not(.swal2-toast-shown){overflow-y:scroll!important}body.swal2-shown:not(.swal2-no-backdrop):not(.swal2-toast-shown)>[aria-hidden=true]{display:none}body.swal2-shown:not(.swal2-no-backdrop):not(.swal2-toast-shown) .swal2-container{position:initial!important}}</style><style>@-webkit-keyframes swal2-show{0%{-webkit-transform:scale(.7);transform:scale(.7)}45%{-webkit-transform:scale(1.05);transform:scale(1.05)}80%{-webkit-transform:scale(.95);transform:scale(.95)}100%{-webkit-transform:scale(1);transform:scale(1)}}@keyframes swal2-show{0%{-webkit-transform:scale(.7);transform:scale(.7)}45%{-webkit-transform:scale(1.05);transform:scale(1.05)}80%{-webkit-transform:scale(.95);transform:scale(.95)}100%{-webkit-transform:scale(1);transform:scale(1)}}@-webkit-keyframes swal2-hide{0%{-webkit-transform:scale(1);transform:scale(1);opacity:1}100%{-webkit-transform:scale(.5);transform:scale(.5);opacity:0}}@keyframes swal2-hide{0%{-webkit-transform:scale(1);transform:scale(1);opacity:1}100%{-webkit-transform:scale(.5);transform:scale(.5);opacity:0}}@-webkit-keyframes swal2-animate-success-line-tip{0%{top:1.1875em;left:.0625em;width:0}54%{top:1.0625em;left:.125em;width:0}70%{top:2.1875em;left:-.375em;width:3.125em}84%{top:3em;left:1.3125em;width:1.0625em}100%{top:2.8125em;left:.875em;width:1.5625em}}@keyframes swal2-animate-success-line-tip{0%{top:1.1875em;left:.0625em;width:0}54%{top:1.0625em;left:.125em;width:0}70%{top:2.1875em;left:-.375em;width:3.125em}84%{top:3em;left:1.3125em;width:1.0625em}100%{top:2.8125em;left:.875em;width:1.5625em}}@-webkit-keyframes swal2-animate-success-line-long{0%{top:3.375em;right:2.875em;width:0}65%{top:3.375em;right:2.875em;width:0}84%{top:2.1875em;right:0;width:3.4375em}100%{top:2.375em;right:.5em;width:2.9375em}}@keyframes swal2-animate-success-line-long{0%{top:3.375em;right:2.875em;width:0}65%{top:3.375em;right:2.875em;width:0}84%{top:2.1875em;right:0;width:3.4375em}100%{top:2.375em;right:.5em;width:2.9375em}}@-webkit-keyframes swal2-rotate-success-circular-line{0%{-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}5%{-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}12%{-webkit-transform:rotate(-405deg);transform:rotate(-405deg)}100%{-webkit-transform:rotate(-405deg);transform:rotate(-405deg)}}@keyframes swal2-rotate-success-circular-line{0%{-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}5%{-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}12%{-webkit-transform:rotate(-405deg);transform:rotate(-405deg)}100%{-webkit-transform:rotate(-405deg);transform:rotate(-405deg)}}@-webkit-keyframes swal2-animate-error-x-mark{0%{margin-top:1.625em;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}50%{margin-top:1.625em;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}80%{margin-top:-.375em;-webkit-transform:scale(1.15);transform:scale(1.15)}100%{margin-top:0;-webkit-transform:scale(1);transform:scale(1);opacity:1}}@keyframes swal2-animate-error-x-mark{0%{margin-top:1.625em;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}50%{margin-top:1.625em;-webkit-transform:scale(.4);transform:scale(.4);opacity:0}80%{margin-top:-.375em;-webkit-transform:scale(1.15);transform:scale(1.15)}100%{margin-top:0;-webkit-transform:scale(1);transform:scale(1);opacity:1}}@-webkit-keyframes swal2-animate-error-icon{0%{-webkit-transform:rotateX(100deg);transform:rotateX(100deg);opacity:0}100%{-webkit-transform:rotateX(0);transform:rotateX(0);opacity:1}}@keyframes swal2-animate-error-icon{0%{-webkit-transform:rotateX(100deg);transform:rotateX(100deg);opacity:0}100%{-webkit-transform:rotateX(0);transform:rotateX(0);opacity:1}}body.swal2-toast-shown .swal2-container{background-color:transparent}body.swal2-toast-shown .swal2-container.swal2-shown{background-color:transparent}body.swal2-toast-shown .swal2-container.swal2-top{top:0;right:auto;bottom:auto;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}body.swal2-toast-shown .swal2-container.swal2-top-end,body.swal2-toast-shown .swal2-container.swal2-top-right{top:0;right:0;bottom:auto;left:auto}body.swal2-toast-shown .swal2-container.swal2-top-left,body.swal2-toast-shown .swal2-container.swal2-top-start{top:0;right:auto;bottom:auto;left:0}body.swal2-toast-shown .swal2-container.swal2-center-left,body.swal2-toast-shown .swal2-container.swal2-center-start{top:50%;right:auto;bottom:auto;left:0;-webkit-transform:translateY(-50%);transform:translateY(-50%)}body.swal2-toast-shown .swal2-container.swal2-center{top:50%;right:auto;bottom:auto;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%)}body.swal2-toast-shown .swal2-container.swal2-center-end,body.swal2-toast-shown .swal2-container.swal2-center-right{top:50%;right:0;bottom:auto;left:auto;-webkit-transform:translateY(-50%);transform:translateY(-50%)}body.swal2-toast-shown .swal2-container.swal2-bottom-left,body.swal2-toast-shown .swal2-container.swal2-bottom-start{top:auto;right:auto;bottom:0;left:0}body.swal2-toast-shown .swal2-container.swal2-bottom{top:auto;right:auto;bottom:0;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}body.swal2-toast-shown .swal2-container.swal2-bottom-end,body.swal2-toast-shown .swal2-container.swal2-bottom-right{top:auto;right:0;bottom:0;left:auto}body.swal2-toast-column .swal2-toast{flex-direction:column;align-items:stretch}body.swal2-toast-column .swal2-toast .swal2-actions{flex:1;align-self:stretch;height:2.2em;margin-top:.3125em}body.swal2-toast-column .swal2-toast .swal2-loading{justify-content:center}body.swal2-toast-column .swal2-toast .swal2-input{height:2em;margin:.3125em auto;font-size:1em}body.swal2-toast-column .swal2-toast .swal2-validation-message{font-size:1em}.swal2-popup.swal2-toast{flex-direction:row;align-items:center;width:auto;padding:.625em;box-shadow:0 0 .625em #d9d9d9;overflow-y:hidden}.swal2-popup.swal2-toast .swal2-header{flex-direction:row}.swal2-popup.swal2-toast .swal2-title{flex-grow:1;justify-content:flex-start;margin:0 .6em;font-size:1em}.swal2-popup.swal2-toast .swal2-footer{margin:.5em 0 0;padding:.5em 0 0;font-size:.8em}.swal2-popup.swal2-toast .swal2-close{position:initial;width:.8em;height:.8em;line-height:.8}.swal2-popup.swal2-toast .swal2-content{justify-content:flex-start;font-size:1em}.swal2-popup.swal2-toast .swal2-icon{width:2em;min-width:2em;height:2em;margin:0}.swal2-popup.swal2-toast .swal2-icon-text{font-size:2em;font-weight:700;line-height:1em}.swal2-popup.swal2-toast .swal2-icon.swal2-success .swal2-success-ring{width:2em;height:2em}.swal2-popup.swal2-toast .swal2-icon.swal2-error [class^=swal2-x-mark-line]{top:.875em;width:1.375em}.swal2-popup.swal2-toast .swal2-icon.swal2-error [class^=swal2-x-mark-line][class$=left]{left:.3125em}.swal2-popup.swal2-toast .swal2-icon.swal2-error [class^=swal2-x-mark-line][class$=right]{right:.3125em}.swal2-popup.swal2-toast .swal2-actions{height:auto;margin:0 .3125em}.swal2-popup.swal2-toast .swal2-styled{margin:0 .3125em;padding:.3125em .625em;font-size:1em}.swal2-popup.swal2-toast .swal2-styled:focus{box-shadow:0 0 0 .0625em #fff,0 0 0 .125em rgba(50,100,150,.4)}.swal2-popup.swal2-toast .swal2-success{border-color:#a5dc86}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-circular-line]{position:absolute;width:2em;height:2.8125em;-webkit-transform:rotate(45deg);transform:rotate(45deg);border-radius:50%}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-circular-line][class$=left]{top:-.25em;left:-.9375em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);-webkit-transform-origin:2em 2em;transform-origin:2em 2em;border-radius:4em 0 0 4em}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-circular-line][class$=right]{top:-.25em;left:.9375em;-webkit-transform-origin:0 2em;transform-origin:0 2em;border-radius:0 4em 4em 0}.swal2-popup.swal2-toast .swal2-success .swal2-success-ring{width:2em;height:2em}.swal2-popup.swal2-toast .swal2-success .swal2-success-fix{top:0;left:.4375em;width:.4375em;height:2.6875em}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-line]{height:.3125em}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-line][class$=tip]{top:1.125em;left:.1875em;width:.75em}.swal2-popup.swal2-toast .swal2-success [class^=swal2-success-line][class$=long]{top:.9375em;right:.1875em;width:1.375em}.swal2-popup.swal2-toast.swal2-show{-webkit-animation:showSweetToast .5s;animation:showSweetToast .5s}.swal2-popup.swal2-toast.swal2-hide{-webkit-animation:hideSweetToast .2s forwards;animation:hideSweetToast .2s forwards}.swal2-popup.swal2-toast .swal2-animate-success-icon .swal2-success-line-tip{-webkit-animation:animate-toast-success-tip .75s;animation:animate-toast-success-tip .75s}.swal2-popup.swal2-toast .swal2-animate-success-icon .swal2-success-line-long{-webkit-animation:animate-toast-success-long .75s;animation:animate-toast-success-long .75s}@-webkit-keyframes showSweetToast{0%{-webkit-transform:translateY(-.625em) rotateZ(2deg);transform:translateY(-.625em) rotateZ(2deg);opacity:0}33%{-webkit-transform:translateY(0) rotateZ(-2deg);transform:translateY(0) rotateZ(-2deg);opacity:.5}66%{-webkit-transform:translateY(.3125em) rotateZ(2deg);transform:translateY(.3125em) rotateZ(2deg);opacity:.7}100%{-webkit-transform:translateY(0) rotateZ(0);transform:translateY(0) rotateZ(0);opacity:1}}@keyframes showSweetToast{0%{-webkit-transform:translateY(-.625em) rotateZ(2deg);transform:translateY(-.625em) rotateZ(2deg);opacity:0}33%{-webkit-transform:translateY(0) rotateZ(-2deg);transform:translateY(0) rotateZ(-2deg);opacity:.5}66%{-webkit-transform:translateY(.3125em) rotateZ(2deg);transform:translateY(.3125em) rotateZ(2deg);opacity:.7}100%{-webkit-transform:translateY(0) rotateZ(0);transform:translateY(0) rotateZ(0);opacity:1}}@-webkit-keyframes hideSweetToast{0%{opacity:1}33%{opacity:.5}100%{-webkit-transform:rotateZ(1deg);transform:rotateZ(1deg);opacity:0}}@keyframes hideSweetToast{0%{opacity:1}33%{opacity:.5}100%{-webkit-transform:rotateZ(1deg);transform:rotateZ(1deg);opacity:0}}@-webkit-keyframes animate-toast-success-tip{0%{top:.5625em;left:.0625em;width:0}54%{top:.125em;left:.125em;width:0}70%{top:.625em;left:-.25em;width:1.625em}84%{top:1.0625em;left:.75em;width:.5em}100%{top:1.125em;left:.1875em;width:.75em}}@keyframes animate-toast-success-tip{0%{top:.5625em;left:.0625em;width:0}54%{top:.125em;left:.125em;width:0}70%{top:.625em;left:-.25em;width:1.625em}84%{top:1.0625em;left:.75em;width:.5em}100%{top:1.125em;left:.1875em;width:.75em}}@-webkit-keyframes animate-toast-success-long{0%{top:1.625em;right:1.375em;width:0}65%{top:1.25em;right:.9375em;width:0}84%{top:.9375em;right:0;width:1.125em}100%{top:.9375em;right:.1875em;width:1.375em}}@keyframes animate-toast-success-long{0%{top:1.625em;right:1.375em;width:0}65%{top:1.25em;right:.9375em;width:0}84%{top:.9375em;right:0;width:1.125em}100%{top:.9375em;right:.1875em;width:1.375em}}body.swal2-shown:not(.swal2-no-backdrop):not(.swal2-toast-shown){overflow:hidden}body.swal2-height-auto{height:auto!important}body.swal2-no-backdrop .swal2-shown{top:auto;right:auto;bottom:auto;left:auto;background-color:transparent}body.swal2-no-backdrop .swal2-shown>.swal2-modal{box-shadow:0 0 10px rgba(0,0,0,.4)}body.swal2-no-backdrop .swal2-shown.swal2-top{top:0;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}body.swal2-no-backdrop .swal2-shown.swal2-top-left,body.swal2-no-backdrop .swal2-shown.swal2-top-start{top:0;left:0}body.swal2-no-backdrop .swal2-shown.swal2-top-end,body.swal2-no-backdrop .swal2-shown.swal2-top-right{top:0;right:0}body.swal2-no-backdrop .swal2-shown.swal2-center{top:50%;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%)}body.swal2-no-backdrop .swal2-shown.swal2-center-left,body.swal2-no-backdrop .swal2-shown.swal2-center-start{top:50%;left:0;-webkit-transform:translateY(-50%);transform:translateY(-50%)}body.swal2-no-backdrop .swal2-shown.swal2-center-end,body.swal2-no-backdrop .swal2-shown.swal2-center-right{top:50%;right:0;-webkit-transform:translateY(-50%);transform:translateY(-50%)}body.swal2-no-backdrop .swal2-shown.swal2-bottom{bottom:0;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%)}body.swal2-no-backdrop .swal2-shown.swal2-bottom-left,body.swal2-no-backdrop .swal2-shown.swal2-bottom-start{bottom:0;left:0}body.swal2-no-backdrop .swal2-shown.swal2-bottom-end,body.swal2-no-backdrop .swal2-shown.swal2-bottom-right{right:0;bottom:0}.swal2-container{display:flex;position:fixed;top:0;right:0;bottom:0;left:0;flex-direction:row;align-items:center;justify-content:center;padding:10px;background-color:transparent;z-index:1060;overflow-x:hidden;-webkit-overflow-scrolling:touch}.swal2-container.swal2-top{align-items:flex-start}.swal2-container.swal2-top-left,.swal2-container.swal2-top-start{align-items:flex-start;justify-content:flex-start}.swal2-container.swal2-top-end,.swal2-container.swal2-top-right{align-items:flex-start;justify-content:flex-end}.swal2-container.swal2-center{align-items:center}.swal2-container.swal2-center-left,.swal2-container.swal2-center-start{align-items:center;justify-content:flex-start}.swal2-container.swal2-center-end,.swal2-container.swal2-center-right{align-items:center;justify-content:flex-end}.swal2-container.swal2-bottom{align-items:flex-end}.swal2-container.swal2-bottom-left,.swal2-container.swal2-bottom-start{align-items:flex-end;justify-content:flex-start}.swal2-container.swal2-bottom-end,.swal2-container.swal2-bottom-right{align-items:flex-end;justify-content:flex-end}.swal2-container.swal2-grow-fullscreen>.swal2-modal{display:flex!important;flex:1;align-self:stretch;justify-content:center}.swal2-container.swal2-grow-row>.swal2-modal{display:flex!important;flex:1;align-content:center;justify-content:center}.swal2-container.swal2-grow-column{flex:1;flex-direction:column}.swal2-container.swal2-grow-column.swal2-bottom,.swal2-container.swal2-grow-column.swal2-center,.swal2-container.swal2-grow-column.swal2-top{align-items:center}.swal2-container.swal2-grow-column.swal2-bottom-left,.swal2-container.swal2-grow-column.swal2-bottom-start,.swal2-container.swal2-grow-column.swal2-center-left,.swal2-container.swal2-grow-column.swal2-center-start,.swal2-container.swal2-grow-column.swal2-top-left,.swal2-container.swal2-grow-column.swal2-top-start{align-items:flex-start}.swal2-container.swal2-grow-column.swal2-bottom-end,.swal2-container.swal2-grow-column.swal2-bottom-right,.swal2-container.swal2-grow-column.swal2-center-end,.swal2-container.swal2-grow-column.swal2-center-right,.swal2-container.swal2-grow-column.swal2-top-end,.swal2-container.swal2-grow-column.swal2-top-right{align-items:flex-end}.swal2-container.swal2-grow-column>.swal2-modal{display:flex!important;flex:1;align-content:center;justify-content:center}.swal2-container:not(.swal2-top):not(.swal2-top-start):not(.swal2-top-end):not(.swal2-top-left):not(.swal2-top-right):not(.swal2-center-start):not(.swal2-center-end):not(.swal2-center-left):not(.swal2-center-right):not(.swal2-bottom):not(.swal2-bottom-start):not(.swal2-bottom-end):not(.swal2-bottom-left):not(.swal2-bottom-right):not(.swal2-grow-fullscreen)>.swal2-modal{margin:auto}@media all and (-ms-high-contrast:none),(-ms-high-contrast:active){.swal2-container .swal2-modal{margin:0!important}}.swal2-container.swal2-fade{transition:background-color .1s}.swal2-container.swal2-shown{background-color:rgba(0,0,0,.4)}.swal2-popup{display:none;position:relative;flex-direction:column;justify-content:center;width:32em;max-width:100%;padding:1.25em;border-radius:.3125em;background:#fff;font-family:inherit;font-size:1rem;box-sizing:border-box}.swal2-popup:focus{outline:0}.swal2-popup.swal2-loading{overflow-y:hidden}.swal2-popup .swal2-header{display:flex;flex-direction:column;align-items:center}.swal2-popup .swal2-title{display:block;position:relative;max-width:100%;margin:0 0 .4em;padding:0;color:#595959;font-size:1.875em;font-weight:600;text-align:center;text-transform:none;word-wrap:break-word}.swal2-popup .swal2-actions{flex-wrap:wrap;align-items:center;justify-content:center;margin:1.25em auto 0;z-index:1}.swal2-popup .swal2-actions:not(.swal2-loading) .swal2-styled[disabled]{opacity:.4}.swal2-popup .swal2-actions:not(.swal2-loading) .swal2-styled:hover{background-image:linear-gradient(rgba(0,0,0,.1),rgba(0,0,0,.1))}.swal2-popup .swal2-actions:not(.swal2-loading) .swal2-styled:active{background-image:linear-gradient(rgba(0,0,0,.2),rgba(0,0,0,.2))}.swal2-popup .swal2-actions.swal2-loading .swal2-styled.swal2-confirm{width:2.5em;height:2.5em;margin:.46875em;padding:0;border:.25em solid transparent;border-radius:100%;border-color:transparent;background-color:transparent!important;color:transparent;cursor:default;box-sizing:border-box;-webkit-animation:swal2-rotate-loading 1.5s linear 0s infinite normal;animation:swal2-rotate-loading 1.5s linear 0s infinite normal;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.swal2-popup .swal2-actions.swal2-loading .swal2-styled.swal2-cancel{margin-right:30px;margin-left:30px}.swal2-popup .swal2-actions.swal2-loading :not(.swal2-styled).swal2-confirm::after{display:inline-block;width:15px;height:15px;margin-left:5px;border:3px solid #999;border-radius:50%;border-right-color:transparent;box-shadow:1px 1px 1px #fff;content:'';-webkit-animation:swal2-rotate-loading 1.5s linear 0s infinite normal;animation:swal2-rotate-loading 1.5s linear 0s infinite normal}.swal2-popup .swal2-styled{margin:.3125em;padding:.625em 2em;font-weight:500;box-shadow:none}.swal2-popup .swal2-styled:not([disabled]){cursor:pointer}.swal2-popup .swal2-styled.swal2-confirm{border:0;border-radius:.25em;background:initial;background-color:#3085d6;color:#fff;font-size:1.0625em}.swal2-popup .swal2-styled.swal2-cancel{border:0;border-radius:.25em;background:initial;background-color:#aaa;color:#fff;font-size:1.0625em}.swal2-popup .swal2-styled:focus{outline:0;box-shadow:0 0 0 2px #fff,0 0 0 4px rgba(50,100,150,.4)}.swal2-popup .swal2-styled::-moz-focus-inner{border:0}.swal2-popup .swal2-footer{justify-content:center;margin:1.25em 0 0;padding:1em 0 0;border-top:1px solid #eee;color:#545454;font-size:1em}.swal2-popup .swal2-image{max-width:100%;margin:1.25em auto}.swal2-popup .swal2-close{position:absolute;top:0;right:0;justify-content:center;width:1.2em;height:1.2em;padding:0;transition:color .1s ease-out;border:none;border-radius:0;outline:initial;background:0 0;color:#ccc;font-family:serif;font-size:2.5em;line-height:1.2;cursor:pointer;overflow:hidden}.swal2-popup .swal2-close:hover{-webkit-transform:none;transform:none;color:#f27474}.swal2-popup>.swal2-checkbox,.swal2-popup>.swal2-file,.swal2-popup>.swal2-input,.swal2-popup>.swal2-radio,.swal2-popup>.swal2-select,.swal2-popup>.swal2-textarea{display:none}.swal2-popup .swal2-content{justify-content:center;margin:0;padding:0;color:#545454;font-size:1.125em;font-weight:300;line-height:normal;z-index:1;word-wrap:break-word}.swal2-popup #swal2-content{text-align:center}.swal2-popup .swal2-checkbox,.swal2-popup .swal2-file,.swal2-popup .swal2-input,.swal2-popup .swal2-radio,.swal2-popup .swal2-select,.swal2-popup .swal2-textarea{margin:1em auto}.swal2-popup .swal2-file,.swal2-popup .swal2-input,.swal2-popup .swal2-textarea{width:100%;transition:border-color .3s,box-shadow .3s;border:1px solid #d9d9d9;border-radius:.1875em;font-size:1.125em;box-shadow:inset 0 1px 1px rgba(0,0,0,.06);box-sizing:border-box}.swal2-popup .swal2-file.swal2-inputerror,.swal2-popup .swal2-input.swal2-inputerror,.swal2-popup .swal2-textarea.swal2-inputerror{border-color:#f27474!important;box-shadow:0 0 2px #f27474!important}.swal2-popup .swal2-file:focus,.swal2-popup .swal2-input:focus,.swal2-popup .swal2-textarea:focus{border:1px solid #b4dbed;outline:0;box-shadow:0 0 3px #c4e6f5}.swal2-popup .swal2-file::-webkit-input-placeholder,.swal2-popup .swal2-input::-webkit-input-placeholder,.swal2-popup .swal2-textarea::-webkit-input-placeholder{color:#ccc}.swal2-popup .swal2-file:-ms-input-placeholder,.swal2-popup .swal2-input:-ms-input-placeholder,.swal2-popup .swal2-textarea:-ms-input-placeholder{color:#ccc}.swal2-popup .swal2-file::-ms-input-placeholder,.swal2-popup .swal2-input::-ms-input-placeholder,.swal2-popup .swal2-textarea::-ms-input-placeholder{color:#ccc}.swal2-popup .swal2-file::placeholder,.swal2-popup .swal2-input::placeholder,.swal2-popup .swal2-textarea::placeholder{color:#ccc}.swal2-popup .swal2-range input{width:80%}.swal2-popup .swal2-range output{width:20%;font-weight:600;text-align:center}.swal2-popup .swal2-range input,.swal2-popup .swal2-range output{height:2.625em;margin:1em auto;padding:0;font-size:1.125em;line-height:2.625em}.swal2-popup .swal2-input{height:2.625em;padding:0 .75em}.swal2-popup .swal2-input[type=number]{max-width:10em}.swal2-popup .swal2-file{font-size:1.125em}.swal2-popup .swal2-textarea{height:6.75em;padding:.75em}.swal2-popup .swal2-select{min-width:50%;max-width:100%;padding:.375em .625em;color:#545454;font-size:1.125em}.swal2-popup .swal2-checkbox,.swal2-popup .swal2-radio{align-items:center;justify-content:center}.swal2-popup .swal2-checkbox label,.swal2-popup .swal2-radio label{margin:0 .6em;font-size:1.125em}.swal2-popup .swal2-checkbox input,.swal2-popup .swal2-radio input{margin:0 .4em}.swal2-popup .swal2-validation-message{display:none;align-items:center;justify-content:center;padding:.625em;background:#f0f0f0;color:#666;font-size:1em;font-weight:300;overflow:hidden}.swal2-popup .swal2-validation-message::before{display:inline-block;width:1.5em;min-width:1.5em;height:1.5em;margin:0 .625em;border-radius:50%;background-color:#f27474;color:#fff;font-weight:600;line-height:1.5em;text-align:center;content:'!';zoom:normal}@supports (-ms-accelerator:true){.swal2-range input{width:100%!important}.swal2-range output{display:none}}@media all and (-ms-high-contrast:none),(-ms-high-contrast:active){.swal2-range input{width:100%!important}.swal2-range output{display:none}}@-moz-document url-prefix(){.swal2-close:focus{outline:2px solid rgba(50,100,150,.4)}}.swal2-icon{position:relative;justify-content:center;width:5em;height:5em;margin:1.25em auto 1.875em;border:.25em solid transparent;border-radius:50%;line-height:5em;cursor:default;box-sizing:content-box;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;zoom:normal}.swal2-icon-text{font-size:3.75em}.swal2-icon.swal2-error{border-color:#f27474}.swal2-icon.swal2-error .swal2-x-mark{position:relative;flex-grow:1}.swal2-icon.swal2-error [class^=swal2-x-mark-line]{display:block;position:absolute;top:2.3125em;width:2.9375em;height:.3125em;border-radius:.125em;background-color:#f27474}.swal2-icon.swal2-error [class^=swal2-x-mark-line][class$=left]{left:1.0625em;-webkit-transform:rotate(45deg);transform:rotate(45deg)}.swal2-icon.swal2-error [class^=swal2-x-mark-line][class$=right]{right:1em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}.swal2-icon.swal2-warning{border-color:#facea8;color:#f8bb86}.swal2-icon.swal2-info{border-color:#9de0f6;color:#3fc3ee}.swal2-icon.swal2-question{border-color:#c9dae1;color:#87adbd}.swal2-icon.swal2-success{border-color:#a5dc86}.swal2-icon.swal2-success [class^=swal2-success-circular-line]{position:absolute;width:3.75em;height:7.5em;-webkit-transform:rotate(45deg);transform:rotate(45deg);border-radius:50%}.swal2-icon.swal2-success [class^=swal2-success-circular-line][class$=left]{top:-.4375em;left:-2.0635em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);-webkit-transform-origin:3.75em 3.75em;transform-origin:3.75em 3.75em;border-radius:7.5em 0 0 7.5em}.swal2-icon.swal2-success [class^=swal2-success-circular-line][class$=right]{top:-.6875em;left:1.875em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);-webkit-transform-origin:0 3.75em;transform-origin:0 3.75em;border-radius:0 7.5em 7.5em 0}.swal2-icon.swal2-success .swal2-success-ring{position:absolute;top:-.25em;left:-.25em;width:100%;height:100%;border:.25em solid rgba(165,220,134,.3);border-radius:50%;z-index:2;box-sizing:content-box}.swal2-icon.swal2-success .swal2-success-fix{position:absolute;top:.5em;left:1.625em;width:.4375em;height:5.625em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg);z-index:1}.swal2-icon.swal2-success [class^=swal2-success-line]{display:block;position:absolute;height:.3125em;border-radius:.125em;background-color:#a5dc86;z-index:2}.swal2-icon.swal2-success [class^=swal2-success-line][class$=tip]{top:2.875em;left:.875em;width:1.5625em;-webkit-transform:rotate(45deg);transform:rotate(45deg)}.swal2-icon.swal2-success [class^=swal2-success-line][class$=long]{top:2.375em;right:.5em;width:2.9375em;-webkit-transform:rotate(-45deg);transform:rotate(-45deg)}.swal2-progresssteps{align-items:center;margin:0 0 1.25em;padding:0;font-weight:600}.swal2-progresssteps li{display:inline-block;position:relative}.swal2-progresssteps .swal2-progresscircle{width:2em;height:2em;border-radius:2em;background:#3085d6;color:#fff;line-height:2em;text-align:center;z-index:20}.swal2-progresssteps .swal2-progresscircle:first-child{margin-left:0}.swal2-progresssteps .swal2-progresscircle:last-child{margin-right:0}.swal2-progresssteps .swal2-progresscircle.swal2-activeprogressstep{background:#3085d6}.swal2-progresssteps .swal2-progresscircle.swal2-activeprogressstep~.swal2-progresscircle{background:#add8e6}.swal2-progresssteps .swal2-progresscircle.swal2-activeprogressstep~.swal2-progressline{background:#add8e6}.swal2-progresssteps .swal2-progressline{width:2.5em;height:.4em;margin:0 -1px;background:#3085d6;z-index:10}[class^=swal2]{-webkit-tap-highlight-color:transparent}.swal2-show{-webkit-animation:swal2-show .3s;animation:swal2-show .3s}.swal2-show.swal2-noanimation{-webkit-animation:none;animation:none}.swal2-hide{-webkit-animation:swal2-hide .15s forwards;animation:swal2-hide .15s forwards}.swal2-hide.swal2-noanimation{-webkit-animation:none;animation:none}.swal2-rtl .swal2-close{right:auto;left:0}.swal2-animate-success-icon .swal2-success-line-tip{-webkit-animation:swal2-animate-success-line-tip .75s;animation:swal2-animate-success-line-tip .75s}.swal2-animate-success-icon .swal2-success-line-long{-webkit-animation:swal2-animate-success-line-long .75s;animation:swal2-animate-success-line-long .75s}.swal2-animate-success-icon .swal2-success-circular-line-right{-webkit-animation:swal2-rotate-success-circular-line 4.25s ease-in;animation:swal2-rotate-success-circular-line 4.25s ease-in}.swal2-animate-error-icon{-webkit-animation:swal2-animate-error-icon .5s;animation:swal2-animate-error-icon .5s}.swal2-animate-error-icon .swal2-x-mark{-webkit-animation:swal2-animate-error-x-mark .5s;animation:swal2-animate-error-x-mark .5s}@-webkit-keyframes swal2-rotate-loading{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes swal2-rotate-loading{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@media print{body.swal2-shown:not(.swal2-no-backdrop):not(.swal2-toast-shown){overflow-y:scroll!important}body.swal2-shown:not(.swal2-no-backdrop):not(.swal2-toast-shown)>[aria-hidden=true]{display:none}body.swal2-shown:not(.swal2-no-backdrop):not(.swal2-toast-shown) .swal2-container{position:initial!important}}</style><style type="text/css">.styles__sound_icon___23DuG{
  cursor: pointer;
  display: -webkit-box;
  display: -ms-flexbox;
  display: flex;
}
.styles__sound_icon___23DuG svg{
  width: 2rem;
  height: 2rem;
}
.styles__sound_icon_auto_width___EVA69 svg{
  width: auto;
  height: auto;
}
.styles__sound_icon___23DuG svg path{
  -webkit-transition: fill .5s;
  transition: fill .5s;
}
.styles__sound_active___2_Hr_ svg path{
  fill: #7AC70C;
}</style><style>
      .ejoy-sub-active{
        color: #1296ba !important;
      }
      
      .ejoy-sub-hovered{
        color: #1296ba !important;
      }
      .ejoy-sub-clzz{
        cursor: pointer;
        
        lineHeight: 1.2;
          font-size: 28px;
          color: #FFCC00; background: rgba(17, 17, 17, 0.7);
        
      }
      .ejoy-sub-clzz:hover{
        color: #1296ba !important;
      }
      .ej-trans-sub{
        position: absolute;
        width: 100%;
        display: flex;
        justify-content: center;
        align-items: center;
        z-index: 9999999;
        cursor: move;
      }
      .ej-trans-sub > span{
        color: #3CF9ED;
        font-size: 18px;
        text-align: center;
        padding: 0 16px;
        line-height: 1.5;
        background: rgba(32, 26, 25, 0.8);
        // text-shadow: 0px 1px 4px black;
        padding: 0 8px;
        
        lineHeight: 1.2;
        font-size: 16px;
        color: #0CB1C7; background: rgba(67, 65, 65, 0.7);
      
      }
      .ej-full-screen-video{
        position: absolute;
        width: 30px;
        height: 30px;
        top: 30px;
        right: 10px;
        display: flex;
        justify-content: center;
        align-items: center;
        z-index: 99999999;
        cursor: pointer;
      }
      .ej-main-sub{
        position: absolute;
        width: 100%;
        display: flex;
        justify-content: center;
        align-items: center;
        z-index: 99999999;
        cursor: move;
        padding: 0 8px;
      }
      .ej-main-sub > span{
        color: white;
        font-size: 20px;
        line-height: 1.5;
        text-align: center;
        background: rgba(32, 26, 25, 0.8);
        padding: 2px 8px;
        
        lineHeight: 1.2;
          font-size: 28px;
          color: #FFCC00; background: rgba(17, 17, 17, 0.7);
        
      }

      .ej-main-sub .ejoy-sub-clzz{
        background: transparent !important
      }

      .tran-subtitle > span{
        cursor: pointer;
        padding-left: 10px;
        top: 2px;
        position: relative;
      }

      .tran-subtitle > span > span{
        position: absolute;
        top: -170%;
        background: rgba(0,0,0,0.5);
        font-size: 13px;
        line-height: 20px;
        padding: 2px 8px;
        color: white;
        display: none;
        border-radius: 4px;
        white-space: nowrap;
        left: -50%;
        font-weight: normal;
      }

      .viewPopupPro {
        z-index: 2147483647;
        cursor: auto;
        position: absolute;
        z-index: 2147483647;
        background: #111111;
        transition: opacity 1s;
        width: 172px;
        height: 66px;
        opacity: 1;
        border-radius: 6px;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
      }

      .titlePopupPro {
        font-style: normal;
        font-weight: 400;
        font-size: 10px;
        line-height: 12px;
        color: #E5E5E5;
        text-shadow: 0px 3px 3px rgba(0, 0, 0, 0.25);
      }
  
      .viewGoPro {
        background: #FFCC00;
        border-radius: 72.6257px;
        display: flex;
        justify-content: center;
        align-items: center;
        margin-top: 8px;
        padding-left: 10px;
        cursor: pointer;
  
      }

      .viewGoPro svg {
        pointer-events: none;
      }
      
      .textGoPro {
        font-style: normal;
        font-weight: 600;
        font-size: 10px;
        line-height: 12px;
        pointer-events: none;
        text-align: center;
        color: #FFFFFF;
        padding: 4px 14px 4px 4px;
      }

      .viewPopupPro{
        top: auto !important;
        bottom: 15px !important;
      }

      .view-icon-copy-main-sub:hover > span,
      .view-icon-edit-sub:hover > span,
      .view-icon-exit-full-sub:hover > span,
      .view-icon-full-sub:hover > span,
      .iconCrownGoPro:hover > span,
      .view-icon-copy-tran-sub:hover > span {
        display: block;
      }

      .iconCrownGoPro{
        padding-left: 0px !important;
        padding-right: 8px !important;
      }
      .iconCrownGoPro svg{
        width: 17px;
        height: 17px;
      }
      .view-icon-full-sub, .view-icon-exit-full-sub {
        display: flex;
      }

      .view-icon-full-sub > svg, .view-icon-exit-full-sub > svg {
        pointer-events: none;
      }

      .tran-subtitle > span > svg{
        width: 16px;
        height: 16px;
        pointer-events: none;
        display: inline-flex !important;
        vertical-align: baseline !important;
      }
      
      .view-icon-copy-main-sub > svg{
        pointer-events: none;
        color: #FFCC00
      }

      .iconCrownGoPro{
        padding-left: 0 !important;
        padding-right: 8px !important;
      }
      .view-icon-copy-tran-sub > svg{
        pointer-events: none;
        color: #0CB1C7
      }

      </style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><div class="l c"><div class="l m n o c" style="transform: translateY(-57px);"><div class="am q r s ds u dt w du i d y z"><a class="dw ag dx be ak b am an ao ap aq ar as at s u w i d q dy z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F30d63e222563&amp;%7Efeature=LiOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="dv"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" rel="noopener follow" href="https://medium.com/?source=---two_column_layout_nav----------------------------------"><svg viewBox="0 0 1043.63 592.71" class="dz ea"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search" value=""></div></div></div><div class="h k w eb ec"><div class="ed ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/new-story?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dw ee ef ab q eg eh"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="dv l">Write</div></div></a></div></div><div class="k j i d"><div class="ed ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" rel="noopener follow" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------"><div class="be b bf z dw ee ef ab q eg eh"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="ed ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerNotificationButton" rel="noopener follow" href="https://medium.com/me/notifications?source=---two_column_layout_nav----------------------------------"><div class="be b bf z dw ee ef ab q eg eh"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Notifications"><path d="M15 18.5a3 3 0 1 1-6 0" stroke="currentColor" stroke-linecap="round"></path><path d="M5.5 10.53V9a6.5 6.5 0 0 1 13 0v1.53c0 1.42.56 2.78 1.57 3.79l.03.03c.26.26.4.6.4.97v2.93c0 .14-.11.25-.25.25H3.75a.25.25 0 0 1-.25-.25v-2.93c0-.37.14-.71.4-.97l.03-.03c1-1 1.57-2.37 1.57-3.79z" stroke="currentColor" stroke-linejoin="round"></path></svg></div></a></div><div class="l" aria-hidden="false"><button class="ax ei am ab q ao ej ek el" aria-label="user options menu" data-testid="headerUserIcon"><div class="l ee"><div class="l ee"><img alt="Vonhuy" class="l eq bx by bz cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/0_oR99AaaRsUWrB2B5.png" width="32" height="32" loading="lazy"><div class="em bx l by bz eo n ax ep"></div></div></div></button></div></div></div><div class="l"><div class="bw"><div class="it gx t iv gy v tu gz du tv ha tw tx hb ty ab ee"><div class="tz gx ua gy gz ha hb ab ee"><div class="ub uc ud ue uf ug uh ab"><svg width="64" height="64" viewBox="0 0 64 64" fill="none" role="presentation" aria-hidden="true" focusable="false" class="ui uj"><path d="M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z" fill="#FFC017"></path></svg></div><p class="be b bf z bj"><span class="qw hu">Get unlimited access to the best of Medium for less than $1/week.</span><div class="bl"><a class="af ag ah ai aj ak al am an ao ap aq ar pi bl" rel="noopener follow" href="https://medium.com/plans?source=upgrade_membership---post_top_nav_upsell----------------------------------"><div class="j i d"><span class="tb uk fn ul um un uo">Become a member</span></div><div class="h k"><span class="tb">Become a member</span></div></a></div></p></div><div class="up uq ur us ut l uu"><div class="h k"><div class="l ee n uv"><button class="af ag ah ai aj ak al am an ao ap aq ar as at ab" data-testid="close-button" aria-label="close"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="ef dw eh eg"><path d="M5 5l7 7m7 7l-7-7m0 0l7-7m-7 7l-7 7" stroke="currentColor" stroke-linecap="round"></path></svg></button></div></div><div class="j i d"><div class="l ee n uv"><button class="af ag ah ai aj ak al am an ao ap aq ar as at ab ee uk fn uw ux uy uz" data-testid="close-button" aria-label="close"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="ef dw eh eg"><path d="M5 5l7 7m7 7l-7-7m0 0l7-7m-7 7l-7 7" stroke="currentColor" stroke-linecap="round"></path></svg></button></div></div></div></div></div><div class="rm" role="dialog" aria-modal="true" tabindex="-1"><div class="va vb bg dy vc vd ve ao vf fj vg" aria-hidden="true" role="presentation"></div><div class="vh vc vi vj vk va dy eq vl vm vn kw vo vp vq vr vs vt vu vv vw" aria-hidden="true"></div></div><div class="er es et eu ev l"><div class="ab ca"><div class="ch bg ew ex ey ez"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="eo ff fg fh fi fj"></div><div class="fk fl fm fn fo"><div class="ab ca"><div class="ch bg ew ex ey ez"><div><h1 id="bd62" class="pw-post-title fp fq fr be fs ft fu fv fw fx fy fz ga gb gc gd ge gf gg gh gi gj gk gl gm gn go gp gq gr bj" data-testid="storyTitle" data-selectable-paragraph="">Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI</h1><div class="gs gt gu gv gw"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="gx gy gz ha hb ab"><div><div class="ab hc"><a rel="noopener follow" href="https://medium.com/@nayakpplaban?source=post_page-----30d63e222563--------------------------------"><div><div class="bl" aria-hidden="false" aria-describedby="1" aria-labelledby="1"><div class="l hd he bx hf hg"><div class="l ee"><img alt="Plaban Nayak" class="l eq bx dc dd cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_oFXd8MlaJnMFie2YKsWB_Q.jpg" width="44" height="44" loading="lazy" data-testid="authorPhoto"><div class="hh bx l dc dd eo n hi ep"></div></div></div></div></div></a><a href="https://medium.com/the-ai-forum?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><div class="hj ab ee"><div><div class="bl" aria-hidden="false" aria-describedby="2" aria-labelledby="2"><div class="l hk hl bx hf hm"><div class="l ee"><img alt="The AI Forum" class="l eq bx bq hn cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_p9oOISlQYwVpgPGEaGPuDA.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto"><div class="hh bx l bq hn eo n hi ep"></div></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="ho ab q"><div class="ab q hp"><div class="ab q"><div><div class="bl" aria-hidden="false" aria-describedby="3" aria-labelledby="3"><p class="be b hq hr bj"><a class="af ag ah ai aj ak al am an ao ap aq ar hs" data-testid="authorName" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=post_page-----30d63e222563--------------------------------">Plaban Nayak</a></p></div></div></div><span class="ht hu" aria-hidden="true"><span class="be b bf z dw">·</span></span><p class="be b hq hr dw"><button class="hv hw ah ai aj ak al am an ao ap aq ar hx hy hz">Follow</button></p></div></div></span></div></div><div class="l ia"><span class="be b bf z dw"><div class="ab cm ib ic id"><div class="ie if ab"><div class="be b bf z dw ab ig"><span class="ih l ia">Published in</span><div><div class="l" aria-hidden="false" aria-describedby="4" aria-labelledby="4"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" data-testid="publicationName" href="https://medium.com/the-ai-forum?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><p class="be b bf z ii ij ik il im in io ip bj">The AI Forum</p></a></div></div></div><div class="h k"><span class="ht hu" aria-hidden="true"><span class="be b bf z dw">·</span></span></div></div><span class="be b bf z dw"><div class="ab ae"><span data-testid="storyReadTime">26 min read</span><div class="iq ir l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dw">·</span></span></div><span data-testid="storyPublishDate">Mar 3, 2024</span></div></span></div></span></div></div></div><div class="ab co is it iu iv iw ix iy iz ja jb jc jd je jf jg jh"><div class="h k w eb ec q"><div class="jx l"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="56" aria-labelledby="56"><button class="kd ao kf vx vy kj am kk kl km kc" data-testid="headerClapButton"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="57" aria-labelledby="57"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">206<span class="l h g f rr rs"></span></button></p></div></div></div></div></div><div><div class="bl" aria-hidden="false" aria-describedby="5" aria-labelledby="5"><button class="ao kd kw kx ab q ef ky kz" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="kv"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count ku kv">2</span></p></button></div></div></div><div class="ab q ji jj jk jl jm jn jo jp jq jr js jt ju jv jw"><div class="la k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false" aria-describedby="6" aria-labelledby="6"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ef ah ai aj ak al lb an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="eq lg cm"><div class="l ae"><div class="ab ca"><div class="lh li lj lk ll lm ch bg"><div class="ab"><div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/plans?dimension=post_audio_button&amp;postId=30d63e222563&amp;source=upgrade_membership---post_audio_button----------------------------------"><div><div class="bl" aria-hidden="false" aria-describedby="24" aria-labelledby="24"><button aria-label="Listen" data-testid="audioPlayButton" class="af ef ah ai aj ak al lb an ao ap hx ln lo kz lp lq lr ls lt s lu lv lw lx ly lz ma u mb mc md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dw">Listen</p></div></button></div></div></a></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false" aria-describedby="8" aria-labelledby="8"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ef ah ai aj ak al lb an ao ap hx ln lo kz lp lq lr ls lt s lu lv lw lx ly lz ma u mb mc md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dw">Share</p></div></button></div></div></div><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="62" aria-labelledby="62"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ef ah ai aj ak al lb an ao ap hx ln lo kz lp lq lr ls lt s lu lv lw lx ly lz ma u mb mc md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dw">More</p></div></button></div></div></div></div></div></div></div></div></div></div><figure class="mh mi mj mk ml mm me mf paragraph-image"><div role="button" tabindex="0" class="mn mo ee mp bg mq"><div class="me mf mg"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg lm mr c" width="700" height="498" loading="eager" role="presentation" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_ZJZu7tHxt3wdrfqdIjr9gA.jpg"></picture></div></div><figcaption class="ms mt mu me mf mv mw be b bf z dw" data-selectable-paragraph="">Corrective RAG workflow</figcaption></figure><h1 id="c690" class="mx my fr be mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu bj" data-selectable-paragraph="">What happens in Native RAG ?</h1><p id="8e00" class="pw-post-body-paragraph nv nw fr nx b ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os fk bj" data-selectable-paragraph="">Preproduction Setup:</p><ol class=""><li id="04a2" class="nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os oy oz pa bj" data-selectable-paragraph="">The Knowledge Source is loaded and formatted using Langchain Orchestration Framework.</li><li id="16ca" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph="">The Formatted Documents is then split into semantically relevant chunks.</li><li id="11f4" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph="">Convert the chunks into vector embeddings using an Embedding Model.</li><li id="d63b" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph="">Load the Vector Embeddings into the VectorStore.</li></ol><p id="fd18" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Production Setup:</p><ol class=""><li id="2f61" class="nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">Set up the LLM for Response Synthesis.</em></li><li id="7af7" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">User asks a query.</em></li><li id="0fe5" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">The query is converted into vector embeddings uisng and Embedding Model.</em></li><li id="4857" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">This embedding is then matched against the Knowledge Source embeddings stored in the VectorStore.</em></li><li id="f2b2" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">Find top-k similar documents matching the user query.</em></li><li id="84a4" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">Postprocess and aggregate matched documents retrieved into a context .</em></li><li id="2a71" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">Generate a prompt based on the user query and context and pass it to the LLM.</em></li><li id="83b9" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">The LLM then synthesizes the response based on the prompt /instruction provided.</em></li></ol><h1 id="1bd9" class="mx my fr be mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu bj" data-selectable-paragraph="">What are the benefits of RAG?</h1><p id="2360" class="pw-post-body-paragraph nv nw fr nx b ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os fk bj" data-selectable-paragraph="">There are several important advantages to the RAG approach:</p><ul class=""><li id="567c" class="nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os ph oz pa bj" data-selectable-paragraph=""><em class="pg">RAG makes sure that an LLM’s response isn’t based just on old, stagnant training data. Instead, the model gets its answers from current external data sources.</em></li><li id="935e" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os ph oz pa bj" data-selectable-paragraph=""><em class="pg">RAG aims to reduce the possibility of reacting with false or misleading information (sometimes referred to as hallucinations) by basing the LLM model’s output on pertinent, outside knowledge. Citations to the original sources can be included in the outputs, enabling human verification.</em></li><li id="d137" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os ph oz pa bj" data-selectable-paragraph=""><em class="pg">By utilizing RAG, the LLM can deliver contextually appropriate answers that are customized to an organization’s proprietary or domain-specific data.</em></li></ul><p id="5896" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">In contrast to alternative methods of integrating domain-specific data into LLM customization, RAG is simple and cost-effective. Organizations can deploy RAG without needing to customize the model. This is especially beneficial when models need to be updated frequently with new data.</p><h1 id="428c" class="mx my fr be mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu bj" data-selectable-paragraph="">What is Corrective RAG ?</h1><p id="d1c2" class="pw-post-body-paragraph nv nw fr nx b ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os fk bj" data-selectable-paragraph="">Corrective RAG is a comprehensive framework that combines retrieval evaluation, corrective actions, web searches, and generative model integration to enhance the accuracy, reliability, and robustness of text generation models by ensuring the utilization of accurate and relevant knowledge,</p><p id="d372" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">In simple terms, Corrective RAG is the method used to grade documents based on their relevance to the data source. If the data source is related to the question, the process proceeds to generation. Otherwise, the framework seeks additional data sources and utilizes web search to supplement retrieval. But in this example instead of seeking additional data sources we will simply discarded the non-relevant data sources.</p><h1 id="f70d" class="mx my fr be mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu bj" data-selectable-paragraph="">Technology Stack</h1><ul class=""><li id="991c" class="nv nw fr nx b ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os ph oz pa bj" data-selectable-paragraph=""><a class="af pi" href="https://python.langchain.com/docs/get_started/introduction" rel="noopener ugc nofollow" target="_blank">Langchain</a> : Orchestration framework to develop LLM Applications</li><li id="8796" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os ph oz pa bj" data-selectable-paragraph=""><a class="af pi" href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta" rel="noopener ugc nofollow" target="_blank">Zephyr-7B-beta</a> : LLM</li><li id="b05d" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os ph oz pa bj" data-selectable-paragraph=""><a class="af pi" href="https://platform.openai.com/docs/introduction" rel="noopener ugc nofollow" target="_blank">OpenAI</a> : To grade the retrieved contexts</li><li id="2b85" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os ph oz pa bj" data-selectable-paragraph=""><a class="af pi" href="https://github.com/bclavie/RAGatouille" rel="noopener ugc nofollow" target="_blank">ragatouille</a> :RAGatouille focuses on making ColBERT</li></ul><h1 id="3a70" class="mx my fr be mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu bj" data-selectable-paragraph="">Code Implementation</h1><p id="716d" class="pw-post-body-paragraph nv nw fr nx b ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os fk bj" data-selectable-paragraph="">Install required dependencies</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="5aa3" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">pip install -q transformers <br>pip install -q accelerate <br>pip install -q bitsandbytes <br>pip install -q langchain <br>pip install -q sentence-transformers <br>pip install -q chromadb openpyxl <br>pip install -q ragatouille <br>pip install -q langchain_openai<br>pip install -q datasets</span></pre><p id="8da2" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Import Required Dependencies</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="1358" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> tqdm.notebook <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>, <span class="hljs-type">List</span>, <span class="hljs-type">Tuple</span><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>pd.set_option(<span class="hljs-string">"display.max_colwidth"</span>, <span class="hljs-literal">None</span>)  <span class="hljs-comment"># this will be helpful when visualizing retriever outputs</span></span></pre><p id="8b15" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Load the Knowledge Source</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="e110" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">import</span> datasets<br><br>ds = datasets.load_dataset(<span class="hljs-string">"m-ric/huggingface_doc"</span>, split=<span class="hljs-string">"train"</span>)</span></pre><p id="5cdd" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Format the datasets into Langchain Document Schema</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="1267" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain.docstore.document <span class="hljs-keyword">import</span> Document <span class="hljs-keyword">as</span> LangchainDocument<br><br>RAW_KNOWLEDGE_BASE = [<br>    LangchainDocument(page_content=doc[<span class="hljs-string">"text"</span>], metadata={<span class="hljs-string">"source"</span>: doc[<span class="hljs-string">"source"</span>]}) <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> tqdm(ds)<br>]<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(RAW_KNOWLEDGE_BASE))<br><span class="hljs-built_in">print</span>(RAW_KNOWLEDGE_BASE[<span class="hljs-number">1</span>].page_content)<br><span class="hljs-built_in">print</span>(RAW_KNOWLEDGE_BASE[<span class="hljs-number">1</span>].metadata)</span></pre><p id="a9a1" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Split the documents into chunks</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="bcd7" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br><br><span class="hljs-comment"># We use a hierarchical list of separators specifically tailored for splitting Markdown documents</span><br><span class="hljs-comment"># This list is taken from LangChain's MarkdownTextSplitter class.</span><br>MARKDOWN_SEPARATORS = [<br>    <span class="hljs-string">"\n#{1,6} "</span>,<br>    <span class="hljs-string">"```\n"</span>,<br>    <span class="hljs-string">"\n\\*\\*\\*+\n"</span>,<br>    <span class="hljs-string">"\n---+\n"</span>,<br>    <span class="hljs-string">"\n___+\n"</span>,<br>    <span class="hljs-string">"\n\n"</span>,<br>    <span class="hljs-string">"\n"</span>,<br>    <span class="hljs-string">" "</span>,<br>    <span class="hljs-string">""</span>,<br>]<br><br>text_splitter = RecursiveCharacterTextSplitter(<br>    chunk_size=<span class="hljs-number">1000</span>,  <span class="hljs-comment"># the maximum number of characters in a chunk: we selected this value arbitrarily</span><br>    chunk_overlap=<span class="hljs-number">100</span>,  <span class="hljs-comment"># the number of characters to overlap between chunks</span><br>    add_start_index=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># If `True`, includes chunk's start index in metadata</span><br>    strip_whitespace=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># If `True`, strips whitespace from the start and end of every document</span><br>    separators=MARKDOWN_SEPARATORS,<br>)<br><br>docs_processed = []<br><span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> RAW_KNOWLEDGE_BASE:<br>    docs_processed += text_splitter.split_documents([doc])</span></pre><p id="c105" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Setup Embedding Model</p><p id="4885" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph=""><em class="pg">We also have to keep in mind that when embedding documents, we will use an embedding model that has accepts a certain maximum sequence length max_seq_length. So we should make sure that our chunk sizes are below this limit, because any longer chunk will be truncated before processing, thus losing relevancy.</em></p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="5301" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer<br><br><span class="hljs-comment"># To get the value of the max sequence_length, we will query the underlying `SentenceTransformer` object used in the RecursiveCharacterTextSplitter.</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Model's maximum sequence length: <span class="hljs-subst">{SentenceTransformer(<span class="hljs-string">'thenlper/gte-small'</span>).max_seq_length}</span>"</span>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">"thenlper/gte-small"</span>)<br>lengths = [<span class="hljs-built_in">len</span>(tokenizer.encode(doc.page_content)) <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> tqdm(docs_processed)]<br><br><span class="hljs-comment"># Plot the distrubution of document lengths, counted as the number of tokens</span><br>fig = pd.Series(lengths).hist()<br>plt.title(<span class="hljs-string">"Distribution of document lengths in the knowledge base (in count of tokens)"</span>)<br>plt.show()</span></pre><figure class="pj pk pl pm pn mm me mf paragraph-image"><div class="me mf px"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*0t0nleN1NH9_tpSsZgSAlw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*0t0nleN1NH9_tpSsZgSAlw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*0t0nleN1NH9_tpSsZgSAlw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*0t0nleN1NH9_tpSsZgSAlw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*0t0nleN1NH9_tpSsZgSAlw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*0t0nleN1NH9_tpSsZgSAlw.png 1100w, https://miro.medium.com/v2/resize:fit:1308/format:webp/1*0t0nleN1NH9_tpSsZgSAlw.png 1308w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 654px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*0t0nleN1NH9_tpSsZgSAlw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*0t0nleN1NH9_tpSsZgSAlw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*0t0nleN1NH9_tpSsZgSAlw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*0t0nleN1NH9_tpSsZgSAlw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*0t0nleN1NH9_tpSsZgSAlw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*0t0nleN1NH9_tpSsZgSAlw.png 1100w, https://miro.medium.com/v2/resize:fit:1308/1*0t0nleN1NH9_tpSsZgSAlw.png 1308w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 654px"><img alt="" class="bg lm mr c" width="654" height="435" loading="lazy" role="presentation" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_0t0nleN1NH9_tpSsZgSAlw.png"></picture></div></figure><p id="21bf" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph=""><em class="pg">As you can see, the chunk lengths are not aligned with our limit of 512 tokens, and some documents are above the limit, thus some part of them will be lost in truncation!</em></p><p id="500e" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph=""><em class="pg">So we should change the RecursiveCharacterTextSplitter class to count length in number of tokens instead of number of characters. Then we can choose a specific chunk size, here we would choose a lower threshold than 512: smaller documents could allow the split to focus more on specific ideas. But too small chunks would split sentences in half, thus losing meaning again: the proper tuning is a matter of balance.</em></p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="1b08" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>EMBEDDING_MODEL_NAME = <span class="hljs-string">"thenlper/gte-small"</span><br>chunk_size = <span class="hljs-number">512</span><br><span class="hljs-comment">#</span><br>text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(<br>        AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME),<br>        chunk_size=chunk_size,<br>        chunk_overlap=<span class="hljs-built_in">int</span>(chunk_size / <span class="hljs-number">10</span>),<br>        add_start_index=<span class="hljs-literal">True</span>,<br>        strip_whitespace=<span class="hljs-literal">True</span>,<br>        separators=MARKDOWN_SEPARATORS,<br>    )<br><span class="hljs-comment">#</span><br>docs_processed = []<br><span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> RAW_KNOWLEDGE_BASE:<br>  docs_processed += text_splitter.split_documents([doc])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(docs_processed)<span class="hljs-comment">#19983</span></span></pre><p id="8f43" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">visualize the chunk sizes we would have in tokens from a common model</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="88f4" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)<br>lengths = [<span class="hljs-built_in">len</span>(tokenizer.encode(doc.page_content)) <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> tqdm(docs_processed)]<br>fig = pd.Series(lengths).hist()<br>plt.title(<span class="hljs-string">"Distribution of document lengths in the knowledge base (in count of tokens)"</span>)<br>plt.show()</span></pre><figure class="pj pk pl pm pn mm me mf paragraph-image"><div class="me mf px"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*gdQHD2x7i31OFHFe5xvLrQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*gdQHD2x7i31OFHFe5xvLrQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*gdQHD2x7i31OFHFe5xvLrQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*gdQHD2x7i31OFHFe5xvLrQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*gdQHD2x7i31OFHFe5xvLrQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*gdQHD2x7i31OFHFe5xvLrQ.png 1100w, https://miro.medium.com/v2/resize:fit:1308/format:webp/1*gdQHD2x7i31OFHFe5xvLrQ.png 1308w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 654px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*gdQHD2x7i31OFHFe5xvLrQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*gdQHD2x7i31OFHFe5xvLrQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*gdQHD2x7i31OFHFe5xvLrQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*gdQHD2x7i31OFHFe5xvLrQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*gdQHD2x7i31OFHFe5xvLrQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*gdQHD2x7i31OFHFe5xvLrQ.png 1100w, https://miro.medium.com/v2/resize:fit:1308/1*gdQHD2x7i31OFHFe5xvLrQ.png 1308w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 654px"><img alt="" class="bg lm mr c" width="654" height="435" loading="lazy" role="presentation" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_gdQHD2x7i31OFHFe5xvLrQ.png"></picture></div></figure><p id="3d43" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Setup VectorStore</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="af17" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive<br>drive.mount(<span class="hljs-string">'/content/drive'</span>)<br><span class="hljs-comment">#</span><br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain_community.embeddings <span class="hljs-keyword">import</span> HuggingFaceEmbeddings<br><span class="hljs-keyword">from</span> langchain_community.vectorstores.utils <span class="hljs-keyword">import</span> DistanceStrategy<br><br>embedding_model = HuggingFaceEmbeddings(<br>    model_name=EMBEDDING_MODEL_NAME,<br>    multi_process=<span class="hljs-literal">True</span>,<br>    model_kwargs={<span class="hljs-string">"device"</span>: <span class="hljs-string">"cuda"</span>},<br>    encode_kwargs={<span class="hljs-string">"normalize_embeddings"</span>: <span class="hljs-literal">True</span>},  <span class="hljs-comment"># set True for cosine similarity</span><br>)<br><br>KNOWLEDGE_VECTOR_DATABASE = Chroma.from_documents(docs_processed,<br>                                                  embedding_model,<br>                                                  persist_directory=<span class="hljs-string">"/content/drive/MyDrive/CRAG"</span>,<br>                                                  collection_name=<span class="hljs-string">"crag"</span>)<br><span class="hljs-comment">#</span><br>KNOWLEDGE_VECTOR_DATABASE.persist()<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(KNOWLEDGE_VECTOR_DATABASE.get()[<span class="hljs-string">'documents'</span>]))</span></pre><p id="5391" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph=""><em class="pg">According to the documentation </em><a class="af pi" href="https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fdocs.trychroma.com%2Fusage-guide" rel="noopener ugc nofollow" target="_blank"><em class="pg">https://docs.trychroma.com/usage-guide</em></a><em class="pg"> embeddings are excluded by default for performance:</em></p><p id="5a16" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph=""><em class="pg">When using get or query you can use the include parameter to specify which data you want returned — any of embeddings, documents, metadatas, and for query, distances. By default, Chroma will return the documents, metadatas and in the case of query, the distances of the results. embeddings are excluded by default for performance and the ids are always returned.</em></p><p id="1443" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph=""><em class="pg">You can include the embeddings when using get as followed:</em></p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="4a26" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">print</span>(collection.<span class="hljs-title.function.invoke">get</span>(<span class="hljs-keyword">include</span>=[<span class="hljs-string">'embeddings'</span>, <span class="hljs-string">'documents'</span>, <span class="hljs-string">'metadatas'</span>]))</span></pre><p id="7998" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Check if the embeddings are retrieved based on user query</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="ed08" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">user_query = <span class="hljs-string">"How to create a pipeline object?"</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f"\nStarting retrieval for <span class="hljs-subst">{user_query=}</span>..."</span>)<br>retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=<span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"\n==================================Top document=================================="</span>)<br><span class="hljs-built_in">print</span>(retrieved_docs[<span class="hljs-number">1</span>].page_content)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">"==================================Metadata=================================="</span>)<br><span class="hljs-built_in">print</span>(retrieved_docs[<span class="hljs-number">1</span>].metadata)</span></pre><p id="9b77" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Setup the LLM</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="de56" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> HuggingFacePipeline<br><br>READER_MODEL_NAME = <span class="hljs-string">"HuggingFaceH4/zephyr-7b-beta"</span><br><br>bnb_config = BitsAndBytesConfig(<br>    load_in_4bit=<span class="hljs-literal">True</span>,<br>    bnb_4bit_use_double_quant=<span class="hljs-literal">True</span>,<br>    bnb_4bit_quant_type=<span class="hljs-string">"nf4"</span>,<br>    bnb_4bit_compute_dtype=torch.bfloat16,<br>)<br>model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config)<br>tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)<br><br>READER_LLM = pipeline(<br>    model=model,<br>    tokenizer=tokenizer,<br>    task=<span class="hljs-string">"text-generation"</span>,<br>    do_sample=<span class="hljs-literal">True</span>,<br>    temperature=<span class="hljs-number">0.2</span>,<br>    repetition_penalty=<span class="hljs-number">1.1</span>,<br>    return_full_text=<span class="hljs-literal">False</span>,<br>    max_new_tokens=<span class="hljs-number">500</span>,<br>)<br><span class="hljs-comment">#</span><br><br>llm = HuggingFacePipeline(pipeline=READER_LLM)</span></pre><p id="8e91" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Create a Prompt</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="bf71" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">prompt_in_chat_format = [<br>    {<br>        <span class="hljs-string">"role"</span>: <span class="hljs-string">"system"</span>,<br>        <span class="hljs-string">"content"</span>: <span class="hljs-string">"""Using the information contained in the context,<br>give a comprehensive answer to the question.<br>Respond only to the question asked, response should be concise and relevant to the question.<br>Provide the number of the source document when relevant.<br>If the answer cannot be deduced from the context, do not give an answer."""</span>,<br>    },<br>    {<br>        <span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>,<br>        <span class="hljs-string">"content"</span>: <span class="hljs-string">"""Context:<br>{context}<br>---<br>Now here is the question you need to answer.<br><br>Question: {question}"""</span>,<br>    },<br>]<br>RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(<br>    prompt_in_chat_format, tokenize=<span class="hljs-literal">False</span>, add_generation_prompt=<span class="hljs-literal">True</span><br>)<br><span class="hljs-built_in">print</span>(RAG_PROMPT_TEMPLATE)</span></pre><pre class="py po pp pq bo pr ba bj"><span id="d4ee" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">&lt;|system|&gt;<br>Using the information contained in the context,<br>give a comprehensive answer to the question.<br>Respond only to the question asked, response should be concise and relevant to the question.<br>Provide the number of the source document when relevant.<br>If the answer cannot be deduced from the context, do not give an answer.&lt;/s&gt;<br>&lt;|user|&gt;<br>Context:<br>{context}<br>---<br>Now here is the question you need to answer.<br><br>Question: {question}&lt;/s&gt;<br>&lt;|assistant|&gt;</span></pre><pre class="py po pp pq bo pr ba bj"><span id="d0a0" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">retrieved_docs_text = [doc.page_content <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> retrieved_docs]  <span class="hljs-comment"># we only need the text of the documents</span><br>context = <span class="hljs-string">"\nExtracted documents:\n"</span><br>context += <span class="hljs-string">""</span>.join([<span class="hljs-string">f"Document <span class="hljs-subst">{<span class="hljs-built_in">str</span>(i)}</span>:::\n"</span> + doc <span class="hljs-keyword">for</span> i, doc <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(retrieved_docs_text)])<br><br>final_prompt = RAG_PROMPT_TEMPLATE.<span class="hljs-built_in">format</span>(question=<span class="hljs-string">"How to create a pipeline object?"</span>, context=context)<br><br><span class="hljs-built_in">print</span>(final_prompt)</span></pre><pre class="py po pp pq bo pr ba bj"><span id="0c72" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">&lt;|system|&gt;<br>Using the information contained in the context,<br>give a comprehensive answer to the question.<br>Respond only to the question asked, response should be concise and relevant to the question.<br>Provide the number of the source document when relevant.<br>If the answer cannot be deduced from the context, do not give an answer.&lt;/s&gt;<br>&lt;|user|&gt;<br>Context:<br><br>Extracted documents:<br>Document 0:::<br>```<br><br>## Available Pipelines:Document 1:::<br>```<br>&lt;/tf&gt;<br>&lt;/frameworkcontent&gt;<br><br>## Pipeline<br><br>&lt;Youtube id="tiZFewofSLM"/&gt;<br><br>The [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:<br><br>&lt;Tip&gt;<br><br>For a complete list of available tasks, check out the [pipeline API reference](./main_classes/pipelines).<br><br>&lt;/Tip&gt;Document 2:::<br>!--Copyright 2020 The HuggingFace Team. All rights reserved.<br><br>Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with<br>the License. You may obtain a copy of the License at<br><br>http://www.apache.org/licenses/LICENSE-2.0<br><br>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on<br>an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the<br><br>⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be<br>rendered properly in your Markdown viewer.<br><br>--&gt;<br><br># How to create a custom pipeline?<br><br>In this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co/models) or add it to the<br>🤗 Transformers library.<br><br>First and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,<br>dictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible<br>as it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the<br>pipeline (`preprocess`).<br><br>Then define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of<br>`postprocess` method.<br><br>Start by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,<br>`_forward`, `postprocess`, and `_sanitize_parameters`.<br><br><br>```python<br>from transformers import PipelineDocument 3:::<br>- **Self-contained**: A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the [`DiffusionPipeline` class](https://github.com/huggingface/diffusers/blob/5cbed8e0d157f65d3ddc2420dfd09f2df630e978/src/diffusers/pipeline_utils.py#L56) or be directly attached to the model and scheduler components of the pipeline.<br>- **Easy-to-use**: Pipelines should be extremely easy to use - one should be able to load the pipeline and<br>use it for its designated task, *e.g.* text-to-image generation, in just a couple of lines of code. Most<br>logic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `__call__` method.<br>- **Easy-to-tweak**: Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part –from pre-processing to diffusing to post-processing– can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our [community-examples](https://github.com/huggingface/diffusers/tree/main/examples/community). If you feel that an important pipeline should be part of the official pipelines but isn't, a contribution to the [official pipelines](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines) would be even better.Document 4:::<br>```<br><br>## Pipeline<br><br>You can also push an entire pipeline with all it's components to the Hub. For example, initialize the components of a [`StableDiffusionPipeline`] with the parameters you want:<br><br>```py<br>from diffusers import (<br>    UNet2DConditionModel,<br>    AutoencoderKL,<br>    DDIMScheduler,<br>    StableDiffusionPipeline,<br>)<br>from transformers import CLIPTextModel, CLIPTextConfig, CLIPTokenizer<br><br>unet = UNet2DConditionModel(<br>    block_out_channels=(32, 64),<br>    layers_per_block=2,<br>    sample_size=32,<br>    in_channels=4,<br>    out_channels=4,<br>    down_block_types=("DownBlock2D", "CrossAttnDownBlock2D"),<br>    up_block_types=("CrossAttnUpBlock2D", "UpBlock2D"),<br>    cross_attention_dim=32,<br>)<br><br>scheduler = DDIMScheduler(<br>    beta_start=0.00085,<br>    beta_end=0.012,<br>    beta_schedule="scaled_linear",<br>    clip_sample=False,<br>    set_alpha_to_one=False,<br>)<br><br>vae = AutoencoderKL(<br>    block_out_channels=[32, 64],<br>    in_channels=3,<br>    out_channels=3,<br>    down_block_types=["DownEncoderBlock2D", "DownEncoderBlock2D"],<br>    up_block_types=["UpDecoderBlock2D", "UpDecoderBlock2D"],<br>    latent_channels=4,<br>)<br><br>text_encoder_config = CLIPTextConfig(<br>    bos_token_id=0,<br>    eos_token_id=2,<br>    hidden_size=32,<br>    intermediate_size=37,<br>    layer_norm_eps=1e-05,<br>    num_attention_heads=4,<br>    num_hidden_layers=5,<br>    pad_token_id=1,<br>    vocab_size=1000,<br>)<br>text_encoder = CLIPTextModel(text_encoder_config)<br>tokenizer = CLIPTokenizer.from_pretrained("hf-internal-testing/tiny-random-clip")<br>---<br>Now here is the question you need to answer.<br><br>Question: How to create a pipeline object?&lt;/s&gt;<br>&lt;|assistant|&gt;</span></pre><p id="5933" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Synthesize Response</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="2cf7" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain_core.output_parsers <span class="hljs-keyword">import</span> JsonOutputParser<br>answer = llm(final_prompt)<br><span class="hljs-built_in">print</span>(answer)</span></pre><pre class="py po pp pq bo pr ba bj"><span id="2ac2" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.<br>  warn_deprecated(<br>Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.<br>To create a pipeline object, follow these steps:<br><br>1. Inherit the `Pipeline` base class from the `transformers` module.<br><br>2. Define the `inputs` and `outputs` of the pipeline. These can be strings, dictionaries, or any other Python data type that can be easily processed.<br><br>3. Implement the four required methods: `preprocess`, `_forward`, `postprocess`, and `_sanitize_parameters`.<br><br>   - `preprocess`: This method takes the raw inputs and returns a dictionary of preprocessed inputs that can be passed to the model.<br><br>   - `_forward`: This method takes the preprocessed inputs and the model and returns the output of the model.<br><br>   - `postprocess`: This method takes the output of the model and returns the final output of the pipeline.<br><br>   - `_sanitize_parameters`: This method ensures that the input parameters are valid and converts them into a format that can be used by the model.<br><br>4. Optionally, you can push the entire pipeline with all its components to the Hugging Face Hub or add it to the `transformers` library.<br><br>Here's an example implementation:<br><br>```python<br>from transformers import Pipeline<br><br>class MyPipeline(Pipeline):<br>    def __init__(self, model, tokenizer):<br>        super().__init__(model, tokenizer)<br><br>    def preprocess(self, inputs):<br>        # Preprocess inputs here<br>        return {"input_ids": inputs}<br><br>    def _forward(self, inputs):<br>        # Pass preprocessed inputs to the model and return the output<br>        return self.model(**inputs)[0]<br><br>    def postprocess(self, outputs):<br>        # Postprocess the output here<br>        return outputs[0]<br><br>    def _sanitize_parameters(self, hparams):<br>        # Sanitize input parameters here<br>        return hparams<br>```<br><br>Note that this implementation assumes a simple text classification pipeline using the `transformers` library. Adjust the implementation according to your specific use case.</span></pre><p id="1cec" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Reranking</p><p id="e47d" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph=""><em class="pg">A good option for RAG is to retrieve more documents than you want in the end, then rerank the results with a more powerful retrieval model before keeping only the top_k.</em></p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="bda5" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> ragatouille <span class="hljs-keyword">import</span> RAGPretrainedModel<br><br>RERANKER = RAGPretrainedModel.from_pretrained(<span class="hljs-string">"colbert-ir/colbertv2.0"</span>)<br><span class="hljs-comment">#</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">"=&gt; Reranking documents..."</span>)<br>question = <span class="hljs-string">"How to create a pipeline object?"</span><br>relevant_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=question, k=<span class="hljs-number">5</span>)<br>relevant_docs = [doc.page_content <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> relevant_docs]<br>reranked_relevant_docs = RERANKER.rerank(question, relevant_docs, k=<span class="hljs-number">3</span>)<br><span class="hljs-comment">#</span><br>reranked_docs = [doc[<span class="hljs-string">"content"</span>] <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> reranked_relevant_docs]<br><span class="hljs-comment">#Compare the documents retrived for normal vector search and rereanker</span><br><span class="hljs-keyword">for</span> i,doc <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(relevant_docs[:<span class="hljs-number">3</span>]):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Document <span class="hljs-subst">{i}</span>: <span class="hljs-subst">{doc}</span>"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"="</span>*<span class="hljs-number">80</span>)</span></pre><pre class="py po pp pq bo pr ba bj"><span id="52e2" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">Document <span class="hljs-number">0</span>: ```<br><br><span class="hljs-comment">## Available Pipelines:</span><br>================================================================================<br>Document <span class="hljs-number">1</span>: ```<br>&lt;/tf&gt;<br>&lt;/frameworkcontent&gt;<br><br><span class="hljs-comment">## Pipeline</span><br><br>&lt;Youtube <span class="hljs-built_in">id</span>=<span class="hljs-string">"tiZFewofSLM"</span>/&gt;<br><br>The [`pipeline`] <span class="hljs-keyword">is</span> the easiest <span class="hljs-keyword">and</span> fastest way to use a pretrained model <span class="hljs-keyword">for</span> inference. You can use the [`pipeline`] out-of-the-box <span class="hljs-keyword">for</span> many tasks across different modalities, some of which are shown <span class="hljs-keyword">in</span> the table below:<br><br>&lt;Tip&gt;<br><br>For a complete <span class="hljs-built_in">list</span> of available tasks, check out the [pipeline API reference](./main_classes/pipelines).<br><br>&lt;/Tip&gt;<br>================================================================================<br>Document <span class="hljs-number">2</span>: !--Copyright <span class="hljs-number">2020</span> The HuggingFace Team. All rights reserved.<br><br>Licensed under the Apache License, Version <span class="hljs-number">2.0</span> (the <span class="hljs-string">"License"</span>); you may <span class="hljs-keyword">not</span> use this file <span class="hljs-keyword">except</span> <span class="hljs-keyword">in</span> compliance <span class="hljs-keyword">with</span><br>the License. You may obtain a copy of the License at<br><br>http://www.apache.org/licenses/LICENSE-<span class="hljs-number">2.0</span><br><br>Unless required by applicable law <span class="hljs-keyword">or</span> agreed to <span class="hljs-keyword">in</span> writing, software distributed under the License <span class="hljs-keyword">is</span> distributed on<br>an <span class="hljs-string">"AS IS"</span> BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express <span class="hljs-keyword">or</span> implied. See the License <span class="hljs-keyword">for</span> the<br><br>⚠️ Note that this file <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> Markdown but contain specific syntax <span class="hljs-keyword">for</span> our doc-builder (similar to MDX) that may <span class="hljs-keyword">not</span> be<br>rendered properly <span class="hljs-keyword">in</span> your Markdown viewer.<br><br>--&gt;<br><br><span class="hljs-comment"># How to create a custom pipeline?</span><br><br>In this guide, we will see how to create a custom pipeline <span class="hljs-keyword">and</span> share it on the [Hub](hf.co/models) <span class="hljs-keyword">or</span> add it to the<br>🤗 Transformers library.<br><br>First <span class="hljs-keyword">and</span> foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw <span class="hljs-built_in">bytes</span>,<br>dictionaries <span class="hljs-keyword">or</span> whatever seems to be the most likely desired <span class="hljs-built_in">input</span>. Try to keep these inputs <span class="hljs-keyword">as</span> pure Python <span class="hljs-keyword">as</span> possible<br><span class="hljs-keyword">as</span> it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the<br>pipeline (`preprocess`).<br><br>Then define the `outputs`. Same policy <span class="hljs-keyword">as</span> the `inputs`. The simpler, the better. Those will be the outputs of<br>`postprocess` method.<br><br>Start by inheriting the base <span class="hljs-keyword">class</span> `Pipeline` <span class="hljs-keyword">with</span> the <span class="hljs-number">4</span> methods needed to implement `preprocess`,<br>`_forward`, `postprocess`, <span class="hljs-keyword">and</span> `_sanitize_parameters`.<br><br><br>```python<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Pipeline<br>================================================================================</span></pre><pre class="py po pp pq bo pr ba bj"><span id="8e1f" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">for</span> i,doc <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(reranked_docs):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Document <span class="hljs-subst">{i}</span>: <span class="hljs-subst">{doc}</span>"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"="</span>*<span class="hljs-number">80</span>)</span></pre><pre class="py po pp pq bo pr ba bj"><span id="ba68" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">Document <span class="hljs-number">0</span>: !--Copyright <span class="hljs-number">2020</span> The HuggingFace Team. All rights reserved.<br><br>Licensed under the Apache License, Version <span class="hljs-number">2.0</span> (the <span class="hljs-string">"License"</span>); you may <span class="hljs-keyword">not</span> use this file <span class="hljs-keyword">except</span> <span class="hljs-keyword">in</span> compliance <span class="hljs-keyword">with</span><br>the License. You may obtain a copy of the License at<br><br>http://www.apache.org/licenses/LICENSE-<span class="hljs-number">2.0</span><br><br>Unless required by applicable law <span class="hljs-keyword">or</span> agreed to <span class="hljs-keyword">in</span> writing, software distributed under the License <span class="hljs-keyword">is</span> distributed on<br>an <span class="hljs-string">"AS IS"</span> BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express <span class="hljs-keyword">or</span> implied. See the License <span class="hljs-keyword">for</span> the<br><br>⚠️ Note that this file <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> Markdown but contain specific syntax <span class="hljs-keyword">for</span> our doc-builder (similar to MDX) that may <span class="hljs-keyword">not</span> be<br>rendered properly <span class="hljs-keyword">in</span> your Markdown viewer.<br><br>--&gt;<br><br><span class="hljs-comment"># How to create a custom pipeline?</span><br><br>In this guide, we will see how to create a custom pipeline <span class="hljs-keyword">and</span> share it on the [Hub](hf.co/models) <span class="hljs-keyword">or</span> add it to the<br>🤗 Transformers library.<br><br>First <span class="hljs-keyword">and</span> foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw <span class="hljs-built_in">bytes</span>,<br>dictionaries <span class="hljs-keyword">or</span> whatever seems to be the most likely desired <span class="hljs-built_in">input</span>. Try to keep these inputs <span class="hljs-keyword">as</span> pure Python <span class="hljs-keyword">as</span> possible<br><span class="hljs-keyword">as</span> it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the<br>pipeline (`preprocess`).<br><br>Then define the `outputs`. Same policy <span class="hljs-keyword">as</span> the `inputs`. The simpler, the better. Those will be the outputs of<br>`postprocess` method.<br><br>Start by inheriting the base <span class="hljs-keyword">class</span> `Pipeline` <span class="hljs-keyword">with</span> the <span class="hljs-number">4</span> methods needed to implement `preprocess`,<br>`_forward`, `postprocess`, <span class="hljs-keyword">and</span> `_sanitize_parameters`.<br><br><br>```python<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Pipeline<br>================================================================================<br>Document <span class="hljs-number">1</span>: ```<br>&lt;/tf&gt;<br>&lt;/frameworkcontent&gt;<br><br><span class="hljs-comment">## Pipeline</span><br><br>&lt;Youtube <span class="hljs-built_in">id</span>=<span class="hljs-string">"tiZFewofSLM"</span>/&gt;<br><br>The [`pipeline`] <span class="hljs-keyword">is</span> the easiest <span class="hljs-keyword">and</span> fastest way to use a pretrained model <span class="hljs-keyword">for</span> inference. You can use the [`pipeline`] out-of-the-box <span class="hljs-keyword">for</span> many tasks across different modalities, some of which are shown <span class="hljs-keyword">in</span> the table below:<br><br>&lt;Tip&gt;<br><br>For a complete <span class="hljs-built_in">list</span> of available tasks, check out the [pipeline API reference](./main_classes/pipelines).<br><br>&lt;/Tip&gt;<br>================================================================================<br>Document <span class="hljs-number">2</span>: - **Self-contained**: A pipeline shall be <span class="hljs-keyword">as</span> self-contained <span class="hljs-keyword">as</span> possible. More specifically, this means that <span class="hljs-built_in">all</span> functionality should be either directly defined <span class="hljs-keyword">in</span> the pipeline file itself, should be inherited <span class="hljs-keyword">from</span> (<span class="hljs-keyword">and</span> only <span class="hljs-keyword">from</span>) the [`DiffusionPipeline` <span class="hljs-keyword">class</span>](https://github.com/huggingface/diffusers/blob/5cbed8e0d157f65d3ddc2420dfd09f2df630e978/src/diffusers/pipeline_utils.py<span class="hljs-comment">#L56) or be directly attached to the model and scheduler components of the pipeline.</span><br>- **Easy-to-use**: Pipelines should be extremely easy to use - one should be able to load the pipeline <span class="hljs-keyword">and</span><br>use it <span class="hljs-keyword">for</span> its designated task, *e.g.* text-to-image generation, <span class="hljs-keyword">in</span> just a couple of lines of code. Most<br>logic including pre-processing, an unrolled diffusion loop, <span class="hljs-keyword">and</span> post-processing should <span class="hljs-built_in">all</span> happen inside the `__call__` method.<br>- **Easy-to-tweak**: Certain pipelines will <span class="hljs-keyword">not</span> be able to handle <span class="hljs-built_in">all</span> use cases <span class="hljs-keyword">and</span> tasks that you might like them to. If you want to use a certain pipeline <span class="hljs-keyword">for</span> a specific use <span class="hljs-keyword">case</span> that <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> yet supported, you might have to copy the pipeline file <span class="hljs-keyword">and</span> tweak the code to your needs. We <span class="hljs-keyword">try</span> to make the pipeline code <span class="hljs-keyword">as</span> readable <span class="hljs-keyword">as</span> possible so that each part –<span class="hljs-keyword">from</span> pre-processing to diffusing to post-processing– can easily be adapted. If you would like the community to benefit <span class="hljs-keyword">from</span> your customized pipeline, we would love to see a contribution to our [community-examples](https://github.com/huggingface/diffusers/tree/main/examples/community). If you feel that an important pipeline should be part of the official pipelines but isn<span class="hljs-string">'t, a contribution to the [official pipelines](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines) would be even better.<br>================================================================================</span></span></pre><p id="d946" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Create a prompt with reranked docs</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="b69d" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">retrieved_docs_text = [doc <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> reranked_docs]  <span class="hljs-comment"># we only need the text of the documents</span><br>context = <span class="hljs-string">"\nExtracted documents:\n"</span><br>context += <span class="hljs-string">""</span>.join([<span class="hljs-string">f"Document <span class="hljs-subst">{<span class="hljs-built_in">str</span>(i)}</span>:::\n"</span> + doc <span class="hljs-keyword">for</span> i, doc <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(retrieved_docs_text)])<br><br>final_prompt = RAG_PROMPT_TEMPLATE.<span class="hljs-built_in">format</span>(question=<span class="hljs-string">"How to create a pipeline object?"</span>, context=context)<br><br><span class="hljs-built_in">print</span>(final_prompt)</span></pre><p id="c0d7" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Response Synthesis using Reranked Context</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="fc9f" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">answer = llm(final_prompt)<br><span class="hljs-built_in">print</span>(answer)</span></pre><pre class="py po pp pq bo pr ba bj"><span id="a381" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">Setting `pad_token_id` to `eos_token_id`:<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> <span class="hljs-built_in">open</span>-end generation.<br>To create a pipeline <span class="hljs-built_in">object</span>, follow these steps:<br><br><span class="hljs-number">1.</span> Define the inputs <span class="hljs-keyword">and</span> outputs of your pipeline, <span class="hljs-keyword">as</span> described <span class="hljs-keyword">in</span> the context.<br><br><span class="hljs-number">2.</span> Inherit the `Pipeline` <span class="hljs-keyword">class</span> <span class="hljs-title.class">from</span> the `transformers` module, <span class="hljs-keyword">as</span> shown <span class="hljs-keyword">in</span> the context:<br><br>   ```python<br>   <span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> PipelineDocument <span class="hljs-number">1</span>:::<br>   ```<br><br><span class="hljs-number">3.</span> Implement the four required methods: `preprocess`, `_forward`, `postprocess`, <span class="hljs-keyword">and</span> `_sanitize_parameters`. Here<span class="hljs-string">'s an example implementation:<br><br>   ```python<br>   class MyCustomPipeline(Pipeline):<br>       def __init__(self,...):<br>           super().__init__(... )<br><br>       def preprocess(self, inputs):<br>           # Preprocess the inputs here<br>           return preprocessed_inputs<br><br>       def _forward(self, inputs):<br>           # Run the forward pass of your model here<br>           return output<br><br>       def postprocess(self, outputs):<br>           # Postprocess the outputs here<br>           return postprocessed_outputs<br><br>       def _sanitize_parameters(self, parameters):<br>           # Sanitize the parameters here<br>           return sanitized_parameters<br>   ```<br><br>4. Load your pipeline using the `from_pretrained()` function provided by the `transformers` module:<br><br>   ```python<br>   my_custom_pipeline = MyCustomPipeline.from_pretrained('</span>my_custom_pipeline<span class="hljs-string">')<br>   ```<br><br>5. Use your pipeline object to perform inference on new data:<br><br>   ```python<br>   results = my_custom_pipeline(input_data)<br>   ```<br><br>That'</span>s it! Your custom pipeline <span class="hljs-keyword">is</span> now ready to use. Remember to follow the guidelines mentioned <span class="hljs-keyword">in</span> the context to ensure that your pipeline <span class="hljs-keyword">is</span> self-contained, easy-to-use, <span class="hljs-keyword">and</span> easy-to-tweak. Additionally, consider contributing your pipeline to the Hugging Face Hub <span class="hljs-keyword">or</span> the official pipelines <span class="hljs-keyword">if</span> it could be useful to others.</span></pre><ul class=""><li id="e285" class="nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os ph oz pa bj" data-selectable-paragraph="">The re-ranked context yields a much better response</li></ul><p id="afd1" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Applying Corrective RAG</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="f05f" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> userdata<br><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">"OPENAI_API_KEY"</span>] = userdata.get(<span class="hljs-string">'OPENAI_API_KEY'</span>)<br><br>llm_openai = OpenAI(temperature=<span class="hljs-number">0</span>)<br><span class="hljs-comment">#</span><br>c_prompt =  PromptTemplate(<br>        template=<span class="hljs-string">"""You are a grader assessing relevance of a retrieved document to a user question. \n<br>        Here is the retrieved document: \n\n {context} \n\n<br>        Here is the user question: {question} \n<br>        If the document contains keywords related to the user question, grade it as relevant. \n<br>        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n<br>        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n<br>        Provide only the binary score as a text varible with a single key 'score' and no premable or explaination."""</span>,<br>        input_variables=[<span class="hljs-string">"question"</span>, <span class="hljs-string">"context"</span>],<br>    )<br><span class="hljs-comment">#</span><br><br>score_prompt = <span class="hljs-string">"""You are a grader assessing relevance of a retrieved document to a user question. \n<br>        Here is the retrieved document: \n\n {context} \n\n<br>        Here is the user question: {question} \n<br>        If the document contains keywords related to the user question, grade it as relevant. \n<br>        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n<br>        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n"""</span><br><span class="hljs-comment">#</span><br></span></pre><pre class="py po pp pq bo pr ba bj"><span id="9a0e" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain.output_parsers <span class="hljs-keyword">import</span> ResponseSchema, StructuredOutputParser<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><br>response_schemas = [<br>    ResponseSchema(name=<span class="hljs-string">"Score"</span>, description=<span class="hljs-string">"score for the context query relevancy"</span>),<br>]<br>output_parser = StructuredOutputParser.from_response_schemas(response_schemas)<br><span class="hljs-comment">#</span><br>format_instructions = output_parser.get_format_instructions()<br><span class="hljs-comment">#</span><br><span class="hljs-built_in">print</span>(output_parser)<br><span class="hljs-comment">#</span><br><span class="hljs-built_in">print</span>(format_instructions)</span></pre><pre class="py po pp pq bo pr ba bj"><span id="230b" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">response_schemas=[ResponseSchema(name='Score', description='score for the context query relevancy', type='string')]<br>The output should be a markdown code snippet formatted in the following schema, including the leading and trailing "```json" and "```":<br><br>```json<br>{<br> "Score": string  // score for the context query relevancy<br>}<br>```</span></pre><pre class="py po pp pq bo pr ba bj"><span id="f1cc" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">template=score_prompt+<span class="hljs-string">"\n{format_instructions}"</span><br><span class="hljs-built_in">print</span>(template)<br><span class="hljs-comment">#</span><br>scoreprompt = PromptTemplate.from_template(template=template)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f"scoreprompt : <span class="hljs-subst">{scoreprompt}</span>"</span>) </span></pre><pre class="py po pp pq bo pr ba bj"><span id="088b" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">You are a grader assessing relevance of a retrieved document to a user question. \n \n        Here is the retrieved document: \n\n {context} \n\n\n        Here is the user question: {question} \n\n        If the document contains keywords related to the user question, grade it as relevant. \n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n\n{format_instructions}<br><br>scoreprompt: PromptTemplate(input_variables=['context', 'format_instructions', 'question'], template="You are a grader assessing relevance of a retrieved document to a user question. \n \n        Here is the retrieved document: \n\n {context} \n\n\n        Here is the user question: {question} \n\n        If the document contains keywords related to the user question, grade it as relevant. \n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n\n{format_instructions}")</span></pre><p id="d27f" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Prepared the final prompt to apply Corrective RAG</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="2d5f" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">question = <span class="hljs-string">"How to create a pipeline object?"</span><br>context = reranked_docs[<span class="hljs-number">0</span>]<br>final_prompt = scoreprompt.format_prompt(format_instructions=format_instructions,<br>                                   question=question,<br>                                    context=context,<br>                                    ).text<br><span class="hljs-built_in">print</span>(final_prompt)</span></pre><pre class="py po pp pq bo pr ba bj"><span id="672d" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">You are a grader assessing relevance of a retrieved document to a user question. <br> <br>        Here <span class="hljs-keyword">is</span> the retrieved document: <br><br> !--Copyright <span class="hljs-number">2020</span> The HuggingFace Team. All rights reserved.<br><br>Licensed under the Apache License, Version <span class="hljs-number">2.0</span> (the <span class="hljs-string">"License"</span>); you may <span class="hljs-keyword">not</span> use this file <span class="hljs-keyword">except</span> <span class="hljs-keyword">in</span> compliance <span class="hljs-keyword">with</span><br>the License. You may obtain a copy of the License at<br><br>http://www.apache.org/licenses/LICENSE-<span class="hljs-number">2.0</span><br><br>Unless required by applicable law <span class="hljs-keyword">or</span> agreed to <span class="hljs-keyword">in</span> writing, software distributed under the License <span class="hljs-keyword">is</span> distributed on<br>an <span class="hljs-string">"AS IS"</span> BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express <span class="hljs-keyword">or</span> implied. See the License <span class="hljs-keyword">for</span> the<br><br>⚠️ Note that this file <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> Markdown but contain specific syntax <span class="hljs-keyword">for</span> our doc-builder (similar to MDX) that may <span class="hljs-keyword">not</span> be<br>rendered properly <span class="hljs-keyword">in</span> your Markdown viewer.<br><br>--&gt;<br><br><span class="hljs-comment"># How to create a custom pipeline?</span><br><br>In this guide, we will see how to create a custom pipeline <span class="hljs-keyword">and</span> share it on the [Hub](hf.co/models) <span class="hljs-keyword">or</span> add it to the<br>🤗 Transformers library.<br><br>First <span class="hljs-keyword">and</span> foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw <span class="hljs-built_in">bytes</span>,<br>dictionaries <span class="hljs-keyword">or</span> whatever seems to be the most likely desired <span class="hljs-built_in">input</span>. Try to keep these inputs <span class="hljs-keyword">as</span> pure Python <span class="hljs-keyword">as</span> possible<br><span class="hljs-keyword">as</span> it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the<br>pipeline (`preprocess`).<br><br>Then define the `outputs`. Same policy <span class="hljs-keyword">as</span> the `inputs`. The simpler, the better. Those will be the outputs of<br>`postprocess` method.<br><br>Start by inheriting the base <span class="hljs-keyword">class</span> `Pipeline` <span class="hljs-keyword">with</span> the <span class="hljs-number">4</span> methods needed to implement `preprocess`,<br>`_forward`, `postprocess`, <span class="hljs-keyword">and</span> `_sanitize_parameters`.<br><br><br>```python<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Pipeline <br><br><br>        Here <span class="hljs-keyword">is</span> the user question: How to create a pipeline <span class="hljs-built_in">object</span>? <br><br>        If the document contains keywords related to the user question, grade it <span class="hljs-keyword">as</span> relevant. <br><br>        It does <span class="hljs-keyword">not</span> need to be a stringent test. The goal <span class="hljs-keyword">is</span> to <span class="hljs-built_in">filter</span> out erroneous retrievals. <br><br>        Give a binary score <span class="hljs-string">'yes'</span> <span class="hljs-keyword">or</span> <span class="hljs-string">'no'</span> score to indicate whether the document <span class="hljs-keyword">is</span> relevant to the question. <br><br>The output should be a markdown code snippet formatted <span class="hljs-keyword">in</span> the following schema, including the leading <span class="hljs-keyword">and</span> trailing <span class="hljs-string">"```json"</span> <span class="hljs-keyword">and</span> <span class="hljs-string">"```"</span>:<br><br>```json<br>{<br> <span class="hljs-string">"Score"</span>: string  // score <span class="hljs-keyword">for</span> the context query relevancy<br>}<br>```</span></pre><pre class="py po pp pq bo pr ba bj"><span id="d70e" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">score = llm_openai(final_prompt)<br><br><span class="hljs-comment">#####Output</span><br><br><br>```json<br>{<br> <span class="hljs-string">"Score"</span>: <span class="hljs-string">"yes"</span><br>}<br>```</span></pre><p id="58be" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Assembling relevant context by running the Corrective RAG logic.</p><h1 id="d21c" class="mx my fr be mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu bj" data-selectable-paragraph="">Corrective RAG</h1><p id="aa5b" class="pw-post-body-paragraph nv nw fr nx b ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os fk bj" data-selectable-paragraph="">Let’s implement self-reflective RAG with some ideas from the CRAG <a class="af pi" href="https://arxiv.org/abs/2401.15884" rel="noopener ugc nofollow" target="_blank">(Corrective RAG) paper</a>:</p><ol class=""><li id="4725" class="nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">Grade documents for relevance relative to the question.</em></li><li id="daba" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">If any are irrelevant, then we will not use the context for generation</em></li><li id="b5a2" class="nv nw fr nx b ny pb oa ob oc pc oe of og pd oi oj ok pe om on oo pf oq or os oy oz pa bj" data-selectable-paragraph=""><em class="pg">We will then pass final retrieved documents to an LLM for final answer generation.</em></li></ol><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="3b13" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph=""> <span class="hljs-comment"># Score</span><br>filtered_docs = []<br>grade_ = []<br>matched_relevant_docs = []<br>question = <span class="hljs-string">"How to create a pipeline object?"</span><br><br>search = <span class="hljs-string">"No"</span>  <span class="hljs-comment"># Default do not opt for web search to supplement retrieval</span><br><span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> reranked_docs:<br>  final_prompt = scoreprompt.format_prompt(format_instructions=format_instructions,<br>                                   question=question,<br>                                    context=d,<br>                                    ).text<br>  <span class="hljs-built_in">print</span>(final_prompt)<br>  score = llm_openai(final_prompt)<br>  <span class="hljs-built_in">print</span>(score)<br>  score_dict = <span class="hljs-built_in">eval</span>(score.split(<span class="hljs-string">"```json\n"</span>)[-<span class="hljs-number">1</span>].replace(<span class="hljs-string">"\n```"</span>,<span class="hljs-string">""</span>).replace(<span class="hljs-string">"\t"</span>,<span class="hljs-string">""</span>).replace(<span class="hljs-string">"\n"</span>,<span class="hljs-string">""</span>))<br>  <span class="hljs-built_in">print</span>(score_dict)<br>  <span class="hljs-keyword">if</span> score_dict[<span class="hljs-string">'Score'</span>] == <span class="hljs-string">"yes"</span>:<br>    matched_relevant_docs.append(d)<br><br></span></pre><pre class="py po pp pq bo pr ba bj"><span id="701d" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">You are a grader assessing relevance of a retrieved document to a user question. <br> <br>        Here is the retrieved document: <br><br> !--Copyright 2020 The HuggingFace Team. All rights reserved.<br><br>Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with<br>the License. You may obtain a copy of the License at<br><br>http://www.apache.org/licenses/LICENSE-2.0<br><br>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on<br>an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the<br><br>⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be<br>rendered properly in your Markdown viewer.<br><br>--&gt;<br><br># How to create a custom pipeline?<br><br>In this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co/models) or add it to the<br>🤗 Transformers library.<br><br>First and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,<br>dictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible<br>as it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the<br>pipeline (`preprocess`).<br><br>Then define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of<br>`postprocess` method.<br><br>Start by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,<br>`_forward`, `postprocess`, and `_sanitize_parameters`.<br><br><br>```python<br>from transformers import Pipeline <br><br><br>        Here is the user question: How to create a pipeline object? <br><br>        If the document contains keywords related to the user question, grade it as relevant. <br><br>        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. <br><br>        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. <br><br>The output should be a markdown code snippet formatted in the following schema, including the leading and trailing "```json" and "```":<br><br>```json<br>{<br> "Score": string  // score for the context query relevancy<br>}<br>```<br><br><br>```json<br>{<br> "Score": "yes"<br>}<br>```<br>{'Score': 'yes'}<br>You are a grader assessing relevance of a retrieved document to a user question. <br> <br>        Here is the retrieved document: <br><br> ```<br>&lt;/tf&gt;<br>&lt;/frameworkcontent&gt;<br><br>## Pipeline<br><br>&lt;Youtube id="tiZFewofSLM"/&gt;<br><br>The [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:<br><br>&lt;Tip&gt;<br><br>For a complete list of available tasks, check out the [pipeline API reference](./main_classes/pipelines).<br><br>&lt;/Tip&gt; <br><br><br>        Here is the user question: How to create a pipeline object? <br><br>        If the document contains keywords related to the user question, grade it as relevant. <br><br>        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. <br><br>        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. <br><br>The output should be a markdown code snippet formatted in the following schema, including the leading and trailing "```json" and "```":<br><br>```json<br>{<br> "Score": string  // score for the context query relevancy<br>}<br>```<br><br><br>```json<br>{<br> "Score": "yes"<br>}<br>```<br>{'Score': 'yes'}<br>You are a grader assessing relevance of a retrieved document to a user question. <br> <br>        Here is the retrieved document: <br><br> - **Self-contained**: A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the [`DiffusionPipeline` class](https://github.com/huggingface/diffusers/blob/5cbed8e0d157f65d3ddc2420dfd09f2df630e978/src/diffusers/pipeline_utils.py#L56) or be directly attached to the model and scheduler components of the pipeline.<br>- **Easy-to-use**: Pipelines should be extremely easy to use - one should be able to load the pipeline and<br>use it for its designated task, *e.g.* text-to-image generation, in just a couple of lines of code. Most<br>logic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `__call__` method.<br>- **Easy-to-tweak**: Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part –from pre-processing to diffusing to post-processing– can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our [community-examples](https://github.com/huggingface/diffusers/tree/main/examples/community). If you feel that an important pipeline should be part of the official pipelines but isn't, a contribution to the [official pipelines](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines) would be even better. <br><br><br>        Here is the user question: How to create a pipeline object? <br><br>        If the document contains keywords related to the user question, grade it as relevant. <br><br>        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. <br><br>        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. <br><br>The output should be a markdown code snippet formatted in the following schema, including the leading and trailing "```json" and "```":<br><br>```json<br>{<br> "Score": string  // score for the context query relevancy<br>}<br>```<br><br><br>```json<br>{<br> "Score": "yes"<br>}<br>```<br>{'Score': 'yes'}</span></pre><p id="b634" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Redact an answer based on the documents scored as yes by the llm- basically implementing Corrective RAG.</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="5a9f" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">retrieved_docs_text = [doc <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> matched_relevant_docs]  <span class="hljs-comment"># we only need the text of the documents</span><br>context = <span class="hljs-string">"\nExtracted documents:\n"</span><br>context += <span class="hljs-string">""</span>.join([<span class="hljs-string">f"Document <span class="hljs-subst">{<span class="hljs-built_in">str</span>(i)}</span>:::\n"</span> + doc <span class="hljs-keyword">for</span> i, doc <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(retrieved_docs_text)])<br><br>final_prompt = RAG_PROMPT_TEMPLATE.<span class="hljs-built_in">format</span>(question=<span class="hljs-string">"How to create a pipeline object?"</span>, context=context)<br><br><span class="hljs-built_in">print</span>(final_prompt)</span></pre><p id="bdf5" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Response Log</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="3441" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">&lt;|system|&gt;<br>Using the information contained <span class="hljs-keyword">in</span> the context,<br>give a comprehensive answer to the question.<br>Respond only to the question asked, response should be concise <span class="hljs-keyword">and</span> relevant to the question.<br>Provide the number of the source document when relevant.<br>If the answer cannot be deduced <span class="hljs-keyword">from</span> the context, do <span class="hljs-keyword">not</span> give an answer.&lt;/s&gt;<br>&lt;|user|&gt;<br>Context:<br><br>Extracted documents:<br>Document <span class="hljs-number">0</span>:::<br>!--Copyright <span class="hljs-number">2020</span> The HuggingFace Team. All rights reserved.<br><br>Licensed under the Apache License, Version <span class="hljs-number">2.0</span> (the <span class="hljs-string">"License"</span>); you may <span class="hljs-keyword">not</span> use this file <span class="hljs-keyword">except</span> <span class="hljs-keyword">in</span> compliance <span class="hljs-keyword">with</span><br>the License. You may obtain a copy of the License at<br><br>http://www.apache.org/licenses/LICENSE-<span class="hljs-number">2.0</span><br><br>Unless required by applicable law <span class="hljs-keyword">or</span> agreed to <span class="hljs-keyword">in</span> writing, software distributed under the License <span class="hljs-keyword">is</span> distributed on<br>an <span class="hljs-string">"AS IS"</span> BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express <span class="hljs-keyword">or</span> implied. See the License <span class="hljs-keyword">for</span> the<br><br>⚠️ Note that this file <span class="hljs-keyword">is</span> <span class="hljs-keyword">in</span> Markdown but contain specific syntax <span class="hljs-keyword">for</span> our doc-builder (similar to MDX) that may <span class="hljs-keyword">not</span> be<br>rendered properly <span class="hljs-keyword">in</span> your Markdown viewer.<br><br>--&gt;<br><br><span class="hljs-comment"># How to create a custom pipeline?</span><br><br>In this guide, we will see how to create a custom pipeline <span class="hljs-keyword">and</span> share it on the [Hub](hf.co/models) <span class="hljs-keyword">or</span> add it to the<br>🤗 Transformers library.<br><br>First <span class="hljs-keyword">and</span> foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw <span class="hljs-built_in">bytes</span>,<br>dictionaries <span class="hljs-keyword">or</span> whatever seems to be the most likely desired <span class="hljs-built_in">input</span>. Try to keep these inputs <span class="hljs-keyword">as</span> pure Python <span class="hljs-keyword">as</span> possible<br><span class="hljs-keyword">as</span> it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the<br>pipeline (`preprocess`).<br><br>Then define the `outputs`. Same policy <span class="hljs-keyword">as</span> the `inputs`. The simpler, the better. Those will be the outputs of<br>`postprocess` method.<br><br>Start by inheriting the base <span class="hljs-keyword">class</span> `Pipeline` <span class="hljs-keyword">with</span> the <span class="hljs-number">4</span> methods needed to implement `preprocess`,<br>`_forward`, `postprocess`, <span class="hljs-keyword">and</span> `_sanitize_parameters`.<br><br><br>```python<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> PipelineDocument <span class="hljs-number">1</span>:::<br>```<br>&lt;/tf&gt;<br>&lt;/frameworkcontent&gt;<br><br><span class="hljs-comment">## Pipeline</span><br><br>&lt;Youtube <span class="hljs-built_in">id</span>=<span class="hljs-string">"tiZFewofSLM"</span>/&gt;<br><br>The [`pipeline`] <span class="hljs-keyword">is</span> the easiest <span class="hljs-keyword">and</span> fastest way to use a pretrained model <span class="hljs-keyword">for</span> inference. You can use the [`pipeline`] out-of-the-box <span class="hljs-keyword">for</span> many tasks across different modalities, some of which are shown <span class="hljs-keyword">in</span> the table below:<br><br>&lt;Tip&gt;<br><br>For a complete <span class="hljs-built_in">list</span> of available tasks, check out the [pipeline API reference](./main_classes/pipelines).<br><br>&lt;/Tip&gt;Document <span class="hljs-number">2</span>:::<br>- **Self-contained**: A pipeline shall be <span class="hljs-keyword">as</span> self-contained <span class="hljs-keyword">as</span> possible. More specifically, this means that <span class="hljs-built_in">all</span> functionality should be either directly defined <span class="hljs-keyword">in</span> the pipeline file itself, should be inherited <span class="hljs-keyword">from</span> (<span class="hljs-keyword">and</span> only <span class="hljs-keyword">from</span>) the [`DiffusionPipeline` <span class="hljs-keyword">class</span>](https://github.com/huggingface/diffusers/blob/5cbed8e0d157f65d3ddc2420dfd09f2df630e978/src/diffusers/pipeline_utils.py<span class="hljs-comment">#L56) or be directly attached to the model and scheduler components of the pipeline.</span><br>- **Easy-to-use**: Pipelines should be extremely easy to use - one should be able to load the pipeline <span class="hljs-keyword">and</span><br>use it <span class="hljs-keyword">for</span> its designated task, *e.g.* text-to-image generation, <span class="hljs-keyword">in</span> just a couple of lines of code. Most<br>logic including pre-processing, an unrolled diffusion loop, <span class="hljs-keyword">and</span> post-processing should <span class="hljs-built_in">all</span> happen inside the `__call__` method.<br>- **Easy-to-tweak**: Certain pipelines will <span class="hljs-keyword">not</span> be able to handle <span class="hljs-built_in">all</span> use cases <span class="hljs-keyword">and</span> tasks that you might like them to. If you want to use a certain pipeline <span class="hljs-keyword">for</span> a specific use <span class="hljs-keyword">case</span> that <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> yet supported, you might have to copy the pipeline file <span class="hljs-keyword">and</span> tweak the code to your needs. We <span class="hljs-keyword">try</span> to make the pipeline code <span class="hljs-keyword">as</span> readable <span class="hljs-keyword">as</span> possible so that each part –<span class="hljs-keyword">from</span> pre-processing to diffusing to post-processing– can easily be adapted. If you would like the community to benefit <span class="hljs-keyword">from</span> your customized pipeline, we would love to see a contribution to our [community-examples](https://github.com/huggingface/diffusers/tree/main/examples/community). If you feel that an important pipeline should be part of the official pipelines but isn<span class="hljs-string">'t, a contribution to the [official pipelines](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines) would be even better.<br>---<br>Now here is the question you need to answer.<br><br>Question: How to create a pipeline object?&lt;/s&gt;<br>&lt;|assistant|&gt;</span></span></pre><p id="dea2" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Response Synthesizer</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="ce16" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">answer = llm(final_prompt)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f"Response Synthesized by LLM :\n\n<span class="hljs-subst">{answer}</span>"</span>)</span></pre><p id="33ac" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Response Log</p><pre class="pj pk pl pm pn po pp pq bo pr ba bj"><span id="1958" class="ps my fr pp b bf pt pu l pv pw" data-selectable-paragraph="">Setting `pad_token_id` to `eos_token_id`:<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> <span class="hljs-built_in">open</span>-end generation.<br>Response Synthesized by LLM :<br><br>To create a pipeline <span class="hljs-built_in">object</span> following the guidelines provided, you can follow these steps:<br><br><span class="hljs-number">1.</span> Define the inputs <span class="hljs-keyword">and</span> outputs of your pipeline. These could be strings, dictionaries, <span class="hljs-keyword">or</span> <span class="hljs-built_in">any</span> other Python data <span class="hljs-built_in">type</span> that best represents the <span class="hljs-built_in">input</span> <span class="hljs-keyword">and</span> output formats <span class="hljs-keyword">for</span> your specific task.<br><br><span class="hljs-number">2.</span> Inherit the `Pipeline` <span class="hljs-keyword">class</span> <span class="hljs-title.class">from</span> the `transformers` module. This <span class="hljs-keyword">class</span> <span class="hljs-title.class">provides</span> the necessary methods <span class="hljs-keyword">for</span> implementing the pipeline.<br><br><span class="hljs-number">3.</span> Implement the four required methods: `preprocess`, `_forward`, `postprocess`, <span class="hljs-keyword">and</span> `_sanitize_parameters`. Here<span class="hljs-string">'s a brief explanation of what each method does:<br><br>   - `preprocess(self, inputs: Dict[str, Any], return_dict: bool = True) -&gt; Dict[str, Any]`: This method takes the input dictionary and returns a dictionary with the preprocessed data. It can also optionally return a dictionary instead of a list of outputs.<br><br>   - `_forward(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]`: This method performs the actual computation using the underlying model and scheduler. It takes the preprocessed input dictionary and returns a dictionary with the computed results.<br><br>   - `postprocess(self, outputs: Dict[str, Any], **kwargs) -&gt; Dict[str, Any]`: This method takes the computed outputs and returns the final output dictionary after applying any necessary postprocessing steps.<br><br>   - `_sanitize_parameters(self, parameters: Dict[str, Any]) -&gt; Dict[str, Any]`: This method sanitizes the input parameters before passing them to the underlying model and scheduler. It ensures that the parameters are in the correct format and range.<br><br>4. Optionally, you can attach additional functionality to the model and scheduler components of the pipeline. This can include custom loss functions, optimizers, and learning rate schedules.<br><br>5. Once you have implemented your pipeline, you can load it using the `Pipeline` constructor and use it for inference. Here'</span>s an example usage:<br><br>   ```python<br>   <span class="hljs-keyword">from</span> my_pipeline <span class="hljs-keyword">import</span> MyPipeline<br>   <br>   <span class="hljs-comment"># Load the pipeline</span><br>   pipe = MyPipeline()<br>   <br>   <span class="hljs-comment"># Use the pipeline for inference</span><br>   result = pipe(<span class="hljs-string">"This is a sample input</span></span></pre><p id="7860" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Conclusion:</p><p id="12f8" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Here we have implemented a Corrective RAG approach aby only considering the context to be those documents which are relevant to the query asked. We could have also used external resources to enhance the correctness of the non relevant contexts and pass it on to the LLM to enhance the response.</p><p id="216d" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph="">Referrences:</p><div class="pz qa qb qc qd qe"><a href="https://arxiv.org/abs/2401.15884?source=post_page-----30d63e222563--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qf ab ia"><div class="qg ab cn ca qh qi"><h2 class="be fs hq z ii qj ik il qk in ip fq bj">Corrective Retrieval Augmented Generation</h2><div class="ql l"><h3 class="be b hq z ii qj ik il qk in ip dw">Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured…</h3></div><div class="qm l"><p class="be b dx z ii qj ik il qk in ip dw">arxiv.org</p></div></div><div class="qn l"><div class="qo l qp qq qr qn qs lm qe"></div></div></div></a></div><div class="pz qa qb qc qd qe"><a href="https://github.com/bclavie/RAGatouille?source=post_page-----30d63e222563--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qf ab ia"><div class="qg ab cn ca qh qi"><h2 class="be fs hq z ii qj ik il qk in ip fq bj">GitHub - bclavie/RAGatouille</h2><div class="ql l"><h3 class="be b hq z ii qj ik il qk in ip dw">Contribute to bclavie/RAGatouille development by creating an account on GitHub.</h3></div><div class="qm l"><p class="be b dx z ii qj ik il qk in ip dw">github.com</p></div></div><div class="qn l"><div class="qt l qp qq qr qn qs lm qe"></div></div></div></a></div><p id="dac8" class="pw-post-body-paragraph nv nw fr nx b ny ot oa ob oc ou oe of og ov oi oj ok ow om on oo ox oq or os fk bj" data-selectable-paragraph=""><a class="af pi" href="https://www.linkedin.com/in/plaban-nayak-a9433a25/" rel="noopener ugc nofollow" target="_blank">connect with me</a></p></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg ew ex ey ez"></div></div></div><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="qu qv ab id"><div class="ql ab"><a class="qw ax am ao" rel="noopener follow" href="https://medium.com/tag/crag?source=post_page-----30d63e222563---------------crag-----------------"><div class="qx ee cw qy fb qz ra be b bf z bj rb">Crag</div></a></div><div class="ql ab"><a class="qw ax am ao" rel="noopener follow" href="https://medium.com/tag/langchain?source=post_page-----30d63e222563---------------langchain-----------------"><div class="qx ee cw qy fb qz ra be b bf z bj rb">Langchain</div></a></div><div class="ql ab"><a class="qw ax am ao" rel="noopener follow" href="https://medium.com/tag/zephyr-7b?source=post_page-----30d63e222563---------------zephyr_7b-----------------"><div class="qx ee cw qy fb qz ra be b bf z bj rb">Zephyr 7b</div></a></div><div class="ql ab"><a class="qw ax am ao" rel="noopener follow" href="https://medium.com/tag/openai?source=post_page-----30d63e222563---------------openai-----------------"><div class="qx ee cw qy fb qz ra be b bf z bj rb">OpenAI</div></a></div><div class="ql ab"><a class="qw ax am ao" rel="noopener follow" href="https://medium.com/tag/chromadb?source=post_page-----30d63e222563---------------chromadb-----------------"><div class="qx ee cw qy fb qz ra be b bf z bj rb">Chromadb</div></a></div></div></div></div><div class="l"></div><footer class="rc rd re rf rg rh ri rj rk ab q rl hm c"><div class="l ae"><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="ab co rm"><div class="ab q jy"><div class="rn l"><span class="l ro rp rq e d"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="63" aria-labelledby="63"><button class="kd ao kf vx vy kj am kk kl km kc" data-testid="footerClapButton"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="64" aria-labelledby="64"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">206<span class="l h g f rr rs"></span></button></p></div></div></div></div></span><span class="l h g f rr rs"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="65" aria-labelledby="65"><button class="kd ao kf vx vy kj am kk kl km kc" data-testid="footerClapButton"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="66" aria-labelledby="66"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">206</button></p></div></div></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false" aria-describedby="10" aria-labelledby="10"><button class="ao kd kw kx ab q ef ky kz" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="kv"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b bf z dw"><span class="pw-responses-count ku kv">2</span></p></button></div></div></div></div><div class="ab q"><div class="rt l ia"><div><div class="bl" aria-hidden="false" aria-describedby="11" aria-labelledby="11"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="footerBookmarkButton" class="af ef ah ai aj ak al lb an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="rt l ia"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false" aria-describedby="12" aria-labelledby="12"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af ef ah ai aj ak al lb an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="70" aria-labelledby="70"><button aria-label="More options" data-testid="footerStoryOptionsButton" class="af ef ah ai aj ak al lb an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="ru rv rw rx ry l bw"><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="ck ab rz co"><div class="ab hc"><a rel="noopener follow" href="https://medium.com/@nayakpplaban?source=post_page-----30d63e222563--------------------------------"><div class="l sa sb bx sc hg"><div class="l ee"><img alt="Plaban Nayak" class="l eq bx sd se cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_oFXd8MlaJnMFie2YKsWB_Q(1).jpg" width="72" height="72" loading="lazy"><div class="hh bx l sd se eo n hi ep"></div></div></div></a><a href="https://medium.com/the-ai-forum?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><div class="sf ab ee"><div><div class="bl" aria-hidden="false" aria-describedby="14" aria-labelledby="14"><div class="l sg sh bx sc hm"><div class="l ee"><img alt="The AI Forum" class="l eq bx by bz cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_p9oOISlQYwVpgPGEaGPuDA(1).png" width="32" height="32" loading="lazy"><div class="hh bx l by bz eo n hi ep"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><button class="be b bf z wb qx wc wd we wf wg wh sr ss st su sv sw sx sy eq bl sz mt">Follow</button><div class="dv l"><div><div><div class="bl" aria-hidden="false" aria-describedby="343" aria-labelledby="343"><div class="l"><button class="be b bf z wb am wc wd we wf wg wh sr ss st su sv sx sy eq bl sz mt" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="wj sh sg"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=post_page-----30d63e222563--------------------------------"><h2 class="pw-author-name be tb tc td te bj"><span class="fk">Written by <!-- -->Plaban Nayak</span></h2></a></div><div class="ql ab"><div class="l ia"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar hs" rel="noopener follow" href="https://medium.com/@nayakpplaban/followers?source=post_page-----30d63e222563--------------------------------">1.4K Followers</a></span></div><div class="be b bf z ii ij ik ab im in io ip dw ig"><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span class="l ia">Editor for </span><div><div class="l" aria-hidden="false" aria-describedby="16" aria-labelledby="16"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/the-ai-forum?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><p class="be b bf z ii ij ik il im in io ip bj">The AI Forum</p></a></div></div></div></div><div class="py l"><p class="be b bf z bj"><span class="fk">Machine Learning and Deep Learning enthusiast</span></p></div></div><div class="h k"><div class="ab"><button class="be b bf z wb qx wc wd we wf wg wh sr ss st su sv sw sx sy eq bl sz mt">Follow</button><div class="dv l"><div><div><div class="bl" aria-hidden="false" aria-describedby="345" aria-labelledby="345"><div class="l"><button class="be b bf z wb am wc wd we wf wg wh sr ss st su sv sx sy eq bl sz mt" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="wj sh sg"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></div></div></div></div></div></div></div></div><div class="tf bg tg mh mi mj mk ml"></div></div></div><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="wk wl l"><h2 class="be tb hq z fq bj">More from Plaban Nayak and The AI Forum</h2></div><div class="wm ab jy id wn wo wp wq wr ws wt wu wv ww wx wy wz xa xb"><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/dphi-tech/implement-rag-with-knowledge-graph-and-llama-index-6a3370e93cdd" tabindex="0"><div class="yp"><div aria-label="Implement RAG with Knowledge Graph and Llama-Index"><div class="yr ys yt yu yv"><img alt="Implement RAG with Knowledge Graph and Llama-Index" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_sF_Vf80yj0Yq-IZZjgjfOQ.png" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="98" aria-labelledby="98"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=author_recirc-----30d63e222563----0---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><div class="l ee"><img alt="Plaban Nayak" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_oFXd8MlaJnMFie2YKsWB_Q(2).jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="99" aria-labelledby="99"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=author_recirc-----30d63e222563----0---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><p class="be b dx z ii ij ik il im in io ip bj">Plaban Nayak</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="100" aria-labelledby="100"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/dphi-tech?source=author_recirc-----30d63e222563----0---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">AI Planet</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/dphi-tech/implement-rag-with-knowledge-graph-and-llama-index-6a3370e93cdd?source=author_recirc-----30d63e222563----0---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><div title=""><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">Implement RAG with Knowledge Graph and Llama-Index</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">Hallucination is a common problem when working with large language models (LLMs). LLMs generate fluent and coherent text but often generate…</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><span>25 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>Dec 3, 2023</span></div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="191" aria-labelledby="191"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="192" aria-labelledby="192"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">959<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="101" aria-labelledby="101"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/dphi-tech/implement-rag-with-knowledge-graph-and-llama-index-6a3370e93cdd?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=author_recirc-----30d63e222563----0---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count ku kv">9</span></p></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="102" aria-labelledby="102"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="193" aria-labelledby="193"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div><div class="j i d"><div class="tf bg tg acp"></div></div></div></div></div></div></div></div></article></div></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/the-ai-forum/instruction-fine-tuning-gemma-2b-on-medical-reasoning-and-convert-the-finetuned-model-into-gguf-844191f8d329" tabindex="0"><div class="yp"><div aria-label="Instruction Fine-Tuning Gemma-2B on Medical Reasoning and Convert the finetuned model into GGUF…"><div class="yr ys yt yu yv"><img alt="Instruction Fine-Tuning Gemma-2B on Medical Reasoning and Convert the finetuned model into GGUF…" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_ARZ4864640UO7Y0vDETTbw.png" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="104" aria-labelledby="104"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=author_recirc-----30d63e222563----1---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><div class="l ee"><img alt="Plaban Nayak" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_oFXd8MlaJnMFie2YKsWB_Q(2).jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="105" aria-labelledby="105"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=author_recirc-----30d63e222563----1---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><p class="be b dx z ii ij ik il im in io ip bj">Plaban Nayak</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="106" aria-labelledby="106"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/the-ai-forum?source=author_recirc-----30d63e222563----1---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">The AI Forum</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/the-ai-forum/instruction-fine-tuning-gemma-2b-on-medical-reasoning-and-convert-the-finetuned-model-into-gguf-844191f8d329?source=author_recirc-----30d63e222563----1---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><div title="Instruction Fine-Tuning Gemma-2B on Medical Reasoning and Convert the finetuned model into GGUF…"><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">Instruction Fine-Tuning Gemma-2B on Medical Reasoning and Convert the finetuned model into GGUF…</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">Gemma is a family of lightweight, state-of-the-art open models built from the same research and technology used to create the Gemini…</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><span>33 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>Mar 10, 2024</span></div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="194" aria-labelledby="194"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="195" aria-labelledby="195"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">49<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="107" aria-labelledby="107"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/the-ai-forum/instruction-fine-tuning-gemma-2b-on-medical-reasoning-and-convert-the-finetuned-model-into-gguf-844191f8d329?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=author_recirc-----30d63e222563----1---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="108" aria-labelledby="108"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="196" aria-labelledby="196"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div><div class="j i d"><div class="tf bg tg acp"></div></div></div></div></div></div></div></div></article></div></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/dphi-tech/implementing-rag-using-langchain-ollama-and-chainlit-on-windows-using-wsl-92d14472f15d" tabindex="0"><div class="yp"><div aria-label="Implementing RAG using Langchain Ollama and Chainlit on Windows using WSL"><div class="yr ys yt yu yv"><img alt="Implementing RAG using Langchain Ollama and Chainlit on Windows using WSL" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_WDeMmVx9vlXEsggmf7GoDg.jpg" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="110" aria-labelledby="110"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=author_recirc-----30d63e222563----2---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><div class="l ee"><img alt="Plaban Nayak" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_oFXd8MlaJnMFie2YKsWB_Q(2).jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="111" aria-labelledby="111"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=author_recirc-----30d63e222563----2---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><p class="be b dx z ii ij ik il im in io ip bj">Plaban Nayak</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="112" aria-labelledby="112"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/dphi-tech?source=author_recirc-----30d63e222563----2---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">AI Planet</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/dphi-tech/implementing-rag-using-langchain-ollama-and-chainlit-on-windows-using-wsl-92d14472f15d?source=author_recirc-----30d63e222563----2---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><div title="Implementing RAG using Langchain Ollama and Chainlit on Windows using WSL"><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">Implementing RAG using Langchain Ollama and Chainlit on Windows using WSL</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">What is Ollama&nbsp;?</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><span>15 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>Nov 11, 2023</span></div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="197" aria-labelledby="197"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="198" aria-labelledby="198"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">410<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="113" aria-labelledby="113"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/dphi-tech/implementing-rag-using-langchain-ollama-and-chainlit-on-windows-using-wsl-92d14472f15d?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=author_recirc-----30d63e222563----2---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count ku kv">6</span></p></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="114" aria-labelledby="114"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="199" aria-labelledby="199"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div><div class="j i d"><div class="tf bg tg acp"></div></div></div></div></div></div></div></div></article></div></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/dphi-tech/advanced-rag-using-llama-index-e06b00dc0ed8" tabindex="0"><div class="yp"><div aria-label="Advanced RAG using Llama Index"><div class="yr ys yt yu yv"><img alt="Advanced RAG using Llama Index" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_DPWC__Fls59QNakGYagjIQ.png" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="116" aria-labelledby="116"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=author_recirc-----30d63e222563----3---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><div class="l ee"><img alt="Plaban Nayak" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_oFXd8MlaJnMFie2YKsWB_Q(2).jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="117" aria-labelledby="117"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=author_recirc-----30d63e222563----3---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><p class="be b dx z ii ij ik il im in io ip bj">Plaban Nayak</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="118" aria-labelledby="118"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/dphi-tech?source=author_recirc-----30d63e222563----3---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">AI Planet</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/dphi-tech/advanced-rag-using-llama-index-e06b00dc0ed8?source=author_recirc-----30d63e222563----3---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><div title=""><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">Advanced RAG using Llama Index</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">Here we will implement concept to improve retrieval that can be useful for contect aware text processing where we would also consider the…</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><span>13 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>Jan 8, 2024</span></div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="200" aria-labelledby="200"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="201" aria-labelledby="201"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">417<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="119" aria-labelledby="119"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/dphi-tech/advanced-rag-using-llama-index-e06b00dc0ed8?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=author_recirc-----30d63e222563----3---------------------ba83c8c3_3ce6_4fa2_b433_0ba2d4ff25d4-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count ku kv">2</span></p></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="120" aria-labelledby="120"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="202" aria-labelledby="202"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="tf bg tg dj dk acq acr acs"></div><div class="ab ib ic act acu acv"><a class="be b bf z bj qx acw acx acy wa ky wg wh sr hx acz ada adb sv adc add ade adf adg sx sy eq bl sz mt" rel="noopener follow" href="https://medium.com/@nayakpplaban?source=post_page-----30d63e222563--------------------------------"><div class="l mt">See all from Plaban Nayak</div></a><div class="adh adi adj adk adl adm adn ado adp kt l"><a class="be b bf z bj qx acw acx acy wa ky wg wh sr hx acz ada adb sv adc add ade adf adg sx sy eq bl sz mt" href="https://medium.com/the-ai-forum?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><div class="l mt">See all from The AI Forum</div></a></div></div></div></div><div class="tf bg tg adq adr ads adt adu"></div><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="adv adw l"><h2 class="be tb na nc nd ne ng nh ni nk nl nm no np nq ns nt bj">Recommended from Medium</h2><div class="pj pk pl pm pn l"><div class="wm ab jy id wn wo wp wq wr ws wt wu wv ww wx wy wz xa xb"><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/@rubenszimbres/building-knowledge-graphs-from-scratch-using-neo4j-and-vertex-ai-8311eb69a472" tabindex="0"><div class="yp"><div aria-label="Building Knowledge Graphs from Scratch Using Neo4j and Vertex AI"><div class="yr ys yt yu yv"><img alt="Building Knowledge Graphs from Scratch Using Neo4j and Vertex AI" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_VAOxnxf-oarBXc350w5zfA.png" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="122" aria-labelledby="122"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@rubenszimbres?source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div class="l ee"><img alt="Rubens Zimbres" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_iTnFtVuxXQtM9UjCEis1Pw@2x.jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="123" aria-labelledby="123"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@rubenszimbres?source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><p class="be b dx z ii ij ik il im in io ip bj">Rubens Zimbres</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@rubenszimbres/building-knowledge-graphs-from-scratch-using-neo4j-and-vertex-ai-8311eb69a472?source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div title=""><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">Building Knowledge Graphs from Scratch Using Neo4j and Vertex AI</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">Recently I watched Andrew Ng and Andreas Kollegger course “Knowledge Graphs for RAG” available at deeplearning.ai. The course builds…</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><span>19 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span>6 days ago</div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="203" aria-labelledby="203"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="204" aria-labelledby="204"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">95<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="124" aria-labelledby="124"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/@rubenszimbres/building-knowledge-graphs-from-scratch-using-neo4j-and-vertex-ai-8311eb69a472?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="125" aria-labelledby="125"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="205" aria-labelledby="205"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div><div class="j i d"><div class="tf bg tg acp"></div></div></div></div></div></div></div></div></article></div></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/singapore-gds/from-conventional-rag-to-graph-rag-a0202a1aaca7" tabindex="0"><div class="yp"><div aria-label="From Conventional RAG to Graph RAG"><div class="yr ys yt yu yv"><img alt="From Conventional RAG to Graph RAG" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_kTLrCRzQp9kLp5LfuZeV0Q.png" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="127" aria-labelledby="127"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@Terencelucasyap?source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div class="l ee"><img alt="Terence Lucas Yap" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/2_SseOYP9ej_mUdj2K24QzpA.jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="128" aria-labelledby="128"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@Terencelucasyap?source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><p class="be b dx z ii ij ik il im in io ip bj">Terence Lucas Yap</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="129" aria-labelledby="129"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/singapore-gds?source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">Government Digital Services, Singapore</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/singapore-gds/from-conventional-rag-to-graph-rag-a0202a1aaca7?source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div title=""><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">From Conventional RAG to Graph RAG</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">When Large Language Models Meet Knowledge Graphs</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><span>13 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>Mar 16, 2024</span></div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="206" aria-labelledby="206"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="207" aria-labelledby="207"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">38<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="130" aria-labelledby="130"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/singapore-gds/from-conventional-rag-to-graph-rag-a0202a1aaca7?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="131" aria-labelledby="131"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="208" aria-labelledby="208"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div><div class="tf bg tg adx"></div><h2 class="be tb hq z fq bj">Lists</h2><div class="acp l"><div class="cm ab jy id wn wo wp wq wr ws wt wu wv ww wx wy wz xa xb"><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" rel="noopener follow" href="https://medium.com/@AMGAS14/list/natural-language-processing-0a856388a93a?source=read_next_recirc-----30d63e222563--------------------------------"><div class="aed aee ii ab ia ee"><div class="ee yw adz bw aea"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_e1qCHbEjGoJFEX6Kxn91SA.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee yw adz bw jz aeb"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_mfZP8TZsoNwTSF9YJMAQlQ.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee yw bw hm aec"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_4nt7sX_aOh-v_QhRv8AjhA.png" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be tb hq z ii qj ik il qk in ip fq bj">Natural Language Processing</h2><div class="be b dx z dw ab ady">1313 stories<span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span>806 saves</div></div></a></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" rel="noopener follow" href="https://medium.com/@MediumStaff/list/ai-regulation-dfa78dfd2438?source=read_next_recirc-----30d63e222563--------------------------------"><div class="aed aee ii ab ia ee"><div class="ee yw adz bw aea"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_era76EGCwdY2gWSFKutuSw.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee yw adz bw jz aeb"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_AiTJDz5wwQFiUCf_SrBOQA.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee yw bw hm aec"><div class="yw he ii l"><img alt="A phone with a tweet on it describing a deepfake video of the Ukrainian president, with a labeled fake image in the background" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_zjPggFS8yoRtFbAP9R_3lw.jpg" width="48" height="48" loading="lazy"></div></div></div><div class="aw l"><h2 class="be tb hq z ii qj ik il qk in ip fq bj">AI Regulation</h2><div class="be b dx z dw ab ady">6 stories<span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span>382 saves</div></div></a></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" rel="noopener follow" href="https://medium.com/@grexe/list/data-science-and-ai-35d21381d956?source=read_next_recirc-----30d63e222563--------------------------------"><div class="aed aee ii ab ia ee"><div class="ee yw adz bw aea"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_Fwpkf8H5PwNrzSzMYUFjjA.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee yw adz bw jz aeb"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_G49cai7vIuhFeSwb4LCuSQ.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee yw bw hm aec"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_HlJ2e41GVVzzjWYiX0dU1g.png" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be tb hq z ii qj ik il qk in ip fq bj">data science and AI</h2><div class="be b dx z dw ab ady">40 stories<span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span>112 saves</div></div></a></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" rel="noopener follow" href="https://medium.com/@jscribes/list/coding-development-e360d380bb82?source=read_next_recirc-----30d63e222563--------------------------------"><div class="aed aee ii ab ia ee"><div class="ee yw adz bw aea"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/0_gzCeWxDtGmD23QR5.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee yw adz bw jz aeb"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_di4WDrnS1F6_p9GWnxvPmg.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee yw bw hm aec"><div class="yw he ii l"><img alt="" class="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_PzJLbFrFtNkqPsxielO8zA.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be tb hq z ii qj ik il qk in ip fq bj">Coding &amp; Development</h2><div class="be b dx z dw ab ady">11 stories<span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span>519 saves</div></div></a></div></div></div><div class="tf bg tg adi dj adk dk aef aeg aeh aei aej aek"></div><div class="wm ab jy id wn wo wp wq wr ws wt wu wv ww wx wy wz xa xb"><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/ai-in-plain-english/advanced-rag-07-exploring-rag-for-tables-5c3fc0de7af6" tabindex="0"><div class="yp"><div aria-label="Advanced RAG 07: Exploring RAG for Tables"><div class="yr ys yt yu yv"><img alt="Advanced RAG 07: Exploring RAG for Tables" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_EbBEUEZk6YN4aeST0gJu3Q.png" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="133" aria-labelledby="133"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@florian_algo?source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div class="l ee"><img alt="Florian June" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_DmQ3DH2JeAJquvhT_tjVCw.jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="134" aria-labelledby="134"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@florian_algo?source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><p class="be b dx z ii ij ik il im in io ip bj">Florian June</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="135" aria-labelledby="135"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/ai-in-plain-english?source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">Artificial Intelligence in Plain English</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/ai-in-plain-english/advanced-rag-07-exploring-rag-for-tables-5c3fc0de7af6?source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div title=""><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">Advanced RAG 07: Exploring RAG for Tables</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">Table parsing, index structure and table summary acquisition method.</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><div class="rk ab"><div class="bl" aria-hidden="false" aria-describedby="136" aria-labelledby="136"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="137" aria-labelledby="137"><svg width="16" height="16" viewBox="0 0 64 64" fill="none"><path d="M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>19 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>Mar 16, 2024</span></div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="209" aria-labelledby="209"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="210" aria-labelledby="210"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">422<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="138" aria-labelledby="138"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/ai-in-plain-english/advanced-rag-07-exploring-rag-for-tables-5c3fc0de7af6?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----30d63e222563----0---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count ku kv">1</span></p></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="139" aria-labelledby="139"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="211" aria-labelledby="211"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div><div class="j i d"><div class="tf bg tg acp"></div></div></div></div></div></div></div></div></article></div></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/towards-data-science/intro-to-llm-agents-with-langchain-when-rag-is-not-enough-7d8c08145834" tabindex="0"><div class="yp"><div aria-label="Intro to LLM Agents with Langchain: When RAG is Not Enough"><div class="yr ys yt yu yv"><img alt="Intro to LLM Agents with Langchain: When RAG is Not Enough" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/0_3O1QAj_62FzWydQj.png" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="141" aria-labelledby="141"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@alexhonchar?source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div class="l ee"><img alt="Alex Honchar" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_iNhT3ND48_WSNLMz44OnzA.jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="142" aria-labelledby="142"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@alexhonchar?source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><p class="be b dx z ii ij ik il im in io ip bj">Alex Honchar</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="143" aria-labelledby="143"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/towards-data-science?source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">Towards Data Science</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/towards-data-science/intro-to-llm-agents-with-langchain-when-rag-is-not-enough-7d8c08145834?source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div title=""><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">Intro to LLM Agents with Langchain: When RAG is Not Enough</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">First-order principles of brain structure for AI assistants</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><span>7 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>Mar 15, 2024</span></div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="212" aria-labelledby="212"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="213" aria-labelledby="213"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">1.2K<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="144" aria-labelledby="144"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/towards-data-science/intro-to-llm-agents-with-langchain-when-rag-is-not-enough-7d8c08145834?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----30d63e222563----1---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count ku kv">7</span></p></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="145" aria-labelledby="145"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="214" aria-labelledby="214"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div><div class="j i d"><div class="tf bg tg acp"></div></div></div></div></div></div></div></div></article></div></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/towards-artificial-intelligence/how-to-do-rag-without-vector-databases-45fd4f6ced06" tabindex="0"><div class="yp"><div aria-label="How To Do RAG Without Vector Databases"><div class="yr ys yt yu yv"><img alt="How To Do RAG Without Vector Databases" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/0_zzq8qXhV7STt-Tyu.jpg" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="147" aria-labelledby="147"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@_init_?source=read_next_recirc-----30d63e222563----2---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div class="l ee"><img alt="___" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_kzgXRp5qsdXsP57SUKD5dA.png" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="148" aria-labelledby="148"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@_init_?source=read_next_recirc-----30d63e222563----2---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><p class="be b dx z ii ij ik il im in io ip bj">___</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="149" aria-labelledby="149"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/towards-artificial-intelligence?source=read_next_recirc-----30d63e222563----2---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">Towards AI</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/towards-artificial-intelligence/how-to-do-rag-without-vector-databases-45fd4f6ced06?source=read_next_recirc-----30d63e222563----2---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div title=""><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">How To Do RAG Without Vector Databases</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">Knowledge Graphs Are All You Need 😀</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><div class="rk ab"><div class="bl" aria-hidden="false" aria-describedby="150" aria-labelledby="150"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="151" aria-labelledby="151"><svg width="16" height="16" viewBox="0 0 64 64" fill="none"><path d="M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>10 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span>Mar 3, 2024</span></div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="215" aria-labelledby="215"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="216" aria-labelledby="216"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">386<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="152" aria-labelledby="152"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/towards-artificial-intelligence/how-to-do-rag-without-vector-databases-45fd4f6ced06?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----30d63e222563----2---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count ku kv">1</span></p></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="153" aria-labelledby="153"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="217" aria-labelledby="217"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div><div class="j i d"><div class="tf bg tg acp"></div></div></div></div></div></div></div></div></article></div></div><div class="xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw"><div class="xx xy xz ya yb dy l"><article class="dy"><div class="dy rk l"><div class="bg dy"><div class="dy l"><div class="ee dy yc yd ye yf yg yh yi yj yk yl ym yn yo" role="link" data-href="https://medium.com/rahasak/build-rag-application-using-a-llm-running-on-local-computer-with-ollama-and-langchain-e6513853fda0" tabindex="0"><div class="yp"><div aria-label="Build RAG Application Using a LLM Running on Local Computer with Ollama and Langchain"><div class="yr ys yt yu yv"><img alt="Build RAG Application Using a LLM Running on Local Computer with Ollama and Langchain" class="bg yw yx yy yz bw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_VbfLqLXGUQrz4lSgnnsVMg.png" loading="lazy"></div></div></div><div class="yq ab ca cn"><div class="ab cn za bg zb zc zd ze"><div class="zf zg zh zi zj ab q"><div class="qw l"><div><div class="l" aria-hidden="false" aria-describedby="155" aria-labelledby="155"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@lambdaEranga?source=read_next_recirc-----30d63e222563----3---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div class="l ee"><img alt="(λx.x)eranga" class="l eq bx zk zl cw" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1_WpIlZqFbVSA9M7Rev_zVdg.jpg" width="20" height="20" loading="lazy"><div class="em bx l zk zl eo n ax ep"></div></div></a></div></div></div><div class="zm l"><div><div class="l" aria-hidden="false" aria-describedby="156" aria-labelledby="156"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" rel="noopener follow" href="https://medium.com/@lambdaEranga?source=read_next_recirc-----30d63e222563----3---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><p class="be b dx z ii ij ik il im in io ip bj">(λx.x)eranga</p></a></div></div></div><div class="zm l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="157" aria-labelledby="157"><a class="af ag ah ai aj ak al am an ao ap aq ar hs ab q" href="https://medium.com/rahasak?source=read_next_recirc-----30d63e222563----3---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------" rel="noopener follow"><p class="be b dx z ii ij ik il im in io ip bj">Effectz.AI</p></a></div></div></div></div><div class="zn zo zp zq zr zs zt zu zv zw l fk"><div class="zx zy zz aba abb abc abd abe"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/rahasak/build-rag-application-using-a-llm-running-on-local-computer-with-ollama-and-langchain-e6513853fda0?source=read_next_recirc-----30d63e222563----3---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><div title="Build RAG Application Using a LLM Running on Local Computer with Ollama and Langchain"><h2 class="be fs na nc abf abg nd ne ng abh abi nh og abj abk abl abm ok abn abo abp abq oo abr abs abt abu ii ik il in ip bj">Build RAG Application Using a LLM Running on Local Computer with Ollama and Langchain</h2></div><div class="abv l"><h3 class="be b hq z ii qj ik il qk in ip dw">Privacy-preserving LLM without GPU</h3></div></a></div></div><span class="be b dx z dw"><div class="ab q"><span>16 min read</span><span class="ht l" aria-hidden="true"><span class="be b bf z dw">·</span></span>6 days ago</div></span><div class="abw abx aby abz aca l"><div class="ab co"><div class="am acb acc acd ace acf acg ach aci acj ack ab q"><div class="ab q jy jz"><div class="pw-multi-vote-icon ee ih ka kb kc"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="218" aria-labelledby="218"><button class="kd ao kf vx vy kj am kk kl km kc"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l kn ko kp kq kr ks kt"><div><div class="bl" aria-hidden="false" aria-describedby="219" aria-labelledby="219"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at vz wa">349<span class="l h g f rr rs"></span></button></p></div></div></div></div><div class="acl l"><div><div class="bl" aria-hidden="false" aria-describedby="158" aria-labelledby="158"><a class="af ef ah kd aj ak al kx an ao ap aq ar as at kw ab q ky kz" aria-label="responses" rel="noopener follow" href="https://medium.com/rahasak/build-rag-application-using-a-llm-running-on-local-computer-with-ollama-and-langchain-e6513853fda0?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----30d63e222563----3---------------------c54de748_4f16_4f3b_b7b3_5a93009c38bd-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count ku kv">2</span></p></a></div></div></div></div><div class="ab q acm acn"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="159" aria-labelledby="159"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al an ao ap hx lc ld le"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lf"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="aco l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="220" aria-labelledby="220"><button aria-label="More options" class="af ef ah ai aj ak al an ao ap hx ln lo kz lp"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="tf bg tg dj dk acq acr acs"></div><a class="be b bf z bj qx acw acx acy wa ky wg wh sr hx acz ada adb sv adc add ade adf adg sx sy eq bl sz mt" rel="noopener follow" href="https://medium.com/?source=post_page-----30d63e222563--------------------------------"><div class="l mt">See more recommendations</div></a></div></div></div><div class="h k j"><div class="tf bg tg th"></div><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="ti ab jy id"><div class="tj tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><p class="be b dx z dw">Help</p></a></div><div class="tj tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><p class="be b dx z dw">Status</p></a></div><div class="tj tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/about?autoplay=1&amp;source=post_page-----30d63e222563--------------------------------"><p class="be b dx z dw">About</p></a></div><div class="tj tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----30d63e222563--------------------------------"><p class="be b dx z dw">Careers</p></a></div><div class="tj tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><p class="be b dx z dw">Blog</p></a></div><div class="tj tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><p class="be b dx z dw">Privacy</p></a></div><div class="tj tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><p class="be b dx z dw">Terms</p></a></div><div class="tj tk l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----30d63e222563--------------------------------" rel="noopener follow"><p class="be b dx z dw">Text to speech</p></a></div><div class="tj l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/business?source=post_page-----30d63e222563--------------------------------"><p class="be b dx z dw">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20240322-235058-82fb4124e4"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"User is logged in","group":"disabled","tags":["group-edgeCachePosts","post-30d63e222563","user-83650c0fa832","collection-d318104265a3"],"serverVariantState":"","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[],"loHomepageEnabled":false,"updatedPostPreviewsEnabled":false,"customMocPreviewWeightThreshold":"control","lohpBgColorGroup":"control","lohpCopyGroup":"control"},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"DEFAULT","explicit":false},"viewerIsBot":false},"debug":{"requestId":"a325f5d1-e008-42db-b3ae-578bd2fee8bf","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"0e4518fb7889ab34","ot-tracer-traceid":"2d8765794aa211d9","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002Fthe-ai-forum\u002Fimplementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563","host":"medium.com","hostname":"medium.com","referrer":"https:\u002F\u002Fmedium.com\u002Fsearch?q=langchain","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"config":{"nodeEnv":"production","version":"main-20240322-235058-82fb4124e4","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20240322-235058-82fb4124e4","commit":"82fb4124e4e429d1d5a270a35d2694f34346c9ec"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":"197f8766e2f2"}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","variantFlags":[{"__typename":"VariantFlag","name":"enable_sprig","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lohp_copy","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"ios_enable_friend_links_postpage_banners","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_lists_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_receive_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lohp_button","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_aggregator_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_autorefresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_topic_portals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_verified_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_premium_plan","valueType":{"__typename":"VariantFlagString","value":"12a660186432"}},{"__typename":"VariantFlag","name":"enable_entities_to_follow_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_premium_tier_badge","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_friend_links_postpage_banners","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"textshots_userid","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"ios_remove_twitter_onboarding_step","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mps_pp_writer_stats","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_aspiriational","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lohp_bg_color","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"price_smoke_test_monthly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"android_enable_friend_links_creation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_image_sharer","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_premium_tier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_redesign_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_friend_links_creation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_custom_moc_preview_weight_threshold","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_new_push_notification_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_widget","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_maim_the_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"onboarding_tags_from_top_views","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_avatar_upload","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_yearly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_android_dynamic_programming_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_eventstats_event_processing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members_username_selection","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_miro_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_verifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_two_hour_refresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_custom_moc_preview_weight_threshold_li","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_archive_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_switch_plan_premium_tier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_simplified_digest_v2_b","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_premium_plan","valueType":{"__typename":"VariantFlagString","value":"4a442ace1476"}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recaptcha_enterprise","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_verified_book_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_new_user_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sharer_create_post_share_key","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"crm_send_contact_to_sendgrid","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_easy_resubscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pre_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_redesign_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cache_less_following_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_dashboard_referred_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recirc_model","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound-source-serif-pro"}},{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_syntax_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefined_top_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_follow_on_subscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_play_purchase_on_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_members_only_audio","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_editor_new_publishing_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_fs_cache_user_vals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_moc_load_processor_c","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"web_enable_syntax_highlighting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_programming","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_display_paywall_after_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_explicit_signals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_send_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_deprecate_legacy_providers_v3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sharer_validate_post_share_key","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"isLoggedIn":true,"collectionByDomainOrSlug({\"domainOrSlug\":\"the-ai-forum\"})":{"__ref":"Collection:d318104265a3"},"viewer":{"__ref":"User:ceb44ee85b4a"},"postResult({\"id\":\"30d63e222563\"})":{"__ref":"Post:30d63e222563"}},"ImageMetadata:":{"__typename":"ImageMetadata","id":"","originalWidth":0,"originalHeight":0},"Collection:d318104265a3":{"__typename":"Collection","id":"d318104265a3","favicon":{"__ref":"ImageMetadata:"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFFFFFFF","point":0},{"__typename":"ColorPoint","color":"#FFE8F3E8","point":0.1},{"__typename":"ColorPoint","color":"#FFE8F3E8","point":0.2},{"__typename":"ColorPoint","color":"#FFD1E7D1","point":0.6},{"__typename":"ColorPoint","color":"#FFA3D0A2","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF1A8917","point":0},{"__typename":"ColorPoint","color":"#FF11800E","point":0.1},{"__typename":"ColorPoint","color":"#FF0F730C","point":0.2},{"__typename":"ColorPoint","color":"#FF095407","point":1}]},"tintBackgroundSpectrum":null},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:de559acb6499"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:83650c0fa832"}}],"name":"The AI Forum","avatar":{"__ref":"ImageMetadata:1*p9oOISlQYwVpgPGEaGPuDA.png"},"domain":null,"slug":"the-ai-forum","description":"Its AI forum where all the topics spread across Data Analytics, Data Science, Machine Learning, Deep Learning are discussed.","subscriberCount":5,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:d318104265a3-viewerId:ceb44ee85b4a"},"twitterUsername":null,"facebookPageId":null,"logo":{"__ref":"ImageMetadata:"}},"UserViewerEdge:userId:ceb44ee85b4a-viewerId:ceb44ee85b4a":{"__typename":"UserViewerEdge","id":"userId:ceb44ee85b4a-viewerId:ceb44ee85b4a","createdAt":1698747875172},"User:ceb44ee85b4a":{"__typename":"User","id":"ceb44ee85b4a","allowEmailAddressSharingEditorWriter":false,"atsQualifiedAt":0,"dismissableFlags":[],"emailObfuscated":"vo•••••••••••@gmail.com","geolocation":{"__typename":"Geolocation","country":"VN"},"hasGroupGiftingEnabled":false,"hasPastMemberships":false,"hasSubdomain":false,"imageId":"0*oR99AaaRsUWrB2B5","isEligibleToImportEmails":false,"isEligibleToViewNewResponses":true,"isMembershipTrialEligible":true,"isSuspended":false,"membership":null,"name":"Vonhuy","partnerProgramEnrollment":null,"postSubscribeMembershipUpsellShownAt":0,"styleEditorOnboardingVersionSeen":0,"twitterScreenName":"","unverifiedEmail":"","username":"vonhuy5112002","viewerEdge":{"__ref":"UserViewerEdge:userId:ceb44ee85b4a-viewerId:ceb44ee85b4a"}},"User:de559acb6499":{"__typename":"User","id":"de559acb6499"},"User:83650c0fa832":{"__typename":"User","id":"83650c0fa832","name":"Plaban Nayak","username":"nayakpplaban","newsletterV3":{"__ref":"NewsletterV3:c7179532ea8d"},"linkedAccounts":{"__ref":"LinkedAccounts:83650c0fa832"},"isSuspended":false,"imageId":"1*oFXd8MlaJnMFie2YKsWB_Q.jpeg","mediumMemberAt":1702123766000,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":1479},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"nayakpplaban.medium.com"}},"hasSubdomain":true,"bio":"Machine Learning and Deep Learning enthusiast","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:83650c0fa832-viewerId:ceb44ee85b4a"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"membership":{"__ref":"Membership:a2c46bdcaa9a"},"twitterScreenName":""},"ImageMetadata:1*p9oOISlQYwVpgPGEaGPuDA.png":{"__typename":"ImageMetadata","id":"1*p9oOISlQYwVpgPGEaGPuDA.png"},"LinkedAccounts:83650c0fa832":{"__typename":"LinkedAccounts","mastodon":null,"id":"83650c0fa832"},"UserViewerEdge:userId:83650c0fa832-viewerId:ceb44ee85b4a":{"__typename":"UserViewerEdge","id":"userId:83650c0fa832-viewerId:ceb44ee85b4a","isFollowing":false,"isUser":false,"isMuting":false},"NewsletterV3:c7179532ea8d":{"__typename":"NewsletterV3","id":"c7179532ea8d","type":"NEWSLETTER_TYPE_AUTHOR","slug":"83650c0fa832","name":"83650c0fa832","collection":null,"user":{"__ref":"User:83650c0fa832"}},"Paragraph:53e976030fef_0":{"__typename":"Paragraph","id":"53e976030fef_0","name":"bd62","type":"H3","href":null,"layout":null,"metadata":null,"text":"Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg":{"__typename":"ImageMetadata","id":"1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg","originalHeight":512,"originalWidth":721,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:53e976030fef_1":{"__typename":"Paragraph","id":"53e976030fef_1","name":"044b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg"},"text":"Corrective RAG workflow","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_2":{"__typename":"Paragraph","id":"53e976030fef_2","name":"c690","type":"H3","href":null,"layout":null,"metadata":null,"text":"What happens in Native RAG ?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_3":{"__typename":"Paragraph","id":"53e976030fef_3","name":"8e00","type":"P","href":null,"layout":null,"metadata":null,"text":"Preproduction Setup:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_4":{"__typename":"Paragraph","id":"53e976030fef_4","name":"04a2","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The Knowledge Source is loaded and formatted using Langchain Orchestration Framework.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_5":{"__typename":"Paragraph","id":"53e976030fef_5","name":"16ca","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The Formatted Documents is then split into semantically relevant chunks.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_6":{"__typename":"Paragraph","id":"53e976030fef_6","name":"11f4","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Convert the chunks into vector embeddings using an Embedding Model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_7":{"__typename":"Paragraph","id":"53e976030fef_7","name":"d63b","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Load the Vector Embeddings into the VectorStore.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_8":{"__typename":"Paragraph","id":"53e976030fef_8","name":"fd18","type":"P","href":null,"layout":null,"metadata":null,"text":"Production Setup:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_9":{"__typename":"Paragraph","id":"53e976030fef_9","name":"2f61","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Set up the LLM for Response Synthesis.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_10":{"__typename":"Paragraph","id":"53e976030fef_10","name":"7af7","type":"OLI","href":null,"layout":null,"metadata":null,"text":"User asks a query.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_11":{"__typename":"Paragraph","id":"53e976030fef_11","name":"0fe5","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The query is converted into vector embeddings uisng and Embedding Model.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":72,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_12":{"__typename":"Paragraph","id":"53e976030fef_12","name":"4857","type":"OLI","href":null,"layout":null,"metadata":null,"text":"This embedding is then matched against the Knowledge Source embeddings stored in the VectorStore.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":97,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_13":{"__typename":"Paragraph","id":"53e976030fef_13","name":"f2b2","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Find top-k similar documents matching the user query.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":53,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_14":{"__typename":"Paragraph","id":"53e976030fef_14","name":"84a4","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Postprocess and aggregate matched documents retrieved into a context .","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":70,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_15":{"__typename":"Paragraph","id":"53e976030fef_15","name":"2a71","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Generate a prompt based on the user query and context and pass it to the LLM.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":77,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_16":{"__typename":"Paragraph","id":"53e976030fef_16","name":"83b9","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The LLM then synthesizes the response based on the prompt \u002Finstruction provided.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":80,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_17":{"__typename":"Paragraph","id":"53e976030fef_17","name":"1bd9","type":"H3","href":null,"layout":null,"metadata":null,"text":"What are the benefits of RAG?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_18":{"__typename":"Paragraph","id":"53e976030fef_18","name":"2360","type":"P","href":null,"layout":null,"metadata":null,"text":"There are several important advantages to the RAG approach:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_19":{"__typename":"Paragraph","id":"53e976030fef_19","name":"567c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RAG makes sure that an LLM’s response isn’t based just on old, stagnant training data. Instead, the model gets its answers from current external data sources.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":158,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_20":{"__typename":"Paragraph","id":"53e976030fef_20","name":"935e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"RAG aims to reduce the possibility of reacting with false or misleading information (sometimes referred to as hallucinations) by basing the LLM model’s output on pertinent, outside knowledge. Citations to the original sources can be included in the outputs, enabling human verification.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":286,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_21":{"__typename":"Paragraph","id":"53e976030fef_21","name":"d137","type":"ULI","href":null,"layout":null,"metadata":null,"text":"By utilizing RAG, the LLM can deliver contextually appropriate answers that are customized to an organization’s proprietary or domain-specific data.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":148,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_22":{"__typename":"Paragraph","id":"53e976030fef_22","name":"5896","type":"P","href":null,"layout":null,"metadata":null,"text":"In contrast to alternative methods of integrating domain-specific data into LLM customization, RAG is simple and cost-effective. Organizations can deploy RAG without needing to customize the model. This is especially beneficial when models need to be updated frequently with new data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_23":{"__typename":"Paragraph","id":"53e976030fef_23","name":"428c","type":"H3","href":null,"layout":null,"metadata":null,"text":"What is Corrective RAG ?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_24":{"__typename":"Paragraph","id":"53e976030fef_24","name":"d1c2","type":"P","href":null,"layout":null,"metadata":null,"text":"Corrective RAG is a comprehensive framework that combines retrieval evaluation, corrective actions, web searches, and generative model integration to enhance the accuracy, reliability, and robustness of text generation models by ensuring the utilization of accurate and relevant knowledge,","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_25":{"__typename":"Paragraph","id":"53e976030fef_25","name":"d372","type":"P","href":null,"layout":null,"metadata":null,"text":"In simple terms, Corrective RAG is the method used to grade documents based on their relevance to the data source. If the data source is related to the question, the process proceeds to generation. Otherwise, the framework seeks additional data sources and utilizes web search to supplement retrieval. But in this example instead of seeking additional data sources we will simply discarded the non-relevant data sources.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_26":{"__typename":"Paragraph","id":"53e976030fef_26","name":"f70d","type":"H3","href":null,"layout":null,"metadata":null,"text":"Technology Stack","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_27":{"__typename":"Paragraph","id":"53e976030fef_27","name":"991c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Langchain : Orchestration framework to develop LLM Applications","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":9,"href":"https:\u002F\u002Fpython.langchain.com\u002Fdocs\u002Fget_started\u002Fintroduction","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_28":{"__typename":"Paragraph","id":"53e976030fef_28","name":"8796","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Zephyr-7B-beta : LLM","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":14,"href":"https:\u002F\u002Fhuggingface.co\u002FHuggingFaceH4\u002Fzephyr-7b-beta","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_29":{"__typename":"Paragraph","id":"53e976030fef_29","name":"b05d","type":"ULI","href":null,"layout":null,"metadata":null,"text":"OpenAI : To grade the retrieved contexts","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":6,"href":"https:\u002F\u002Fplatform.openai.com\u002Fdocs\u002Fintroduction","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_30":{"__typename":"Paragraph","id":"53e976030fef_30","name":"2b85","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ragatouille :RAGatouille focuses on making ColBERT","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":11,"href":"https:\u002F\u002Fgithub.com\u002Fbclavie\u002FRAGatouille","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_31":{"__typename":"Paragraph","id":"53e976030fef_31","name":"3a70","type":"H3","href":null,"layout":null,"metadata":null,"text":"Code Implementation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_32":{"__typename":"Paragraph","id":"53e976030fef_32","name":"716d","type":"P","href":null,"layout":null,"metadata":null,"text":"Install required dependencies","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_33":{"__typename":"Paragraph","id":"53e976030fef_33","name":"5aa3","type":"PRE","href":null,"layout":null,"metadata":null,"text":"pip install -q transformers \npip install -q accelerate \npip install -q bitsandbytes \npip install -q langchain \npip install -q sentence-transformers \npip install -q chromadb openpyxl \npip install -q ragatouille \npip install -q langchain_openai\npip install -q datasets","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_34":{"__typename":"Paragraph","id":"53e976030fef_34","name":"8da2","type":"P","href":null,"layout":null,"metadata":null,"text":"Import Required Dependencies","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_35":{"__typename":"Paragraph","id":"53e976030fef_35","name":"1358","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from tqdm.notebook import tqdm\nimport pandas as pd\nfrom typing import Optional, List, Tuple\nfrom datasets import Dataset\nimport matplotlib.pyplot as plt\n\npd.set_option(\"display.max_colwidth\", None)  # this will be helpful when visualizing retriever outputs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_36":{"__typename":"Paragraph","id":"53e976030fef_36","name":"8b15","type":"P","href":null,"layout":null,"metadata":null,"text":"Load the Knowledge Source","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_37":{"__typename":"Paragraph","id":"53e976030fef_37","name":"e110","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import datasets\n\nds = datasets.load_dataset(\"m-ric\u002Fhuggingface_doc\", split=\"train\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_38":{"__typename":"Paragraph","id":"53e976030fef_38","name":"5cdd","type":"P","href":null,"layout":null,"metadata":null,"text":"Format the datasets into Langchain Document Schema","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_39":{"__typename":"Paragraph","id":"53e976030fef_39","name":"1267","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain.docstore.document import Document as LangchainDocument\n\nRAW_KNOWLEDGE_BASE = [\n    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]}) for doc in tqdm(ds)\n]\nprint(len(RAW_KNOWLEDGE_BASE))\nprint(RAW_KNOWLEDGE_BASE[1].page_content)\nprint(RAW_KNOWLEDGE_BASE[1].metadata)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_40":{"__typename":"Paragraph","id":"53e976030fef_40","name":"a9a1","type":"P","href":null,"layout":null,"metadata":null,"text":"Split the documents into chunks","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_41":{"__typename":"Paragraph","id":"53e976030fef_41","name":"bcd7","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# We use a hierarchical list of separators specifically tailored for splitting Markdown documents\n# This list is taken from LangChain's MarkdownTextSplitter class.\nMARKDOWN_SEPARATORS = [\n    \"\\n#{1,6} \",\n    \"```\\n\",\n    \"\\n\\\\*\\\\*\\\\*+\\n\",\n    \"\\n---+\\n\",\n    \"\\n___+\\n\",\n    \"\\n\\n\",\n    \"\\n\",\n    \" \",\n    \"\",\n]\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,  # the maximum number of characters in a chunk: we selected this value arbitrarily\n    chunk_overlap=100,  # the number of characters to overlap between chunks\n    add_start_index=True,  # If `True`, includes chunk's start index in metadata\n    strip_whitespace=True,  # If `True`, strips whitespace from the start and end of every document\n    separators=MARKDOWN_SEPARATORS,\n)\n\ndocs_processed = []\nfor doc in RAW_KNOWLEDGE_BASE:\n    docs_processed += text_splitter.split_documents([doc])","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_42":{"__typename":"Paragraph","id":"53e976030fef_42","name":"c105","type":"P","href":null,"layout":null,"metadata":null,"text":"Setup Embedding Model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_43":{"__typename":"Paragraph","id":"53e976030fef_43","name":"4885","type":"P","href":null,"layout":null,"metadata":null,"text":"We also have to keep in mind that when embedding documents, we will use an embedding model that has accepts a certain maximum sequence length max_seq_length. So we should make sure that our chunk sizes are below this limit, because any longer chunk will be truncated before processing, thus losing relevancy.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":308,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_44":{"__typename":"Paragraph","id":"53e976030fef_44","name":"5301","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from sentence_transformers import SentenceTransformer\n\n# To get the value of the max sequence_length, we will query the underlying `SentenceTransformer` object used in the RecursiveCharacterTextSplitter.\nprint(f\"Model's maximum sequence length: {SentenceTransformer('thenlper\u002Fgte-small').max_seq_length}\")\n\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"thenlper\u002Fgte-small\")\nlengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n\n# Plot the distrubution of document lengths, counted as the number of tokens\nfig = pd.Series(lengths).hist()\nplt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\nplt.show()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*0t0nleN1NH9_tpSsZgSAlw.png":{"__typename":"ImageMetadata","id":"1*0t0nleN1NH9_tpSsZgSAlw.png","originalHeight":435,"originalWidth":654,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:53e976030fef_45":{"__typename":"Paragraph","id":"53e976030fef_45","name":"e1df","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*0t0nleN1NH9_tpSsZgSAlw.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_46":{"__typename":"Paragraph","id":"53e976030fef_46","name":"21bf","type":"P","href":null,"layout":null,"metadata":null,"text":"As you can see, the chunk lengths are not aligned with our limit of 512 tokens, and some documents are above the limit, thus some part of them will be lost in truncation!","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":170,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_47":{"__typename":"Paragraph","id":"53e976030fef_47","name":"500e","type":"P","href":null,"layout":null,"metadata":null,"text":"So we should change the RecursiveCharacterTextSplitter class to count length in number of tokens instead of number of characters. Then we can choose a specific chunk size, here we would choose a lower threshold than 512: smaller documents could allow the split to focus more on specific ideas. But too small chunks would split sentences in half, thus losing meaning again: the proper tuning is a matter of balance.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":414,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_48":{"__typename":"Paragraph","id":"53e976030fef_48","name":"1b08","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom transformers import AutoTokenizer\n\nEMBEDDING_MODEL_NAME = \"thenlper\u002Fgte-small\"\nchunk_size = 512\n#\ntext_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n        AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME),\n        chunk_size=chunk_size,\n        chunk_overlap=int(chunk_size \u002F 10),\n        add_start_index=True,\n        strip_whitespace=True,\n        separators=MARKDOWN_SEPARATORS,\n    )\n#\ndocs_processed = []\nfor doc in RAW_KNOWLEDGE_BASE:\n  docs_processed += text_splitter.split_documents([doc])\n\nprint(len(docs_processed)#19983","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_49":{"__typename":"Paragraph","id":"53e976030fef_49","name":"8f43","type":"P","href":null,"layout":null,"metadata":null,"text":"visualize the chunk sizes we would have in tokens from a common model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_50":{"__typename":"Paragraph","id":"53e976030fef_50","name":"88f4","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\nlengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\nfig = pd.Series(lengths).hist()\nplt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\nplt.show()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*gdQHD2x7i31OFHFe5xvLrQ.png":{"__typename":"ImageMetadata","id":"1*gdQHD2x7i31OFHFe5xvLrQ.png","originalHeight":435,"originalWidth":654,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:53e976030fef_51":{"__typename":"Paragraph","id":"53e976030fef_51","name":"e7da","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*gdQHD2x7i31OFHFe5xvLrQ.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_52":{"__typename":"Paragraph","id":"53e976030fef_52","name":"3d43","type":"P","href":null,"layout":null,"metadata":null,"text":"Setup VectorStore","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_53":{"__typename":"Paragraph","id":"53e976030fef_53","name":"af17","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from google.colab import drive\ndrive.mount('\u002Fcontent\u002Fdrive')\n#\nfrom langchain.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores.utils import DistanceStrategy\n\nembedding_model = HuggingFaceEmbeddings(\n    model_name=EMBEDDING_MODEL_NAME,\n    multi_process=True,\n    model_kwargs={\"device\": \"cuda\"},\n    encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n)\n\nKNOWLEDGE_VECTOR_DATABASE = Chroma.from_documents(docs_processed,\n                                                  embedding_model,\n                                                  persist_directory=\"\u002Fcontent\u002Fdrive\u002FMyDrive\u002FCRAG\",\n                                                  collection_name=\"crag\")\n#\nKNOWLEDGE_VECTOR_DATABASE.persist()\nprint(len(KNOWLEDGE_VECTOR_DATABASE.get()['documents']))","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_54":{"__typename":"Paragraph","id":"53e976030fef_54","name":"5391","type":"P","href":null,"layout":null,"metadata":null,"text":"According to the documentation https:\u002F\u002Fdocs.trychroma.com\u002Fusage-guide embeddings are excluded by default for performance:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":31,"end":69,"href":"https:\u002F\u002Fcolab.research.google.com\u002Fcorgiredirector?site=https%3A%2F%2Fdocs.trychroma.com%2Fusage-guide","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":0,"end":121,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_55":{"__typename":"Paragraph","id":"53e976030fef_55","name":"5a16","type":"P","href":null,"layout":null,"metadata":null,"text":"When using get or query you can use the include parameter to specify which data you want returned — any of embeddings, documents, metadatas, and for query, distances. By default, Chroma will return the documents, metadatas and in the case of query, the distances of the results. embeddings are excluded by default for performance and the ids are always returned.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":362,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_56":{"__typename":"Paragraph","id":"53e976030fef_56","name":"1443","type":"P","href":null,"layout":null,"metadata":null,"text":"You can include the embeddings when using get as followed:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":58,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_57":{"__typename":"Paragraph","id":"53e976030fef_57","name":"4a26","type":"PRE","href":null,"layout":null,"metadata":null,"text":"print(collection.get(include=['embeddings', 'documents', 'metadatas']))","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"php"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_58":{"__typename":"Paragraph","id":"53e976030fef_58","name":"7998","type":"P","href":null,"layout":null,"metadata":null,"text":"Check if the embeddings are retrieved based on user query","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_59":{"__typename":"Paragraph","id":"53e976030fef_59","name":"ed08","type":"PRE","href":null,"layout":null,"metadata":null,"text":"user_query = \"How to create a pipeline object?\"\nprint(f\"\\nStarting retrieval for {user_query=}...\")\nretrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=5)\nprint(\"\\n==================================Top document==================================\")\nprint(retrieved_docs[1].page_content)\nprint(\"==================================Metadata==================================\")\nprint(retrieved_docs[1].metadata)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_60":{"__typename":"Paragraph","id":"53e976030fef_60","name":"9b77","type":"P","href":null,"layout":null,"metadata":null,"text":"Setup the LLM","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_61":{"__typename":"Paragraph","id":"53e976030fef_61","name":"de56","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from transformers import pipeline\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import HuggingFacePipeline\n\nREADER_MODEL_NAME = \"HuggingFaceH4\u002Fzephyr-7b-beta\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n)\nmodel = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config)\ntokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n\nREADER_LLM = pipeline(\n    model=model,\n    tokenizer=tokenizer,\n    task=\"text-generation\",\n    do_sample=True,\n    temperature=0.2,\n    repetition_penalty=1.1,\n    return_full_text=False,\n    max_new_tokens=500,\n)\n#\n\nllm = HuggingFacePipeline(pipeline=READER_LLM)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_62":{"__typename":"Paragraph","id":"53e976030fef_62","name":"8e91","type":"P","href":null,"layout":null,"metadata":null,"text":"Create a Prompt","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_63":{"__typename":"Paragraph","id":"53e976030fef_63","name":"bf71","type":"PRE","href":null,"layout":null,"metadata":null,"text":"prompt_in_chat_format = [\n    {\n        \"role\": \"system\",\n        \"content\": \"\"\"Using the information contained in the context,\ngive a comprehensive answer to the question.\nRespond only to the question asked, response should be concise and relevant to the question.\nProvide the number of the source document when relevant.\nIf the answer cannot be deduced from the context, do not give an answer.\"\"\",\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"\"\"Context:\n{context}\n---\nNow here is the question you need to answer.\n\nQuestion: {question}\"\"\",\n    },\n]\nRAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n)\nprint(RAG_PROMPT_TEMPLATE)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_64":{"__typename":"Paragraph","id":"53e976030fef_64","name":"d4ee","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003C|system|\u003E\nUsing the information contained in the context,\ngive a comprehensive answer to the question.\nRespond only to the question asked, response should be concise and relevant to the question.\nProvide the number of the source document when relevant.\nIf the answer cannot be deduced from the context, do not give an answer.\u003C\u002Fs\u003E\n\u003C|user|\u003E\nContext:\n{context}\n---\nNow here is the question you need to answer.\n\nQuestion: {question}\u003C\u002Fs\u003E\n\u003C|assistant|\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_65":{"__typename":"Paragraph","id":"53e976030fef_65","name":"d0a0","type":"PRE","href":null,"layout":null,"metadata":null,"text":"retrieved_docs_text = [doc.page_content for doc in retrieved_docs]  # we only need the text of the documents\ncontext = \"\\nExtracted documents:\\n\"\ncontext += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n\nfinal_prompt = RAG_PROMPT_TEMPLATE.format(question=\"How to create a pipeline object?\", context=context)\n\nprint(final_prompt)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_66":{"__typename":"Paragraph","id":"53e976030fef_66","name":"0c72","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003C|system|\u003E\nUsing the information contained in the context,\ngive a comprehensive answer to the question.\nRespond only to the question asked, response should be concise and relevant to the question.\nProvide the number of the source document when relevant.\nIf the answer cannot be deduced from the context, do not give an answer.\u003C\u002Fs\u003E\n\u003C|user|\u003E\nContext:\n\nExtracted documents:\nDocument 0:::\n```\n\n## Available Pipelines:Document 1:::\n```\n\u003C\u002Ftf\u003E\n\u003C\u002Fframeworkcontent\u003E\n\n## Pipeline\n\n\u003CYoutube id=\"tiZFewofSLM\"\u002F\u003E\n\nThe [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:\n\n\u003CTip\u003E\n\nFor a complete list of available tasks, check out the [pipeline API reference](.\u002Fmain_classes\u002Fpipelines).\n\n\u003C\u002FTip\u003EDocument 2:::\n!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp:\u002F\u002Fwww.apache.org\u002Flicenses\u002FLICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n\n⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n--\u003E\n\n# How to create a custom pipeline?\n\nIn this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co\u002Fmodels) or add it to the\n🤗 Transformers library.\n\nFirst and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\ndictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\nas it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\npipeline (`preprocess`).\n\nThen define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n`postprocess` method.\n\nStart by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n`_forward`, `postprocess`, and `_sanitize_parameters`.\n\n\n```python\nfrom transformers import PipelineDocument 3:::\n- **Self-contained**: A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the [`DiffusionPipeline` class](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Fblob\u002F5cbed8e0d157f65d3ddc2420dfd09f2df630e978\u002Fsrc\u002Fdiffusers\u002Fpipeline_utils.py#L56) or be directly attached to the model and scheduler components of the pipeline.\n- **Easy-to-use**: Pipelines should be extremely easy to use - one should be able to load the pipeline and\nuse it for its designated task, *e.g.* text-to-image generation, in just a couple of lines of code. Most\nlogic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `__call__` method.\n- **Easy-to-tweak**: Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part –from pre-processing to diffusing to post-processing– can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our [community-examples](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Ftree\u002Fmain\u002Fexamples\u002Fcommunity). If you feel that an important pipeline should be part of the official pipelines but isn't, a contribution to the [official pipelines](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Fblob\u002Fmain\u002Fsrc\u002Fdiffusers\u002Fpipelines) would be even better.Document 4:::\n```\n\n## Pipeline\n\nYou can also push an entire pipeline with all it's components to the Hub. For example, initialize the components of a [`StableDiffusionPipeline`] with the parameters you want:\n\n```py\nfrom diffusers import (\n    UNet2DConditionModel,\n    AutoencoderKL,\n    DDIMScheduler,\n    StableDiffusionPipeline,\n)\nfrom transformers import CLIPTextModel, CLIPTextConfig, CLIPTokenizer\n\nunet = UNet2DConditionModel(\n    block_out_channels=(32, 64),\n    layers_per_block=2,\n    sample_size=32,\n    in_channels=4,\n    out_channels=4,\n    down_block_types=(\"DownBlock2D\", \"CrossAttnDownBlock2D\"),\n    up_block_types=(\"CrossAttnUpBlock2D\", \"UpBlock2D\"),\n    cross_attention_dim=32,\n)\n\nscheduler = DDIMScheduler(\n    beta_start=0.00085,\n    beta_end=0.012,\n    beta_schedule=\"scaled_linear\",\n    clip_sample=False,\n    set_alpha_to_one=False,\n)\n\nvae = AutoencoderKL(\n    block_out_channels=[32, 64],\n    in_channels=3,\n    out_channels=3,\n    down_block_types=[\"DownEncoderBlock2D\", \"DownEncoderBlock2D\"],\n    up_block_types=[\"UpDecoderBlock2D\", \"UpDecoderBlock2D\"],\n    latent_channels=4,\n)\n\ntext_encoder_config = CLIPTextConfig(\n    bos_token_id=0,\n    eos_token_id=2,\n    hidden_size=32,\n    intermediate_size=37,\n    layer_norm_eps=1e-05,\n    num_attention_heads=4,\n    num_hidden_layers=5,\n    pad_token_id=1,\n    vocab_size=1000,\n)\ntext_encoder = CLIPTextModel(text_encoder_config)\ntokenizer = CLIPTokenizer.from_pretrained(\"hf-internal-testing\u002Ftiny-random-clip\")\n---\nNow here is the question you need to answer.\n\nQuestion: How to create a pipeline object?\u003C\u002Fs\u003E\n\u003C|assistant|\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_67":{"__typename":"Paragraph","id":"53e976030fef_67","name":"5933","type":"P","href":null,"layout":null,"metadata":null,"text":"Synthesize Response","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_68":{"__typename":"Paragraph","id":"53e976030fef_68","name":"2cf7","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain_core.output_parsers import JsonOutputParser\nanswer = llm(final_prompt)\nprint(answer)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_69":{"__typename":"Paragraph","id":"53e976030fef_69","name":"2ac2","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u002Fusr\u002Flocal\u002Flib\u002Fpython3.10\u002Fdist-packages\u002Flangchain_core\u002F_api\u002Fdeprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nTo create a pipeline object, follow these steps:\n\n1. Inherit the `Pipeline` base class from the `transformers` module.\n\n2. Define the `inputs` and `outputs` of the pipeline. These can be strings, dictionaries, or any other Python data type that can be easily processed.\n\n3. Implement the four required methods: `preprocess`, `_forward`, `postprocess`, and `_sanitize_parameters`.\n\n   - `preprocess`: This method takes the raw inputs and returns a dictionary of preprocessed inputs that can be passed to the model.\n\n   - `_forward`: This method takes the preprocessed inputs and the model and returns the output of the model.\n\n   - `postprocess`: This method takes the output of the model and returns the final output of the pipeline.\n\n   - `_sanitize_parameters`: This method ensures that the input parameters are valid and converts them into a format that can be used by the model.\n\n4. Optionally, you can push the entire pipeline with all its components to the Hugging Face Hub or add it to the `transformers` library.\n\nHere's an example implementation:\n\n```python\nfrom transformers import Pipeline\n\nclass MyPipeline(Pipeline):\n    def __init__(self, model, tokenizer):\n        super().__init__(model, tokenizer)\n\n    def preprocess(self, inputs):\n        # Preprocess inputs here\n        return {\"input_ids\": inputs}\n\n    def _forward(self, inputs):\n        # Pass preprocessed inputs to the model and return the output\n        return self.model(**inputs)[0]\n\n    def postprocess(self, outputs):\n        # Postprocess the output here\n        return outputs[0]\n\n    def _sanitize_parameters(self, hparams):\n        # Sanitize input parameters here\n        return hparams\n```\n\nNote that this implementation assumes a simple text classification pipeline using the `transformers` library. Adjust the implementation according to your specific use case.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_70":{"__typename":"Paragraph","id":"53e976030fef_70","name":"1cec","type":"P","href":null,"layout":null,"metadata":null,"text":"Reranking","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_71":{"__typename":"Paragraph","id":"53e976030fef_71","name":"e47d","type":"P","href":null,"layout":null,"metadata":null,"text":"A good option for RAG is to retrieve more documents than you want in the end, then rerank the results with a more powerful retrieval model before keeping only the top_k.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":169,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_72":{"__typename":"Paragraph","id":"53e976030fef_72","name":"bda5","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from ragatouille import RAGPretrainedModel\n\nRERANKER = RAGPretrainedModel.from_pretrained(\"colbert-ir\u002Fcolbertv2.0\")\n#\nprint(\"=\u003E Reranking documents...\")\nquestion = \"How to create a pipeline object?\"\nrelevant_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=question, k=5)\nrelevant_docs = [doc.page_content for doc in relevant_docs]\nreranked_relevant_docs = RERANKER.rerank(question, relevant_docs, k=3)\n#\nreranked_docs = [doc[\"content\"] for doc in reranked_relevant_docs]\n#Compare the documents retrived for normal vector search and rereanker\nfor i,doc in enumerate(relevant_docs[:3]):\n    print(f\"Document {i}: {doc}\")\n    print(\"=\"*80)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_73":{"__typename":"Paragraph","id":"53e976030fef_73","name":"52e2","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Document 0: ```\n\n## Available Pipelines:\n================================================================================\nDocument 1: ```\n\u003C\u002Ftf\u003E\n\u003C\u002Fframeworkcontent\u003E\n\n## Pipeline\n\n\u003CYoutube id=\"tiZFewofSLM\"\u002F\u003E\n\nThe [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:\n\n\u003CTip\u003E\n\nFor a complete list of available tasks, check out the [pipeline API reference](.\u002Fmain_classes\u002Fpipelines).\n\n\u003C\u002FTip\u003E\n================================================================================\nDocument 2: !--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp:\u002F\u002Fwww.apache.org\u002Flicenses\u002FLICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n\n⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n--\u003E\n\n# How to create a custom pipeline?\n\nIn this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co\u002Fmodels) or add it to the\n🤗 Transformers library.\n\nFirst and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\ndictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\nas it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\npipeline (`preprocess`).\n\nThen define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n`postprocess` method.\n\nStart by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n`_forward`, `postprocess`, and `_sanitize_parameters`.\n\n\n```python\nfrom transformers import Pipeline\n================================================================================","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_74":{"__typename":"Paragraph","id":"53e976030fef_74","name":"8e1f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"for i,doc in enumerate(reranked_docs):\n    print(f\"Document {i}: {doc}\")\n    print(\"=\"*80)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_75":{"__typename":"Paragraph","id":"53e976030fef_75","name":"ba68","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Document 0: !--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp:\u002F\u002Fwww.apache.org\u002Flicenses\u002FLICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n\n⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n--\u003E\n\n# How to create a custom pipeline?\n\nIn this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co\u002Fmodels) or add it to the\n🤗 Transformers library.\n\nFirst and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\ndictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\nas it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\npipeline (`preprocess`).\n\nThen define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n`postprocess` method.\n\nStart by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n`_forward`, `postprocess`, and `_sanitize_parameters`.\n\n\n```python\nfrom transformers import Pipeline\n================================================================================\nDocument 1: ```\n\u003C\u002Ftf\u003E\n\u003C\u002Fframeworkcontent\u003E\n\n## Pipeline\n\n\u003CYoutube id=\"tiZFewofSLM\"\u002F\u003E\n\nThe [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:\n\n\u003CTip\u003E\n\nFor a complete list of available tasks, check out the [pipeline API reference](.\u002Fmain_classes\u002Fpipelines).\n\n\u003C\u002FTip\u003E\n================================================================================\nDocument 2: - **Self-contained**: A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the [`DiffusionPipeline` class](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Fblob\u002F5cbed8e0d157f65d3ddc2420dfd09f2df630e978\u002Fsrc\u002Fdiffusers\u002Fpipeline_utils.py#L56) or be directly attached to the model and scheduler components of the pipeline.\n- **Easy-to-use**: Pipelines should be extremely easy to use - one should be able to load the pipeline and\nuse it for its designated task, *e.g.* text-to-image generation, in just a couple of lines of code. Most\nlogic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `__call__` method.\n- **Easy-to-tweak**: Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part –from pre-processing to diffusing to post-processing– can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our [community-examples](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Ftree\u002Fmain\u002Fexamples\u002Fcommunity). If you feel that an important pipeline should be part of the official pipelines but isn't, a contribution to the [official pipelines](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Fblob\u002Fmain\u002Fsrc\u002Fdiffusers\u002Fpipelines) would be even better.\n================================================================================","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_76":{"__typename":"Paragraph","id":"53e976030fef_76","name":"d946","type":"P","href":null,"layout":null,"metadata":null,"text":"Create a prompt with reranked docs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_77":{"__typename":"Paragraph","id":"53e976030fef_77","name":"b69d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"retrieved_docs_text = [doc for doc in reranked_docs]  # we only need the text of the documents\ncontext = \"\\nExtracted documents:\\n\"\ncontext += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n\nfinal_prompt = RAG_PROMPT_TEMPLATE.format(question=\"How to create a pipeline object?\", context=context)\n\nprint(final_prompt)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_78":{"__typename":"Paragraph","id":"53e976030fef_78","name":"c0d7","type":"P","href":null,"layout":null,"metadata":null,"text":"Response Synthesis using Reranked Context","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_79":{"__typename":"Paragraph","id":"53e976030fef_79","name":"fc9f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"answer = llm(final_prompt)\nprint(answer)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_80":{"__typename":"Paragraph","id":"53e976030fef_80","name":"a381","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nTo create a pipeline object, follow these steps:\n\n1. Define the inputs and outputs of your pipeline, as described in the context.\n\n2. Inherit the `Pipeline` class from the `transformers` module, as shown in the context:\n\n   ```python\n   from transformers import PipelineDocument 1:::\n   ```\n\n3. Implement the four required methods: `preprocess`, `_forward`, `postprocess`, and `_sanitize_parameters`. Here's an example implementation:\n\n   ```python\n   class MyCustomPipeline(Pipeline):\n       def __init__(self,...):\n           super().__init__(... )\n\n       def preprocess(self, inputs):\n           # Preprocess the inputs here\n           return preprocessed_inputs\n\n       def _forward(self, inputs):\n           # Run the forward pass of your model here\n           return output\n\n       def postprocess(self, outputs):\n           # Postprocess the outputs here\n           return postprocessed_outputs\n\n       def _sanitize_parameters(self, parameters):\n           # Sanitize the parameters here\n           return sanitized_parameters\n   ```\n\n4. Load your pipeline using the `from_pretrained()` function provided by the `transformers` module:\n\n   ```python\n   my_custom_pipeline = MyCustomPipeline.from_pretrained('my_custom_pipeline')\n   ```\n\n5. Use your pipeline object to perform inference on new data:\n\n   ```python\n   results = my_custom_pipeline(input_data)\n   ```\n\nThat's it! Your custom pipeline is now ready to use. Remember to follow the guidelines mentioned in the context to ensure that your pipeline is self-contained, easy-to-use, and easy-to-tweak. Additionally, consider contributing your pipeline to the Hugging Face Hub or the official pipelines if it could be useful to others.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_81":{"__typename":"Paragraph","id":"53e976030fef_81","name":"e285","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The re-ranked context yields a much better response","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_82":{"__typename":"Paragraph","id":"53e976030fef_82","name":"afd1","type":"P","href":null,"layout":null,"metadata":null,"text":"Applying Corrective RAG","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_83":{"__typename":"Paragraph","id":"53e976030fef_83","name":"f05f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain_openai import OpenAI\nfrom google.colab import userdata\nimport os\nos.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n\nllm_openai = OpenAI(temperature=0)\n#\nc_prompt =  PromptTemplate(\n        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n        Here is the retrieved document: \\n\\n {context} \\n\\n\n        Here is the user question: {question} \\n\n        If the document contains keywords related to the user question, grade it as relevant. \\n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n        Provide only the binary score as a text varible with a single key 'score' and no premable or explaination.\"\"\",\n        input_variables=[\"question\", \"context\"],\n    )\n#\n\nscore_prompt = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n        Here is the retrieved document: \\n\\n {context} \\n\\n\n        Here is the user question: {question} \\n\n        If the document contains keywords related to the user question, grade it as relevant. \\n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\"\"\"\n#\n","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_84":{"__typename":"Paragraph","id":"53e976030fef_84","name":"9a0e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain.output_parsers import ResponseSchema, StructuredOutputParser\nfrom langchain.prompts import PromptTemplate\n\nresponse_schemas = [\n    ResponseSchema(name=\"Score\", description=\"score for the context query relevancy\"),\n]\noutput_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n#\nformat_instructions = output_parser.get_format_instructions()\n#\nprint(output_parser)\n#\nprint(format_instructions)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_85":{"__typename":"Paragraph","id":"53e976030fef_85","name":"230b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"response_schemas=[ResponseSchema(name='Score', description='score for the context query relevancy', type='string')]\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n \"Score\": string  \u002F\u002F score for the context query relevancy\n}\n```","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_86":{"__typename":"Paragraph","id":"53e976030fef_86","name":"f1cc","type":"PRE","href":null,"layout":null,"metadata":null,"text":"template=score_prompt+\"\\n{format_instructions}\"\nprint(template)\n#\nscoreprompt = PromptTemplate.from_template(template=template)\nprint(f\"scoreprompt : {scoreprompt}\") ","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_87":{"__typename":"Paragraph","id":"53e976030fef_87","name":"088b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"You are a grader assessing relevance of a retrieved document to a user question. \\n \\n        Here is the retrieved document: \\n\\n {context} \\n\\n\\n        Here is the user question: {question} \\n\\n        If the document contains keywords related to the user question, grade it as relevant. \\n\\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\\n{format_instructions}\n\nscoreprompt: PromptTemplate(input_variables=['context', 'format_instructions', 'question'], template=\"You are a grader assessing relevance of a retrieved document to a user question. \\n \\n        Here is the retrieved document: \\n\\n {context} \\n\\n\\n        Here is the user question: {question} \\n\\n        If the document contains keywords related to the user question, grade it as relevant. \\n\\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\\n{format_instructions}\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_88":{"__typename":"Paragraph","id":"53e976030fef_88","name":"d27f","type":"P","href":null,"layout":null,"metadata":null,"text":"Prepared the final prompt to apply Corrective RAG","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_89":{"__typename":"Paragraph","id":"53e976030fef_89","name":"2d5f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"question = \"How to create a pipeline object?\"\ncontext = reranked_docs[0]\nfinal_prompt = scoreprompt.format_prompt(format_instructions=format_instructions,\n                                   question=question,\n                                    context=context,\n                                    ).text\nprint(final_prompt)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_90":{"__typename":"Paragraph","id":"53e976030fef_90","name":"672d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"You are a grader assessing relevance of a retrieved document to a user question. \n \n        Here is the retrieved document: \n\n !--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp:\u002F\u002Fwww.apache.org\u002Flicenses\u002FLICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n\n⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n--\u003E\n\n# How to create a custom pipeline?\n\nIn this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co\u002Fmodels) or add it to the\n🤗 Transformers library.\n\nFirst and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\ndictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\nas it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\npipeline (`preprocess`).\n\nThen define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n`postprocess` method.\n\nStart by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n`_forward`, `postprocess`, and `_sanitize_parameters`.\n\n\n```python\nfrom transformers import Pipeline \n\n\n        Here is the user question: How to create a pipeline object? \n\n        If the document contains keywords related to the user question, grade it as relevant. \n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n \"Score\": string  \u002F\u002F score for the context query relevancy\n}\n```","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_91":{"__typename":"Paragraph","id":"53e976030fef_91","name":"d70e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"score = llm_openai(final_prompt)\n\n#####Output\n\n\n```json\n{\n \"Score\": \"yes\"\n}\n```","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_92":{"__typename":"Paragraph","id":"53e976030fef_92","name":"58be","type":"P","href":null,"layout":null,"metadata":null,"text":"Assembling relevant context by running the Corrective RAG logic.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_93":{"__typename":"Paragraph","id":"53e976030fef_93","name":"d21c","type":"H3","href":null,"layout":null,"metadata":null,"text":"Corrective RAG","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_94":{"__typename":"Paragraph","id":"53e976030fef_94","name":"aa5b","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s implement self-reflective RAG with some ideas from the CRAG (Corrective RAG) paper:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":66,"end":88,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F2401.15884","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_95":{"__typename":"Paragraph","id":"53e976030fef_95","name":"4725","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Grade documents for relevance relative to the question.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":55,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_96":{"__typename":"Paragraph","id":"53e976030fef_96","name":"daba","type":"OLI","href":null,"layout":null,"metadata":null,"text":"If any are irrelevant, then we will not use the context for generation","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":70,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_97":{"__typename":"Paragraph","id":"53e976030fef_97","name":"b5a2","type":"OLI","href":null,"layout":null,"metadata":null,"text":"We will then pass final retrieved documents to an LLM for final answer generation.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":82,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_98":{"__typename":"Paragraph","id":"53e976030fef_98","name":"3b13","type":"PRE","href":null,"layout":null,"metadata":null,"text":" # Score\nfiltered_docs = []\ngrade_ = []\nmatched_relevant_docs = []\nquestion = \"How to create a pipeline object?\"\n\nsearch = \"No\"  # Default do not opt for web search to supplement retrieval\nfor d in reranked_docs:\n  final_prompt = scoreprompt.format_prompt(format_instructions=format_instructions,\n                                   question=question,\n                                    context=d,\n                                    ).text\n  print(final_prompt)\n  score = llm_openai(final_prompt)\n  print(score)\n  score_dict = eval(score.split(\"```json\\n\")[-1].replace(\"\\n```\",\"\").replace(\"\\t\",\"\").replace(\"\\n\",\"\"))\n  print(score_dict)\n  if score_dict['Score'] == \"yes\":\n    matched_relevant_docs.append(d)\n\n","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_99":{"__typename":"Paragraph","id":"53e976030fef_99","name":"701d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"You are a grader assessing relevance of a retrieved document to a user question. \n \n        Here is the retrieved document: \n\n !--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp:\u002F\u002Fwww.apache.org\u002Flicenses\u002FLICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n\n⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n--\u003E\n\n# How to create a custom pipeline?\n\nIn this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co\u002Fmodels) or add it to the\n🤗 Transformers library.\n\nFirst and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\ndictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\nas it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\npipeline (`preprocess`).\n\nThen define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n`postprocess` method.\n\nStart by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n`_forward`, `postprocess`, and `_sanitize_parameters`.\n\n\n```python\nfrom transformers import Pipeline \n\n\n        Here is the user question: How to create a pipeline object? \n\n        If the document contains keywords related to the user question, grade it as relevant. \n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n \"Score\": string  \u002F\u002F score for the context query relevancy\n}\n```\n\n\n```json\n{\n \"Score\": \"yes\"\n}\n```\n{'Score': 'yes'}\nYou are a grader assessing relevance of a retrieved document to a user question. \n \n        Here is the retrieved document: \n\n ```\n\u003C\u002Ftf\u003E\n\u003C\u002Fframeworkcontent\u003E\n\n## Pipeline\n\n\u003CYoutube id=\"tiZFewofSLM\"\u002F\u003E\n\nThe [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:\n\n\u003CTip\u003E\n\nFor a complete list of available tasks, check out the [pipeline API reference](.\u002Fmain_classes\u002Fpipelines).\n\n\u003C\u002FTip\u003E \n\n\n        Here is the user question: How to create a pipeline object? \n\n        If the document contains keywords related to the user question, grade it as relevant. \n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n \"Score\": string  \u002F\u002F score for the context query relevancy\n}\n```\n\n\n```json\n{\n \"Score\": \"yes\"\n}\n```\n{'Score': 'yes'}\nYou are a grader assessing relevance of a retrieved document to a user question. \n \n        Here is the retrieved document: \n\n - **Self-contained**: A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the [`DiffusionPipeline` class](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Fblob\u002F5cbed8e0d157f65d3ddc2420dfd09f2df630e978\u002Fsrc\u002Fdiffusers\u002Fpipeline_utils.py#L56) or be directly attached to the model and scheduler components of the pipeline.\n- **Easy-to-use**: Pipelines should be extremely easy to use - one should be able to load the pipeline and\nuse it for its designated task, *e.g.* text-to-image generation, in just a couple of lines of code. Most\nlogic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `__call__` method.\n- **Easy-to-tweak**: Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part –from pre-processing to diffusing to post-processing– can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our [community-examples](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Ftree\u002Fmain\u002Fexamples\u002Fcommunity). If you feel that an important pipeline should be part of the official pipelines but isn't, a contribution to the [official pipelines](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Fblob\u002Fmain\u002Fsrc\u002Fdiffusers\u002Fpipelines) would be even better. \n\n\n        Here is the user question: How to create a pipeline object? \n\n        If the document contains keywords related to the user question, grade it as relevant. \n\n        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n\n        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \n\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n \"Score\": string  \u002F\u002F score for the context query relevancy\n}\n```\n\n\n```json\n{\n \"Score\": \"yes\"\n}\n```\n{'Score': 'yes'}","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"plaintext"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_100":{"__typename":"Paragraph","id":"53e976030fef_100","name":"b634","type":"P","href":null,"layout":null,"metadata":null,"text":"Redact an answer based on the documents scored as yes by the llm- basically implementing Corrective RAG.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_101":{"__typename":"Paragraph","id":"53e976030fef_101","name":"5a9f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"retrieved_docs_text = [doc for doc in matched_relevant_docs]  # we only need the text of the documents\ncontext = \"\\nExtracted documents:\\n\"\ncontext += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n\nfinal_prompt = RAG_PROMPT_TEMPLATE.format(question=\"How to create a pipeline object?\", context=context)\n\nprint(final_prompt)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_102":{"__typename":"Paragraph","id":"53e976030fef_102","name":"bdf5","type":"P","href":null,"layout":null,"metadata":null,"text":"Response Log","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_103":{"__typename":"Paragraph","id":"53e976030fef_103","name":"3441","type":"PRE","href":null,"layout":null,"metadata":null,"text":"\u003C|system|\u003E\nUsing the information contained in the context,\ngive a comprehensive answer to the question.\nRespond only to the question asked, response should be concise and relevant to the question.\nProvide the number of the source document when relevant.\nIf the answer cannot be deduced from the context, do not give an answer.\u003C\u002Fs\u003E\n\u003C|user|\u003E\nContext:\n\nExtracted documents:\nDocument 0:::\n!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp:\u002F\u002Fwww.apache.org\u002Flicenses\u002FLICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n\n⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n--\u003E\n\n# How to create a custom pipeline?\n\nIn this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co\u002Fmodels) or add it to the\n🤗 Transformers library.\n\nFirst and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\ndictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\nas it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\npipeline (`preprocess`).\n\nThen define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n`postprocess` method.\n\nStart by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n`_forward`, `postprocess`, and `_sanitize_parameters`.\n\n\n```python\nfrom transformers import PipelineDocument 1:::\n```\n\u003C\u002Ftf\u003E\n\u003C\u002Fframeworkcontent\u003E\n\n## Pipeline\n\n\u003CYoutube id=\"tiZFewofSLM\"\u002F\u003E\n\nThe [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:\n\n\u003CTip\u003E\n\nFor a complete list of available tasks, check out the [pipeline API reference](.\u002Fmain_classes\u002Fpipelines).\n\n\u003C\u002FTip\u003EDocument 2:::\n- **Self-contained**: A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the [`DiffusionPipeline` class](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Fblob\u002F5cbed8e0d157f65d3ddc2420dfd09f2df630e978\u002Fsrc\u002Fdiffusers\u002Fpipeline_utils.py#L56) or be directly attached to the model and scheduler components of the pipeline.\n- **Easy-to-use**: Pipelines should be extremely easy to use - one should be able to load the pipeline and\nuse it for its designated task, *e.g.* text-to-image generation, in just a couple of lines of code. Most\nlogic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `__call__` method.\n- **Easy-to-tweak**: Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part –from pre-processing to diffusing to post-processing– can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our [community-examples](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Ftree\u002Fmain\u002Fexamples\u002Fcommunity). If you feel that an important pipeline should be part of the official pipelines but isn't, a contribution to the [official pipelines](https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Fdiffusers\u002Fblob\u002Fmain\u002Fsrc\u002Fdiffusers\u002Fpipelines) would be even better.\n---\nNow here is the question you need to answer.\n\nQuestion: How to create a pipeline object?\u003C\u002Fs\u003E\n\u003C|assistant|\u003E","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_104":{"__typename":"Paragraph","id":"53e976030fef_104","name":"dea2","type":"P","href":null,"layout":null,"metadata":null,"text":"Response Synthesizer","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_105":{"__typename":"Paragraph","id":"53e976030fef_105","name":"ce16","type":"PRE","href":null,"layout":null,"metadata":null,"text":"answer = llm(final_prompt)\nprint(f\"Response Synthesized by LLM :\\n\\n{answer}\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_106":{"__typename":"Paragraph","id":"53e976030fef_106","name":"33ac","type":"P","href":null,"layout":null,"metadata":null,"text":"Response Log","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_107":{"__typename":"Paragraph","id":"53e976030fef_107","name":"1958","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nResponse Synthesized by LLM :\n\nTo create a pipeline object following the guidelines provided, you can follow these steps:\n\n1. Define the inputs and outputs of your pipeline. These could be strings, dictionaries, or any other Python data type that best represents the input and output formats for your specific task.\n\n2. Inherit the `Pipeline` class from the `transformers` module. This class provides the necessary methods for implementing the pipeline.\n\n3. Implement the four required methods: `preprocess`, `_forward`, `postprocess`, and `_sanitize_parameters`. Here's a brief explanation of what each method does:\n\n   - `preprocess(self, inputs: Dict[str, Any], return_dict: bool = True) -\u003E Dict[str, Any]`: This method takes the input dictionary and returns a dictionary with the preprocessed data. It can also optionally return a dictionary instead of a list of outputs.\n\n   - `_forward(self, inputs: Dict[str, Any]) -\u003E Dict[str, Any]`: This method performs the actual computation using the underlying model and scheduler. It takes the preprocessed input dictionary and returns a dictionary with the computed results.\n\n   - `postprocess(self, outputs: Dict[str, Any], **kwargs) -\u003E Dict[str, Any]`: This method takes the computed outputs and returns the final output dictionary after applying any necessary postprocessing steps.\n\n   - `_sanitize_parameters(self, parameters: Dict[str, Any]) -\u003E Dict[str, Any]`: This method sanitizes the input parameters before passing them to the underlying model and scheduler. It ensures that the parameters are in the correct format and range.\n\n4. Optionally, you can attach additional functionality to the model and scheduler components of the pipeline. This can include custom loss functions, optimizers, and learning rate schedules.\n\n5. Once you have implemented your pipeline, you can load it using the `Pipeline` constructor and use it for inference. Here's an example usage:\n\n   ```python\n   from my_pipeline import MyPipeline\n   \n   # Load the pipeline\n   pipe = MyPipeline()\n   \n   # Use the pipeline for inference\n   result = pipe(\"This is a sample input","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_108":{"__typename":"Paragraph","id":"53e976030fef_108","name":"7860","type":"P","href":null,"layout":null,"metadata":null,"text":"Conclusion:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_109":{"__typename":"Paragraph","id":"53e976030fef_109","name":"12f8","type":"P","href":null,"layout":null,"metadata":null,"text":"Here we have implemented a Corrective RAG approach aby only considering the context to be those documents which are relevant to the query asked. We could have also used external resources to enhance the correctness of the non relevant contexts and pass it on to the LLM to enhance the response.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_110":{"__typename":"Paragraph","id":"53e976030fef_110","name":"216d","type":"P","href":null,"layout":null,"metadata":null,"text":"Referrences:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:53e976030fef_111":{"__typename":"Paragraph","id":"53e976030fef_111","name":"8d8c","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"Corrective Retrieval Augmented Generation\nLarge language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured…arxiv.org","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":170,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F2401.15884","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":42,"end":161,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F2401.15884","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*OyIFAlFSDMKxJweG"}},"Paragraph:53e976030fef_112":{"__typename":"Paragraph","id":"53e976030fef_112","name":"7e98","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"GitHub - bclavie\u002FRAGatouille\nContribute to bclavie\u002FRAGatouille development by creating an account on GitHub.github.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":118,"href":"https:\u002F\u002Fgithub.com\u002Fbclavie\u002FRAGatouille","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":28,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":29,"end":108,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fgithub.com\u002Fbclavie\u002FRAGatouille","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*R1ylI_wPNbMDWW6O"}},"Paragraph:53e976030fef_113":{"__typename":"Paragraph","id":"53e976030fef_113","name":"dac8","type":"P","href":null,"layout":null,"metadata":null,"text":"connect with me","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":15,"href":"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fplaban-nayak-a9433a25\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:d318104265a3-viewerId:ceb44ee85b4a":{"__typename":"CollectionViewerEdge","id":"collectionId:d318104265a3-viewerId:ceb44ee85b4a","isEditor":false,"isMuting":false},"Membership:a2c46bdcaa9a":{"__typename":"Membership","tier":"MEMBER","id":"a2c46bdcaa9a"},"Tag:crag":{"__typename":"Tag","id":"crag","displayTitle":"Crag","normalizedTagSlug":"crag"},"Tag:langchain":{"__typename":"Tag","id":"langchain","displayTitle":"Langchain","normalizedTagSlug":"langchain"},"Tag:zephyr-7b":{"__typename":"Tag","id":"zephyr-7b","displayTitle":"Zephyr 7b","normalizedTagSlug":"zephyr-7b"},"Tag:openai":{"__typename":"Tag","id":"openai","displayTitle":"OpenAI","normalizedTagSlug":"openai"},"Tag:chromadb":{"__typename":"Tag","id":"chromadb","displayTitle":"Chromadb","normalizedTagSlug":"chromadb"},"Post:30d63e222563":{"__typename":"Post","id":"30d63e222563","collection":{"__ref":"Collection:d318104265a3"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"6105","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:53e976030fef_0"},{"__ref":"Paragraph:53e976030fef_1"},{"__ref":"Paragraph:53e976030fef_2"},{"__ref":"Paragraph:53e976030fef_3"},{"__ref":"Paragraph:53e976030fef_4"},{"__ref":"Paragraph:53e976030fef_5"},{"__ref":"Paragraph:53e976030fef_6"},{"__ref":"Paragraph:53e976030fef_7"},{"__ref":"Paragraph:53e976030fef_8"},{"__ref":"Paragraph:53e976030fef_9"},{"__ref":"Paragraph:53e976030fef_10"},{"__ref":"Paragraph:53e976030fef_11"},{"__ref":"Paragraph:53e976030fef_12"},{"__ref":"Paragraph:53e976030fef_13"},{"__ref":"Paragraph:53e976030fef_14"},{"__ref":"Paragraph:53e976030fef_15"},{"__ref":"Paragraph:53e976030fef_16"},{"__ref":"Paragraph:53e976030fef_17"},{"__ref":"Paragraph:53e976030fef_18"},{"__ref":"Paragraph:53e976030fef_19"},{"__ref":"Paragraph:53e976030fef_20"},{"__ref":"Paragraph:53e976030fef_21"},{"__ref":"Paragraph:53e976030fef_22"},{"__ref":"Paragraph:53e976030fef_23"},{"__ref":"Paragraph:53e976030fef_24"},{"__ref":"Paragraph:53e976030fef_25"},{"__ref":"Paragraph:53e976030fef_26"},{"__ref":"Paragraph:53e976030fef_27"},{"__ref":"Paragraph:53e976030fef_28"},{"__ref":"Paragraph:53e976030fef_29"},{"__ref":"Paragraph:53e976030fef_30"},{"__ref":"Paragraph:53e976030fef_31"},{"__ref":"Paragraph:53e976030fef_32"},{"__ref":"Paragraph:53e976030fef_33"},{"__ref":"Paragraph:53e976030fef_34"},{"__ref":"Paragraph:53e976030fef_35"},{"__ref":"Paragraph:53e976030fef_36"},{"__ref":"Paragraph:53e976030fef_37"},{"__ref":"Paragraph:53e976030fef_38"},{"__ref":"Paragraph:53e976030fef_39"},{"__ref":"Paragraph:53e976030fef_40"},{"__ref":"Paragraph:53e976030fef_41"},{"__ref":"Paragraph:53e976030fef_42"},{"__ref":"Paragraph:53e976030fef_43"},{"__ref":"Paragraph:53e976030fef_44"},{"__ref":"Paragraph:53e976030fef_45"},{"__ref":"Paragraph:53e976030fef_46"},{"__ref":"Paragraph:53e976030fef_47"},{"__ref":"Paragraph:53e976030fef_48"},{"__ref":"Paragraph:53e976030fef_49"},{"__ref":"Paragraph:53e976030fef_50"},{"__ref":"Paragraph:53e976030fef_51"},{"__ref":"Paragraph:53e976030fef_52"},{"__ref":"Paragraph:53e976030fef_53"},{"__ref":"Paragraph:53e976030fef_54"},{"__ref":"Paragraph:53e976030fef_55"},{"__ref":"Paragraph:53e976030fef_56"},{"__ref":"Paragraph:53e976030fef_57"},{"__ref":"Paragraph:53e976030fef_58"},{"__ref":"Paragraph:53e976030fef_59"},{"__ref":"Paragraph:53e976030fef_60"},{"__ref":"Paragraph:53e976030fef_61"},{"__ref":"Paragraph:53e976030fef_62"},{"__ref":"Paragraph:53e976030fef_63"},{"__ref":"Paragraph:53e976030fef_64"},{"__ref":"Paragraph:53e976030fef_65"},{"__ref":"Paragraph:53e976030fef_66"},{"__ref":"Paragraph:53e976030fef_67"},{"__ref":"Paragraph:53e976030fef_68"},{"__ref":"Paragraph:53e976030fef_69"},{"__ref":"Paragraph:53e976030fef_70"},{"__ref":"Paragraph:53e976030fef_71"},{"__ref":"Paragraph:53e976030fef_72"},{"__ref":"Paragraph:53e976030fef_73"},{"__ref":"Paragraph:53e976030fef_74"},{"__ref":"Paragraph:53e976030fef_75"},{"__ref":"Paragraph:53e976030fef_76"},{"__ref":"Paragraph:53e976030fef_77"},{"__ref":"Paragraph:53e976030fef_78"},{"__ref":"Paragraph:53e976030fef_79"},{"__ref":"Paragraph:53e976030fef_80"},{"__ref":"Paragraph:53e976030fef_81"},{"__ref":"Paragraph:53e976030fef_82"},{"__ref":"Paragraph:53e976030fef_83"},{"__ref":"Paragraph:53e976030fef_84"},{"__ref":"Paragraph:53e976030fef_85"},{"__ref":"Paragraph:53e976030fef_86"},{"__ref":"Paragraph:53e976030fef_87"},{"__ref":"Paragraph:53e976030fef_88"},{"__ref":"Paragraph:53e976030fef_89"},{"__ref":"Paragraph:53e976030fef_90"},{"__ref":"Paragraph:53e976030fef_91"},{"__ref":"Paragraph:53e976030fef_92"},{"__ref":"Paragraph:53e976030fef_93"},{"__ref":"Paragraph:53e976030fef_94"},{"__ref":"Paragraph:53e976030fef_95"},{"__ref":"Paragraph:53e976030fef_96"},{"__ref":"Paragraph:53e976030fef_97"},{"__ref":"Paragraph:53e976030fef_98"},{"__ref":"Paragraph:53e976030fef_99"},{"__ref":"Paragraph:53e976030fef_100"},{"__ref":"Paragraph:53e976030fef_101"},{"__ref":"Paragraph:53e976030fef_102"},{"__ref":"Paragraph:53e976030fef_103"},{"__ref":"Paragraph:53e976030fef_104"},{"__ref":"Paragraph:53e976030fef_105"},{"__ref":"Paragraph:53e976030fef_106"},{"__ref":"Paragraph:53e976030fef_107"},{"__ref":"Paragraph:53e976030fef_108"},{"__ref":"Paragraph:53e976030fef_109"},{"__ref":"Paragraph:53e976030fef_110"},{"__ref":"Paragraph:53e976030fef_111"},{"__ref":"Paragraph:53e976030fef_112"},{"__ref":"Paragraph:53e976030fef_113"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:83650c0fa832"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fthe-ai-forum\u002Fimplementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563","primaryTopic":null,"topics":[],"isPublished":true,"latestPublishedVersion":"53e976030fef","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":2},"createdAt":1709450792256,"firstPublishedAt":1709469653244,"latestPublishedAt":1709469653244,"clapCount":206,"allowResponses":true,"isLimitedState":false,"title":"Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI","isSeries":false,"sequence":null,"uniqueSlug":"implementing-a-flavor-of-corrective-rag-using-langchain-chromadb-zephyr-7b-beta-and-openai-30d63e222563","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","readingTime":25.712264150943398,"previewContent":{"__typename":"PreviewContent","subtitle":"What happens in Native RAG ?"},"previewImage":{"__ref":"ImageMetadata:1*ZJZu7tHxt3wdrfqdIjr9gA.jpeg"},"isShortform":false,"seoTitle":"","updatedAt":1710144359507,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:crag"},{"__ref":"Tag:langchain"},{"__ref":"Tag:zephyr-7b"},{"__ref":"Tag:openai"},{"__ref":"Tag:chromadb"}],"pendingCollection":null,"statusForCollection":"APPROVED","detectedLanguage":"en","wordCount":6668,"layerCake":6}}</script><script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/manifest.6a9e7a94.js.tải xuống"></script><script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/3057.5e22bbb0.js.tải xuống"></script><script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/main.6c3d1aef.js.tải xuống"></script><script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/instrumentation.5e7f2981.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/reporting.2021fe63.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/6068.e9093f2e.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/4398.db4d4378.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/7883.0e445e04.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/6733.1d85727b.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/4711.043615ac.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/8695.9065ba3d.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/4341.e697d2a1.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/5971.c8339d3b.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/5203.e7a22052.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/7222.a06e9442.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/6487.09cd8beb.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/5459.7b1218fd.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/6804.2cda7ee2.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1711.b70f1a35.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/7652.f5b06845.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/2462.0589a8d7.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/9174.24f568ee.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/1128.cb861fd1.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/4129.ee8ae2c8.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/8580.feeb2549.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/8883.c8b03d13.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/4078.da7800a7.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/9408.3df4db57.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/9150.42fafb2e.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/5005.b5d4a37c.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/6605.6978809c.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/2393.aaa1ee6d.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/2211.706ab0f5.chunk.js.tải xuống"></script>
<script src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/PostPage.MainContent.0377a67c.chunk.js.tải xuống"></script><script>window.main();</script><script defer="" src="./Implementing A Flavor of Corrective RAG using Langchain, Chromadb , Zephyr-7B-Beta and OpenAI _ by Plaban Nayak _ The AI Forum _ Mar, 2024 _ Medium_files/v84a3a4012de94ce1a686ba8c167c359c1696973893317" integrity="sha512-euoFGowhlaLqXsPWQ48qSkBSCFs3DPRyiwVu3FjR96cMPx+Fr+gpWRhIafcHwqwCqWS42RZhIudOvEI+Ckf6MA==" data-cf-beacon="{&quot;rayId&quot;:&quot;86936bb4882c1fa9&quot;,&quot;version&quot;:&quot;2024.3.0&quot;,&quot;token&quot;:&quot;0b5f665943484354a59c39c6833f7078&quot;}" crossorigin="anonymous"></script>
<div id="eJOY__extension_root" class="eJOY__extension_root_class" style="all: unset;"><template shadowrootmode="open">
        <style>
          @import url('https://fonts.googleapis.com/css?family=Open+Sans:300,400,600');
          .wrapperEjoy {
  font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
}

.container {
  position: absolute;
  display: none;
  z-index: 2147483647;
  color: black;
  font-size: 14px;
  /* font-family: 'Open Sans', 'sans-serif', 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif; */
  font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  text-rendering: optimizeLegibility;
  -moz-transition: width 1s ease-in-out;
  -webkit-transition: width 1s ease-in-out;
  -moz-transition: width 1s ease-in-out;
  -o-transition: width 1s ease-in-out;
  transition: width 1s ease-in-out;
  /* transition: width 1s ease-in-out, left 1.5s ease-in-out; */
}

.container button {
  background-color: transparent;
}

.main {
  position: relative;
  /* height: 100%; */
  flex-grow: 1;
}

.main_content {
  background-color: #fff;
  min-height: 100px;
  width: 304px;
  height: 100%;
  display: flex;
  flex-direction: column;
  border-radius: 5px;
  top: 0;
  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);
  border-color: transparent;
  /* overflow: hidden; */
  z-index: 2;
  box-sizing: border-box;
  padding: 0 0 8px 0;
}

.view_main {
  overflow-y: auto;
  overflow-x: hidden;
}

.view_main_old {
  height: calc(100% - 55px);
  display: flex;
  flex-direction: column;
  /* overflow-y: auto; 
  overflow-x: hidden;  */
}

.icon {
  cursor: pointer;
}

.viewLoading {
  background: white;
  box-shadow: 0px 0px 4px #727272;
  width: 30px;
  height: 30px;
  display: flex;
  justify-content: center;
  align-items: center;
  border-radius: 5px;
}

.icon:hover {
  transform: scale(1.1);
}

.triangle {
  position: absolute;
  width: 0;
  height: 0;
  bottom: -21px;
  border-bottom: 25px solid transparent;
  border-left: 35px solid #fff;
  filter: drop-shadow(-1px 7px 4px rgba(0, 0, 0, 0.2));
}

.header_container {
  background-color: rgb(29, 161, 242);
  letter-spacing: -0.2px;
  font-size: 12px;
  text-align: left;
  max-height: 33px;
  line-height: normal;
  border-radius: 5px 5px 0 0;
}

.header_bar {
  background-color: transparent;
  height: 100%;
  display: flex;
  overflow: hidden;
  text-align: center;
  border-radius: 5px 5px 0 0;
}

.header_btn {
  height: 100%;
  width: 33.3%;
  color: rgb(255, 255, 255);
  background-color: transparent;
  cursor: pointer;
  padding: 8px;
}

.header_btn:hover {
  background-color: #196594;
}

.header_btn_new {
  /* height: 100%; */
  /* width: 33.3%; */
  display: flex;
  align-items: center;
  justify-content: center;
  color: rgb(255, 255, 255);
  background-color: transparent;
  cursor: pointer;
  padding: 8px;
}

.header_btn_new .clzzTooltip {
  display: none;
  position: absolute;
  top: -30px;
  white-space: nowrap;
  background: #424141b5;
  padding: 4px 12px;
  border-radius: 5px;
  font-weight: 600;
}

.header_btn_new:hover {
  background-color: #196594;
}

.header_btn_new:hover .clzzTooltipShow {
  display: block;
}

.header_last {
  /* padding-right: 32px; */
}

.header_close_icon_container {
  position: absolute;
  top: 11.4px;
  right: -20px;
  cursor: pointer;
  width: 12px;
  height: 12px;
  border-radius: 50%;
  background-color: #ffffff;
  box-shadow: 1px 1px 10px black;
}

.header_close_icon {
  /* all: unset; */
  padding: 3px;
}

.header_triangle_top {
  position: absolute;
  width: 0;
  height: 0;
  bottom: -21px;
  border-bottom: 25px solid transparent;
  border-left: 35px solid #fff;
  filter: drop-shadow(-1px 7px 4px rgba(0, 0, 0, 0.2));
}

.word_container {
  padding: 8px 7px 8px 16px;
  line-height: 1.17;
}

.word_content {
  min-height: 28px;
  max-height: 116px;
  padding-bottom: 0px;
  display: flex;
  flex-wrap: wrap;
  overflow-wrap: break-word;
  align-items: center;
  /* overflow-x: hidden;
  overflow-y: auto; */
}

.word_content::-webkit-scrollbar {
  width: 4px;
  border-radius: 100px;
}

.word_content::-webkit-scrollbar-track {
  -webkit-box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.3);
  border-radius: 100px;
}

.word_content::-webkit-scrollbar-thumb {
  background-color: #9f9f9f;
  outline: 1px solid #e5e5e5;
  border-radius: 100px;
}

.word_speaker_container {
  cursor: pointer;
  align-self: flex-start;
  /* margin-top: 8px; */
  opacity: 0.7;
  height: 28px;
  display: flex;
  justify-content: center;
  align-items: center;
}

.word_speaker_container:hover {
  opacity: 1;
}

.word_word {
  min-width: 10px;
  max-width: 240px;
  font-size: 24px;
  font-weight: bold;
  letter-spacing: 1.2px;
  text-align: left;
  color: #000000;
  /* margin-left: 5px; */
}

.word_incorect {
  font-size: 12px;
  font-weight: 300;
  letter-spacing: 1.2px;
  text-align: left;
  color: #000000;
  margin-left: 5px;
}

.word_pronun {
  font-style: italic;
  margin-left: 8px;
}

.word_loading_container {
  margin-left: 20px;
  margin-top: 7px;
  overflow: hidden;
}

.word_loading {
  height: 20px;
  width: 20px;
  -webkit-animation: spin 1.5s 0.3s linear infinite;
  -moz-animation: spin 1.5s 0.3s linear infinite;
  animation: spin 1.5s linear 0.3s infinite;
}

@-moz-keyframes spin {
  100% {
    -moz-transform: rotate(360deg);
  }
}

@-webkit-keyframes spin {
  100% {
    -webkit-transform: rotate(360deg);
  }
}

@keyframes spin {
  100% {
    -webkit-transform: rotate(360deg);
    transform: rotate(360deg);
  }
}

.word_pop_symbol_container {
  position: relative;
}

.word_pop_symbol {
  width: 33px;
  height: 15px;
  background-color: #ffcc00;
  margin-left: 8px;
  transform: skewX(-25deg);
  display: flex;
  justify-content: center;
  align-items: center;
  border-radius: 2px;
}

.word_pop_symbol img {
  z-index: 1;
  transform: skewX(25deg);
}

.word_tooltip_container {
  position: fixed;
  margin-top: 14px;
  margin-left: 30px;
  opacity: 0;
  display: none;
  transition: opacity 0.3s ease;
  z-index: 1000000000000;
  background-color: #fff;
  height: 40px;
  width: 120px;
  border-radius: 5px;
  box-shadow: -1px -4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.2);
  font-size: 11px;
  font-weight: normal;
  font-style: normal;
  font-stretch: normal;
  line-height: 1.25;
  letter-spacing: normal;
  text-align: left;
  padding: 5px;
}

.word_tooltip_triangle {
  position: absolute;
  width: 0;
  height: 0;
  top: -14px;
  border-top: 15px solid transparent;
  border-left: 15px solid #fff;
  filter: drop-shadow(-1px -1px 1px rgba(0, 0, 0, 0.2));
}

.word_pop_symbol_container:hover .word_tooltip_container {
  opacity: 1;
  display: block
}

.word_tooltip_container p {
  margin-top: 5px;
}

.content_container {
  padding: 0 7px 0 13px;
  /* margin-bottom: 17px; */
  overflow-y: auto;
  overflow-x: hidden;
  /* max-height: 247px; */
  /* height: 200px; */
  flex-grow: 1;
}

.content_container_new_scroll {
  padding: 0 7px 0 13px;
  /* margin-bottom: 17px; */
  /* overflow-y: auto;
  overflow-x: hidden; */
  /* max-height: 247px; */
  /* height: 200px; */
  flex-grow: 1;
}

.content_container .content_inner {
  position: relative;
  min-height: 150px;
  padding-top: 5px;
  /* overflow-y: auto;
  overflow-x: hidden;
  max-height: 247px;
  height: 200px;
  flex-grow: 1; */
}

.content_inner_list {
  width: 284px;
  box-sizing: border-box;
  padding-left: 11px;
}

.content_container::-webkit-scrollbar,
.selectWbConSelect::-webkit-scrollbar,
.selectWbConSelect .selectWbConSelectMain::-webkit-scrollbar {
  width: 4px;
  border-radius: 100px;
}

.content_container::-webkit-scrollbar-track,
.selectWbConSelect::-webkit-scrollbar-track,
.selectWbConSelect .selectWbConSelectMain::-webkit-scrollbar-track {
  -webkit-box-shadow: inset 0 0 6px rgba(95, 85, 85, 0.3);
  border-radius: 100px;
}

.content_container::-webkit-scrollbar-thumb,
.selectWbConSelect::-webkit-scrollbar-thumb,
.selectWbConSelect .selectWbConSelectMain::-webkit-scrollbar-thumb {
  background-color: #9f9f9f;
  outline: 1px solid #e5e5e5;
  border-radius: 100px;
  text-align: center;
}

.content_pos {
  color: #faa918;
  font-size: 16px;
  font-weight: 600;
  line-height: 1.17;
  letter-spacing: -0.3px;
  text-align: left;
}

.content_more_btn {
  width: 94%;
  height: 24px;
  border-radius: 16px;
  margin-top: 20px;
  background-color: #d8d8d8;
  cursor: pointer;
  text-align: center;
  display: flex;
  justify-content: center;
  align-items: center;
}

.content_more_btn:hover {
  background-color: rgb(148, 148, 148);
}

.tran_container {
  width: 256px;
  min-height: 40px;
  border-radius: 5px;
  background-color: #d8d8d8;
  margin-top: 4px;
  margin-bottom: 4px;
}

.tran_content {
  padding: 11px 8px 12px 8px;
  display: flex;
  flex-direction: column;
}

.tran_content .tran_content_top {
  display: flex;
  margin-bottom: 8px;
  justify-content: space-between;
}

.tran_tran_content {
  display: flex;
}

.tran_tran {
  width: 77%;
  font-weight: 600;
  line-height: 1.14;
  letter-spacing: -0.2px;
  flex-grow: 1;
  flex-wrap: wrap;
  overflow-wrap: break-word;
  text-align: left;
  color: #333333;
}

.tran_btn_add {
  all: initial;
  margin-left: 4px;
  cursor: pointer;
  width: 48px;
  height: 20px;
  float: left;
  background-color: #1da1f2;
  border-radius: 2px;
  display: flex !important;
  color: #fff;
  justify-content: space-around;
  font-family: Open Sans, sans-serif;
  align-items: center;
  font-size: 12px;
  font-weight: 300;
  font-style: normal;
  font-stretch: normal;
  line-height: 1.33;
  letter-spacing: 0.8px;
  /* overflow: hidden; */
  text-overflow: ellipsis;
}

.tran_btn_edit {
  all: initial;
  margin-right: 10px;
  cursor: pointer;
  opacity: 0.7;
}

.tran_btn_add:hover,
.btn_edit:hover {
  transform: scale(1.1)
}

.tran_extra_data {
  width: 100%;
  font-weight: 300;
  font-size: 14px;
  line-height: 1.33;
  letter-spacing: -0.2px;
  flex-wrap: wrap;
  overflow-wrap: break-word;
  text-align: left;
  color: #666666;
  padding-top: 2px;
  white-space: pre-wrap;
}

.tran_footer {
  display: flex;
  width: 100%;
  justify-content: flex-end;
}

.tran_vote_container {
  min-width: 88px;
  height: 16px;
  border-radius: 8px;
  background-color: #d8d8d8;
  border: solid 1px #979797;
  /* margin-left: 59%; */
  margin-bottom: -27px;
  font-size: 8px;
  font-weight: normal;
  font-style: italic;
  font-stretch: normal;
  line-height: normal;
  letter-spacing: normal;
  text-align: justify;
  color: #000000;
  /* padding: 2px 12px 2px 12px; */
  display: flex;
  justify-content: space-around;
  align-items: center;
}

.OOPS_container {
  height: 129px;
  border-radius: 5px;
  background-color: #d8d8d8;
  display: flex;
  justify-content: center;
  flex-direction: column;
  text-align: center;
}

.OOPS_img {
  align-self: center;
}

.OOPS_oops_text {
  font-size: 14px;
  font-weight: bold;
}

.OOPS_alert_text {
  font-size: 12px;
  font-family: 300;
  line-height: 1.33;
  letter-spacing: -0.2px;
}

.btnSayItCon {
  padding: 8px;
}

.btnToAdvTranslation {
  position: absolute;
  right: -32px;
  width: 32px;
  height: 32px;
  top: 33px;
  background: #ffffff;
  border-radius: 0 5px 5px 0px;
  cursor: pointer;
  box-shadow: 3px 2px 4px rgba(0, 0, 0, 0.5);
  padding: 0;
  display: flex;
  justify-content: center;
  align-items: center;
}

.btnSpeak {
  position: absolute;
  right: -32px;
  width: 32px;
  height: 32px;
  top: 66px;
  background: #ffffff;
  border-radius: 0 5px 5px 0px;
  cursor: pointer;
  box-shadow: 3px 2px 4px rgba(0, 0, 0, 0.5);
  padding: 0;
  display: flex;
  justify-content: center;
  align-items: center;
}

.btnGoProIconRight {
  top: 132px;
}

.btnGoSupportRight {
  top: 99px;
}

.btnSayIt {
  display: flex;
  justify-content: center;
  align-items: center;
  height: 18px;
  border-radius: 5px;
  padding: 0 4px;
  background-color: #ff7700;
  cursor: pointer;
}

.btnSayItIcon {
  display: flex;
  padding-right: 4px;
}

.btnSayItIcon svg {
  width: 12px;
  height: 12px;
}

.btnSayItText {
  font-size: 12px;
  font-weight: 600;
  font-style: normal;
  font-stretch: normal;
  line-height: 1.3333333333333333;
  letter-spacing: normal;
  color: #ffffff;
}

.word_pron {
  margin-top: 8px;
  display: flex;
  align-items: center;
}

.custom_container {
  position: relative;
  z-index: 99999999999999999;
}

.custom_add_translation {
  display: flex;
  justify-content: flex-end;
  align-items: center;
}

.custom_input {
  flex-grow: 1;
  padding: 0px 21px 0px 0px;
}

.custom_input input {
  width: 100%;
  min-height: 35px;
  border-radius: 5px;
  background-color: #d8d8d8;
  border: none;
  font-weight: 600;
  line-height: 1.14;
  letter-spacing: -0.2px;
  flex-grow: 1;
  flex-wrap: wrap;
  overflow-wrap: break-word;
  text-align: left;
  color: #000000;
  font-size: 14px;
  padding: 0 8px;
}

.custom_content {
  flex-grow: 1;
}

.icon_plus {
  cursor: pointer;
  display: flex;
}

.icon_plus svg {
  width: 16px;
  height: 16px;
}

.hidden {
  display: none;
}

.tooltip_custom_add {
  position: absolute;
  /* display: none; */
}

/* tool tip */

[tooltip] {
  position: relative;
  display: inline-block;
}

[tooltip]::before {
  content: "";
  position: absolute;
  top: -7px;
  left: 50%;
  transform: translateX(-50%);
  border-width: 5px 6px 0 6px;
  border-style: solid;
  border-color: #808080 transparent transparent transparent;
  /* border-color: rgba(0,0,0,0.7) transparent transparent transparent; */
  z-index: 99;
  opacity: 0;
}

[tooltip-position='left']::before {
  left: 0%;
  top: 50%;
  margin-left: -12px;
  transform: translatey(-50%) rotate(-90deg)
}

[tooltip-position='top-left']::before {
  left: 90%;
}

[tooltip-position='top-right']::before {
  left: 14%;
}

[tooltip-position='top']::before {
  left: 50%;
}

[tooltip-position='buttom']::before {
  top: 100%;
  margin-top: 8px;
  transform: translateX(-50%) translatey(-100%) rotate(-180deg)
}

[tooltip-position='right']::before {
  left: 100%;
  top: 50%;
  margin-left: 1px;
  transform: translatey(-50%) rotate(90deg)
}

[tooltip]::after {
  content: attr(tooltip);
  position: absolute;
  left: 50%;
  top: -6px;
  transform: translateX(-50%) translateY(-100%);
  /* background: rgba(0,0,0,0.7); */
  background: #808080;
  text-align: center;
  color: #fff;
  padding: 4px 2px;
  font-size: 10px;
  min-width: 180px;
  border-radius: 5px;
  pointer-events: none;
  padding: 4px 4px;
  z-index: 99;
  opacity: 0;
  white-space: pre-wrap;
}

[tooltip-position='left']::after {
  left: 0%;
  top: 50%;
  margin-left: -8px;
  transform: translateX(-100%) translateY(-50%);
}

[tooltip-position='top']::after {
  left: 50%;
}

[tooltip-position='top-left']::after {
  left: -90%;
}

[tooltip-position='top-right']::after {
  left: 90%;
}

[tooltip-position='buttom']::after {
  top: 100%;
  margin-top: 8px;
  transform: translateX(-50%) translateY(0%);
}

[tooltip-position='right']::after {
  left: 100%;
  top: 50%;
  margin-left: 8px;
  transform: translateX(0%) translateY(-50%);
}

[tooltip]:hover::after,
[tooltip]:hover::before {
  opacity: 1
}

.selectWbCon {
  /* filter: drop-shadow(-1px 7px 4px rgba(0, 0, 0, 0.2));
  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19); */
  display: flex;
  justify-content: flex-end;
  position: relative;
  align-items: center;
  padding: 8px 8px 0 8px;
  font-size: 12px;
  color: #666666;
}

.selectWbConLeft {
  font-style: normal;
  font-weight: normal;
  font-size: 12px;
  line-height: 16px;
  display: flex;
  cursor: pointer;
  color: #666666;
  align-items: center;
  padding-right: 4px;
}

.selectWbConRight {
  font-style: normal;
  font-weight: 600;
  font-size: 12px;
  line-height: 16px;
  display: flex;
  cursor: pointer;
  color: #666666;
  align-items: center;
  padding-right: 3px;
  white-space: nowrap;
}

.selectWbIcon {
  display: flex;
  cursor: pointer;
}

.selectWbConSelect {
  position: absolute;
  bottom: 31px;
  visibility: hidden;
  background: white;
  /* height: 300px; */
  z-index: 999;
  min-width: 200px;
  max-width: 300px;
  max-height: 300px;
  overflow: auto;
  filter: drop-shadow(-1px 7px 4px rgba(0, 0, 0, 0.2));
  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);
  border-radius: 5px;
}

.selectWbConSelect.isShow {
  visibility: visible;
}

.selectWbConSelect.hidden {
  visibility: hidden;
}

.itemOptionSelectWb {
  cursor: pointer;
  padding: 6px 8px;
  font-style: normal;
  font-weight: normal;
  font-size: 12px;
  line-height: 16px;
  display: flex;
  color: #666666;
  align-items: center;
}

.itemOptionSelectWb.active {
  color: #1da1f2
}

.itemOptionSelectWb:hover {
  background: #1da1f2;
  color: white;
}

.selectWb {
  border: none;
  font-size: 14px;
  font-weight: 400;
  color: #666666;
  background: transparent;
}

/* start icon level */

.viewIconFilter {
  display: flex;
  justify-content: center;
  align-items: center;
}

.iconFilter {
  width: 24px;
  height: 23px;
  background: #1DA1F2;
  -webkit-mask-size: cover;
  mask-size: cover;
  display: flex;
  justify-content: center;
  align-items: center;
  margin-right: 8px;
}

.iconFilter span {
  font-size: 12px;
  line-height: 1.2;
  align-items: center;
  font-weight: bold;
  color: #FFFFFF;
}

.nameFilter {
  font-style: normal;
  font-weight: 600;
  font-size: 14px;
  line-height: 16px;
  display: flex;
  align-items: center;
  color: #333333;
}

/* end icon level */

/* start popup go to pro */

.iconItemGoPro svg {
  width: 38px;
  transition: all 0.5s;
}

.iconItemGoPro path {
  fill: #B2B2B2;
  transition: all 0.5s;
}

.iconItemGoProActive svg {
  width: 56px;
}

.iconItemGoProActive path {
  fill: #1DA1F2;
}

/* end popup go to pro */

.switch {
  position: relative;
  display: inline-block;
  cursor: pointer;
  width: 30px;
  height: 17px;
}

.slider {
  position: absolute;
  cursor: pointer;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: #ccc;
  -webkit-transition: background-color 0.4s, transform 0.4s;
  -moz-transition: background-color 0.4s, transform 0.4s;
  -ms-transition: background-color 0.4s, transform 0.4s;
  -o-transition: background-color 0.4s, transform 0.4s;
  transition: background-color 0.4s, transform 0.4s;
}

.slider:before {
  position: absolute;
  content: "";
  height: 13px;
  width: 13px;
  left: calc(13px / 6.5);
  bottom: calc(13px / 6.5);
  background-color: #ffffff;
  -webkit-transition: background-color 0.4s, transform 0.4s;
  -moz-transition: background-color 0.4s, transform 0.4s;
  -ms-transition: background-color 0.4s, transform 0.4s;
  -o-transition: background-color 0.4s, transform 0.4s;
  transition: background-color 0.4s, transform 0.4s;
}

.round {
  border-radius: 30px;
}

.round:before {
  border-radius: 50%;
}

.active .slider {
  background-color: #1da1f2;
}

.active .slider:before {
  -webkit-transform: translateX(13px);
  -ms-transform: translateX(13px);
  transform: translateX(13px);
}

.view_main::-webkit-scrollbar,
.selectWbConSelect::-webkit-scrollbar,
.selectWbConSelect .selectWbConSelectMain::-webkit-scrollbar {
  width: 4px;
  border-radius: 100px;
}

.view_main::-webkit-scrollbar-track,
.selectWbConSelect::-webkit-scrollbar-track,
.selectWbConSelect .selectWbConSelectMain::-webkit-scrollbar-track {
  -webkit-box-shadow: inset 0 0 6px rgba(95, 85, 85, 0.3);
  border-radius: 100px;
}

.view_main::-webkit-scrollbar-thumb,
.selectWbConSelect::-webkit-scrollbar-thumb,
.selectWbConSelect .selectWbConSelectMain::-webkit-scrollbar-thumb {
  background-color: #9f9f9f;
  /* outline: 1px solid #e5e5e5; */
  border-radius: 100px;
  text-align: center;
}

.scale-animation {
  height: 20px;
  width: 20px;
  -webkit-animation: scale-infi 1.5s 0.3s linear infinite;
  -moz-animation: scale-infi 1.5s 0.3s linear infinite;
  animation: scale-infi 1.5s linear 0.3s infinite;
}

@-moz-keyframes scale-infi {
  0% {
    -webkit-transform: scale(1);
    transform: rotate(1);
  }

  50% {
    -webkit-transform: scale(1.5);
    transform: rotate(1.5);
  }
}

@-webkit-keyframes scale-infi {
  0% {
    -webkit-transform: scale(1);
    transform: rotate(1);
  }

  50% {
    -webkit-transform: scale(1.5);
    transform: rotate(1.5);
  }
}

@keyframes scale-infi {
  0% {
    -webkit-transform: scale(1);
    transform: rotate(1);
  }

  50% {
    -webkit-transform: scale(1.5);
    transform: rotate(1.5);
  }
}

.notify_onboarding_container {
  position: absolute;
  width: 272px;
  min-height: 65px;
  flex-direction: column;
  left: 16px;
  padding-bottom: 8px;
  display: flex;
  align-items: center;
  bottom: 45px;
  text-align: center;
  background: #FFFFFF;
  box-shadow: 0px 2px 10px rgba(0, 0, 0, 0.2);
  border-radius: 5px;
  border: 1px solid #1DA1F2;
}

.notify_onboarding_close {
  display: flex;
  cursor: pointer;
  align-self: self-end;
  justify-content: flex-end;
}

.notify_onboarding_close>svg {
  padding: 10px 10px 0 0;
}

.notify_onboarding_title {
  font-style: normal;
  font-weight: normal;
  font-size: 12px;
  padding: 0 16px;
  line-height: 16px;
  color: #333333;
}

.notify_onboarding_btn {
  display: flex;
  justify-content: center;
  font-style: normal;
  font-weight: normal;
  font-size: 12px;
  display: flex;
  align-items: center;
  padding: 6px 24px;
  line-height: 14px;
  cursor: pointer;
  background: #1DA1F2;
  color: white;
  border-radius: 72.6px;
  margin-top: 10px;
  margin-bottom: 10px;
}

.notify_onboarding_btn>span {
  padding-left: 8px;
}

.notify_onboarding_arrow {
  position: absolute;
  bottom: -21px;
  left: 0px;
}

[class*="icono"] {
  position: relative;
  display: inline-block;
  vertical-align: middle;
  color: #C4C4C4;
  box-sizing: border-box;
}

[class*="icono-white"] {
  color: white;
}

[class*="icono"]:after,
[class*="icono"]:before {
  content: "";
  box-sizing: border-box;
}

[class*="icono-arrow4"] {
  width: 0;
  height: 0;
  border: 7px solid transparent;
  border-top: 7px solid;
  border-right: 7px solid;
  margin: 15px;
}

[class*="icono-arrow4"][class*="-left"] {
  transform: rotate(45deg);
}

[class*="icono-arrow4"][class*="-left"][class*="-up"] {
  transform: none;
}

[class*="icono-arrow4"][class*="-left"][class*="-down"] {
  transform: rotate(90deg);
}

[class*="icono-arrow4"][class*="-right"] {
  transform: rotate(-135deg);
}

[class*="icono-arrow4"][class*="-right"][class*="-up"] {
  transform: rotate(-90deg);
}

[class*="icono-arrow4"][class*="-right"][class*="-down"] {
  transform: rotate(180deg);
}

[class*="icono-arrow4"][class*="-up"] {
  transform: rotate(-45deg);
}

[class*="icono-arrow4"][class*="-down"] {
  transform: rotate(135deg);
}


.searchMeaningGg_container {
  /* background: #D8D8D8; */
  border-radius: 4px;
  padding: 8px 0px;
  display: flex;
  justify-content: center;
  align-items: center;
  flex-direction: column;
}

.searchMeaningGg_text {
  font-style: normal;
  font-weight: 400;
  font-size: 14px;
  line-height: 16px;
  cursor: pointer;
  /* display: flex;
  align-items: center; */
  /* text-align: center; */
}

.searchMeaningGg_text span {
  color: #1DA1F2;
}

.searchMeaningGg_btn {
  /* background: #1DA1F2; */
  border-radius: 100px;
  padding: 8px 36px;
  margin-top: 16px;
  font-style: normal;
  font-size: 14px;
  line-height: 16px;
  text-align: center;
  color: #1DA1F2;
  cursor: pointer;
}



.view_similar {
  display: flex;
  flex-wrap: wrap;
}

.view_similar .imilar_text {
  font-style: normal;
  font-weight: 400;
  font-size: 10px;
  line-height: 16px;
  display: flex;
  padding-right: 10px;
  align-items: center;
  text-align: center;
  color: #397447;
}

.view_similar .imilar_item {
  background-color: #fff;
  border: 1px solid #dadce0;
  line-height: 16px;
  font-size: 9px;
  margin: 3px 0px;
  padding: 0 10px;
  margin-right: 4px;
  border-radius: 32px;
  float: left;
  max-width: 250px;
  cursor: pointer;
  position: relative;
  overflow: hidden;
  text-align: center;
  text-overflow: ellipsis;
  white-space: nowrap;
  color: #3c4043;
}

.view_similar .imilar_item.imilar_item_disable {
  cursor: text;
  color: #bdc1c6 !important;
  cursor: default;
  background-color: #f1f3f4;
  border: 1px solid #f8f9fa;
}

.google_Dictionary_title {
  background: #E6E7EB;
  font-style: normal;
  font-weight: 500;
  font-size: 12px;
  line-height: 16px;
  display: flex;
  align-items: center;
  letter-spacing: 0.05em;
  text-transform: uppercase;
  color: #3B3C40;
  padding: 4px 9px;
}

.google_Dictionary_desc {
  font-style: normal;
  font-weight: 400;
  font-size: 10px;
  line-height: 16px;
  cursor: pointer;
  display: flex;
  align-items: center;
  text-align: center;
  color: #626262;
  padding-top: 8px;
  padding-bottom: 4px;
}

.google_Dictionary_pharse {
  font-style: normal;
  font-weight: 400;
  font-size: 12px;
  line-height: 16px;
  display: flex;
  align-items: center;
  text-align: center;
  color: #8C8C8C;
  padding-bottom: 4px;
  padding-left: 26px;
}

.google_Dictionary_content_pos {
  text-align: left;
  font-style: italic;
  font-weight: 400;
  font-size: 12px;
  line-height: 20px;
  color: #8C8C8C;
}

.google_Dictionary_pharse_link {
  font-style: normal;
  font-weight: 400;
  font-size: 12px;
  line-height: 16px;
  cursor: pointer;
  display: flex;
  align-items: center;
  text-align: center;
  color: #0F59C5;
  padding-left: 4px;
}

.dataGetMeaningEmpty {
  background: #D8D8D8;
  border-radius: 4px;
  font-style: normal;
  font-weight: 400;
  font-size: 12px;
  line-height: 16px;
  color: #3B3C40;
  width: '100%';
  min-width: 124px;
  min-height: 124px;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  text-align: center;
}

.dataGetMeaningEmpty span {
  padding: 16px 11px 0px;
}

.item_lookup_container {
  min-height: 34px;
  display: flex;
  flex-direction: row;
  padding: 8px 12px;
  align-items: center;
  cursor: pointer;
}

.item_lookup_logo {
  height: 34px;
  width: 34px;
  display: flex;
  justify-content: center;
  align-items: center;
  background-color: #11A37F;
}

.item_lookup_logo_small {
  height: 16px;
  width: 16px;
  border-radius: 3px;
  font-weight: 600;
}

.item_lookup_logo_bg_none {
  background-color: transparent;
}

.item_lookup_logo img {
  height: 34px;
  width: 34px;
}

.item_lookup_logo_small svg {
  height: 10px;
  width: 10px;
}

.item_lookup_logo svg path {
  fill: white
}


.item_lookup_text {
  font-style: normal;
  font-weight: 400;
  font-size: 14px;
  line-height: 20px;
  display: flex;
  align-items: center;
  color: #666666;
  flex: 1;
  padding-left: 12px;
}

.item_lookup_text_small {
  font-size: 12px;
  line-height: 16px;
  font-weight: 600;
}

.item_lookup_more {
  cursor: pointer;
  /* height: 34px;
  width: 34px;
  display: flex;
  justify-content: center;
  align-items: center;
  background-color: #11A37F; */
}

.viewIcon {
  display: flex;
  justify-content: center;
  position: relative;
  align-items: center;
  background: white;
  border: 1px solid #1DA1F2;
  border-radius: 3px
}

.viewIcon img {
  background: #1DA1F2;
  border-radius: 1px 0px 0px 1px;
}

.itemDropDown {
  color: #333;
  font-size: 14px;
  line-height: 16px;
  padding: 0 8px;
  position: relative;
}

.btnAddImg {
  position: relative;
  height: 100%;
  justify-content: center;
  align-items: center;
  display: flex;
}

.btnAddImg>img,
.itemArrowDropDownImg {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  cursor: pointer;
  opacity: 0;
  background: transparent;
}

.itemDropDownWithLine {
  border-right: 1px solid #B2B2B2;
}

.itemArrowDropDown {
  padding: 0 6px;
  cursor: pointer;
  height: 100%;
  display: flex;
  position: relative;
  justify-content: center;
  align-items: center;
}

.viewContentItemDrop {
  width: 162px;
  position: absolute;
  right: 0;
  flex-shrink: 0;
  display: flex;
  flex-direction: column;
  background: #FFF;
  padding-bottom: 6px;
  border-radius: 4px;
  box-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.20);
  /* box-shadow: 0px 3px 12px 0px rgba(0, 0, 0, 0.20); */
}

.viewContentItemDropTop {
  top: 105%;
}

.viewContentItemDropBottom {
  bottom: 105%;
}

.itemArrowDropDown:hover div[datatype="viewItemHover"] {
  /* display: flex; */
}

.viewItemHoverTitle {
  color: #333;
  font-size: 14px;
  font-style: normal;
  font-weight: 600;
  padding: 12px 12px 6px 12px;
  line-height: 16px;
}

.viewItemDrop {
  height: 32px;
  display: flex;
  padding: 0 12px;
  padding-right: 0;
  align-items: center;
  cursor: pointer;
  background: #fff
}

.viewItemDrop>span {
  flex-grow: 1;
  font-size: 14px;
  padding: 0 12px;
  line-height: 16px;
}

.viewItemDrop:hover {
  background: #F0F0F0
}

.viewIconPin {
  display: flex;
  padding: 10px;
  justify-content: center;
  align-items: center;
  cursor: pointer;
}

.viewIconPinDisable{
  opacity: 0.5;
  cursor: not-allowed !important;
}

.viewIconPinDisable img{
  cursor: not-allowed !important;
}

.itemArrowDropDown>svg,
.viewItemDrop>svg,
.viewItemDrop>span,
.viewIconPin svg {
  pointer-events: none;
}

.viewIconPin:hover svg path {
  fill: rgb(29, 161, 242)
}

#PopupSyncNotifyContent {
  position: absolute;
  font-family: "Open Sans", Arial, sans-serif !important;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  margin: auto;
  background: #0000005c;
  display: flex;
  z-index: 2147483647;
  flex-direction: column;
  justify-content: space-around;
  align-items: center;
  /* background: #FFFFFF;
  border-radius: 10px;
  align-items: center;
  display: flex;
  flex-direction: column;
  justify-content: center;
  padding: 16px 33px 27px 33px; */
}

.PopupSyncNotifyContent-main {
  background: #FFFFFF;
  border-radius: 10px;
  align-items: center;
  display: flex;
  width: 600px;
  height: 500px;
  position: relative;
  flex-direction: column;
  justify-content: space-evenly;
  padding: 32px 33px 27px 33px;
}


.PopupSyncNotifyContent-viewTitle {
  color: #333;
  font-family: Open Sans;
  font-size: 24px;
  font-style: normal;
  font-weight: 600;
  line-height: 32px;
}

.PopupSyncNotifyContent-viewDesc {
  margin-top: 16px;
  font-style: normal;
  font-weight: normal;
  font-size: 16px;
  line-height: 24px;
  display: flex;
  align-items: center;
  text-align: center;
  padding-bottom: 32px;
  color: #333333;
}

.PopupSyncNotifyContent-main-close{
  position: absolute;
  top: -30px;
  right: 0;
  cursor: pointer;
}
.PopupSyncNotifyContent-viewViewBtn {
  
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
}

.PopupSyncNotifyContent-viewViewBtn1 {
  display: flex;
  flex-direction: column;
  justify-content: center;
  cursor: pointer;
  align-items: center;
  background: #1DA1F2;
  border-radius: 72.6px;
  padding: 10px 46px;
  min-width: 189px;
  font-style: normal;
  font-weight: 400;
  font-size: 16px;
  line-height: 20px;
  display: flex;
  align-items: center;
  text-align: center;
  color: #FFFFFF;
}
.PopupSyncNotifyContent-viewViewBtn1 img {
  width: 22px;
}

.PopupSyncNotifyContent-viewViewBtn2 {
  margin-top: 16px;
  display: flex;
  cursor: pointer;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  background: #7AC70C;
  border-radius: 72.6px;
  padding: 10px 46px;
  min-width: 189px;
  font-style: normal;
  font-weight: 400;
  font-size: 16px;
  line-height: 20px;
  display: flex;
  align-items: center;
  text-align: center;
  color: #fff;
}

.PopupSyncNotifyContent-viewViewBtn3 {
  margin-top: 16px;
  display: flex;
  cursor: pointer;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  background: #E6E6E6;
  border-radius: 72.6px;
  padding: 10px 46px;
  min-width: 189px;
  font-style: normal;
  font-weight: 400;
  font-size: 16px;
  line-height: 20px;
  display: flex;
  align-items: center;
  text-align: center;
  color: #1DA1F2;
}

.PopupSyncNotifyContent-viewItems {
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
}


.ejoyViewNotifyAddWord {
  border-radius: 8px;
  position: fixed;
  left: 50%;
  transform: translate(-50%, 0);
  bottom: 16px;
  z-index: 9999;
  background: #FFF;
  box-shadow: 0px 2px 10px 0px rgba(0, 0, 0, 0.20);
  display: flex;
  padding: 8px 16px 8px 16px !important;
  align-items: center;
  gap: 54px;
}

.ejoyViewNotifyAddWord span {
  color: var(--standard-standard-high-day, #2C2C2C);
  font-size: 16px;
  font-style: normal;
  font-weight: 600;
  line-height: 20px;
}

.ejoyViewNotifyAddWord button {
  display: flex;
  flex-direction: column;
  justify-content: center;
  cursor: pointer;
  align-items: center;
  padding: 10px 12px;
  gap: 8px;
  color: var(--Primary-Azuare, #1DA1F2);
  text-align: right;
  font-size: 16px;
  font-style: normal;
  font-weight: 400;
  border: none;
  background: transparent;
  line-height: 20px;
}

.ejoyStatusEndGeneralSub {
  align-items: center;
  background: #fff;
  border-radius: 8px;
  bottom: 20px;
  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);
  color: #333;
  display: flex;
  font-size: 16px;
  font-style: normal;
  font-weight: 400;
  justify-content: center;
  line-height: 20px;
  padding: 16px;
  position: fixed;
  left: 50%;
  transform: translate(-50%,0);
  text-align: center;
  z-index: 999999;
}

.ejoyStatusEndGeneralSub svg {
  margin-right: 6px
}

.ejoyBtnCloseShowGeneral{
  cursor: pointer;
  display: flex;
  padding-left: 32px;
}


.selectWbConPopup {
  /* filter: drop-shadow(-1px 7px 4px rgba(0, 0, 0, 0.2));
  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19); */
  display: flex;
  align-items: center;
  padding: 8px 8px 0 8px;
  font-size: 12px;
  color: #666666;
  position: fixed;
  inset: 0;
  justify-content: center;
  background: #00000082;
  z-index: 999999;
}

.selectWbConSelectPopup {
  visibility: hidden;
  background: white;
  z-index: 999;
  min-width: 255px;
  max-width: 300px;
  height: 330px;
  display: flex;
  flex-direction: column;
  filter: drop-shadow(-1px 7px 4px rgba(0, 0, 0, 0.2));
  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);
  border-radius: 5px;
}

.selectWbConSelectMainPopup {
  overflow: auto;
  overflow-x: hidden;
  flex: 1;
}

.selectWbConSelectPopup.isShow {
  visibility: visible;
}

.selectWbConSelectPopup.hidden {
  visibility: hidden;
}

.itemOptionSelectWbPopup {
  cursor: pointer;
  padding: 6px 8px;
  font-style: normal;
  font-weight: normal;
  font-size: 12px;
  line-height: 16px;
  display: flex;
  color: #666666;
  align-items: center;
}

.itemOptionSelectWbPopup.active {
  color: #1da1f2
}

.itemOptionSelectWbPopup:hover {
  text-decoration: underline;
}
          #popup_eJOY {
  all: initial;
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  margin: auto;
  background-color: rgba(0, 0, 0, 0.8);
  z-index: 99999999999999999999999999999999;
  outline: none;
  display: flex;
  justify-content: center;
  align-items: center;
}

.view_desc {
  display: flex;
  min-width: 279px;
  align-items: center;
  justify-content: flex-start;
}

.popup_main_go_pro {
  /* position: absolute;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0; */
  position: relative;
  margin: auto;
  /* height: 201px; */
  width: 623px;
  border-radius: 10px;
  background-color: #fff;
  display: flex;
  max-width: 100%;
  flex-direction: column;
  justify-content: flex-start;
  align-items: center;
  font-size: 16px;
  font-weight: 400;
  font-style: normal;
  font-stretch: normal;
  line-height: 1.5;
  letter-spacing: -0.4px;
  text-align: center;
  color: #000000;
  animation: alertPop 0.2s ease-out;
  background: white;
  font-family: "Open Sans", Arial, sans-serif;
}

.popup_main {
  position: absolute;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  margin: auto;
  height: 201px;
  width: 415px;
  max-width: 100%;
  border-radius: 5px;
  background-color: #fff;
  display: flex;
  flex-direction: column;
  justify-content: flex-start;
  align-items: center;
  font-size: 16px;
  font-weight: 400;
  font-style: normal;
  font-stretch: normal;
  line-height: 1.5;
  letter-spacing: -0.4px;
  text-align: center;
  color: #000000;
  animation: alertPop 0.2s ease-out
}

.popup_main_login {
  position: absolute;
  font-family: "Open Sans", Arial, sans-serif !important;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  margin: auto;
  height: 342px;
  width: 392px;
  max-width: 100%;
  border-radius: 5px;
  background-color: #fff;
  display: flex;
  flex-direction: column;
  justify-content: space-around;
  align-items: center;
  font-size: 16px;
  font-weight: 400;
  font-style: normal;
  font-stretch: normal;
  line-height: 1.5;
  letter-spacing: -0.4px;
  text-align: center;
  color: #000000;
  animation: alertPop 0.2s ease-out
}

.popup_main_login span, .popup_main_login button {
  font-family: "Open Sans", Arial, sans-serif !important;
}

@keyframes alertPop {
  0% {
    transform: scale(0)
  }
  100% {
    transform: scale(1)
  }
}

#popup_eJOY header {
  font-size: 24px;
  font-weight: 600;
  margin-top: 10px;
}

#popup_eJOY p {
  width: 342px;
}

.popup_line {
  width: 414px;
  height: 1px;
  background-color: #d8d8d8;
  margin-top: 6px;
}

.popup_close_btn {
  position: absolute;
  top: 18px;
  right: 29px;
  width: 12px;
  height: 12px;
  border-radius: 50%;
  background-color: #b4b4b4;
  display: flex;
  justify-content: center;
  align-items: center;
  cursor: pointer;
}

.btn_login{
  background-color: rgb(29, 161, 242);
}
#popup_eJOY .titleTxt {
  font-style: normal;
  font-weight: 600;
  font-size: 32px;
  max-width: 100%;
  line-height: 40px;
  text-align: center;
  color: #333333;
  padding-top: 16px;
}

#popup_eJOY .descTxt {
  font-style: normal;
  font-weight: normal;
  font-size: 18px;
  line-height: 28px;
  text-align: center;
  color: #333333;
  padding-top: 16px;
  max-width: 100%;
  width: 403px;
}

#popup_eJOY .descTxt span:first-child {
  color: rgb(29, 161, 242);
  text-decoration: none;
  cursor: pointer;
}

#popup_eJOY .viewIcon {
  width: 100%;
  display: flex;
  justify-content: center;
  align-items: center;
  padding: 16px 0 40px 0;
}

#popup_eJOY .viewItem {
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  margin: 0 20px;
  cursor: pointer;
}

#popup_eJOY .itemICon {
  background: linear-gradient(360deg, #71C5F6 -3.99%, #61CCDF 95.66%);
  border-radius: 18px;
  width: 80px;
  height: 80px;
  display: flex;
  justify-content: center;
  align-items: center;
  margin-bottom: 8px;
}

#popup_eJOY .itemText {
  font-style: normal;
  font-weight: 300;
  font-size: 12px;
  line-height: 15px;
  text-align: center;
  letter-spacing: -0.0738461px;
  color: #000000;
  width: 90px;
}

#popup_eJOY button {
  border-radius: 16px;
  color: #fff;
  padding: 6px 16px;
  background-color: #FF7700;
  display: flex;
  justify-content: center;
  align-items: center;
  cursor: pointer;
  outline: none;
  font-weight: 600;
  font-size: 16px;
  margin-top: 24px;
  border: none;
}

.popup_main_login button {
  padding: 6px 49px !important;
}

.popup_main_login .popup_close_btn {
  top: 8px !important;
  right: 9px !important;
}

@media only screen and (max-width: 400px) {
  #popup_eJOY .popup_main_go_pro {
    border-radius: 0;
  }
  #popup_eJOY .titleTxt {
    font-size: 18px;
    line-height: 24px;
    padding-top: 16px;
  }
  #popup_eJOY .descTxt {
    font-size: 14px;
    line-height: 16px;
    padding-top: 10px;
  }
  #popup_eJOY .viewIcon {
    padding: 16px 0 13px 0;
  }
}

.popup_main_onboarding {
  position: absolute;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  margin: auto;
  height: 520px;
  width: 773px;
  max-width: 100%;
  border-radius: 10px;
  background-color: #fff;
  display: flex;
  flex-direction: column;
  justify-content: flex-start;
  align-items: center;
  font-size: 16px;
  font-weight: 400;
  font-style: normal;
  font-stretch: normal;
  line-height: 1.5;
  letter-spacing: -0.4px;
  text-align: center;
  color: #000000;
  animation: alertPop 0.2s ease-out
}

.popup_main_onboarding_no_ani{
  animation:none;
}

.onboarding_popup_close {
  position: absolute;
  top: -25px;
  right: 10px;
  width: 12px;
  height: 12px;
  border-radius: 50%;
  /* background-color: #b4b4b4; */
  display: flex;
  justify-content: center;
  align-items: center;
  cursor: pointer;
}

.onboarding_btn {
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
}

.onboarding_content {
  width: 100%;
  height: 100%;
  justify-content: space-around;
  align-items: center;
  display: flex;
  flex-direction: column;
  padding: 10px 0 50px 0;
}

.onboarding_text {
  font-style: normal;
  font-weight: 600;
  font-size: 18px;
  line-height: 24px;
  font-family: sans-serif;
  display: flex;
  align-items: center;
  text-align: center;
  color: #333333;
  padding: 0 40px;
}

.onboarding_btn>button {
  margin: 16px 0 !important;
  line-height: 20px !important;
  padding: 10px 20px !important;
  border-radius: 72.6px !important;
  min-width: 264px !important;
  font-weight: 400 !important;
}

.onboarding_btn_no_remind {
  height: 40px !important;
  min-width: 264px !important;
  border: 1px solid #B3B3B3 !important;
  border-radius: 72.6px !important;
  font-style: normal !important;
  margin: 16px 0 !important;
  font-weight: 600 !important;
  font-size: 16px !important;
  line-height: 20px !important;
  padding: 10px 40px !important;
  display: flex !important;
  align-items: center !important;
  text-align: center !important;
  color: #B3B3B3 !important;
  background: transparent !important;
}

.onboarding_content_remind {
  width: 100%;
  height: 100%;
  font-family: sans-serif;
  /* justify-content: space-around; */
  align-items: center;
  display: flex;
  flex-direction: column;
  /* padding: 10px 0 50px 0; */
}

.onboarding_remind_main {
  display: flex;
  justify-content: space-around;
  width: 100%;
  margin-top: 40px;
}

.onboarding_btn_back {
  display: flex;
  align-items: center;
  font-style: normal;
  font-weight: normal;
  font-size: 16px;
  align-self: flex-start;
  line-height: 20px;
  padding-top: 16px;
  padding-left: 16px;
  /* identical to box height, or 125% */
  display: flex;
  align-items: center;
  cursor: pointer;
  text-align: center;
  /* 6.“ON”color/Lower emphasis */
  color: #B3B3B3;
}

.onboarding_remind_main_right_view_time {
  text-align: left;
  display: flex;
  padding: 8px 0;
  font-family: "Open Sans", Arial, sans-serif;
  font-family: sans-serif;
}

.onboarding_remind_main_right_view_time>span {
  font-style: normal;
  font-weight: normal;
  padding-right: 8px;
  font-size: 14px;
  min-width: 94px;
  line-height: 16px;
  display: flex;
  align-items: center;
  color: #8C8C8C;
}

.onboarding_remind_main_right_view_time_main {
  display: flex;
}

.onboarding_remind_main_right_view_time_main_item {
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  cursor: pointer;
}

.onboarding_remind_main_right_view_time_input_time {
  padding: 2px 8px !important;
  border: 1px solid #B3B3B3 !important;
  border-radius: 3px !important;
  box-sizing: border-box !important;
}

.onboarding_remind_main_right_view_time_main_item span:first-child {
  margin: 0 2px 2px 2px;
  background: #FFFFFF;
  border: 1px solid #B3B3B3;
  box-sizing: border-box;
  min-width: 31px;
  border-radius: 3px;
  font-style: normal;
  font-weight: normal;
  font-size: 10px;
  line-height: 16px;
  display: flex;
  justify-content: center;
  align-items: center;
  text-align: center;
  color: #333333;
}

.onboarding_remind_main_right_view_time_main_item .span_check {
  border: 1px solid #B2B2B2;
  width: 10px;
  height: 10px;
  border-radius: 100px;
}

.popup_main_onboarding .onboarding_btn button {
  margin-top: 0 !important;
}

.onboarding_success_icon {
  border-radius: 90.3704px;
  border: 15px solid #7AC70C;
  width: 92px;
  height: 92px;
  display: flex;
  justify-content: center;
  align-items: center;
}

.onboarding_success_text {
  font-style: normal;
  font-weight: normal;
  font-size: 16px;
  font-family: "Open Sans", Arial, sans-serif;
  line-height: 20px;
  display: flex;
  align-items: center;
  text-align: center;
  color: #333333;
}

.popup_main_success_onboarding{
  width: 398px;
  height: 245px;
}

.onboarding_success_content{
  padding: 16px;
}
        </style>
        <div id="eJOY__extension_shadow"><div class="wrapperEjoy"><div class="container" style="display: none;"><div class="viewIcon"><img src="chrome-extension://amfojhdiedpdnlijjbhjnhokbnohfdfb/img/logo/icon@2x.png" width="24" alt="" height="24" class="icon"><div class="itemArrowDropDown"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" fill="none"><path d="M1 4L6 9L11 4H1Z" fill="#8C8C8C"></path></svg><img class="itemArrowDropDownImg"></div></div></div><span style="position: absolute; top: 1px; left: 1px; opacity: 0; pointer-events: none; background-color: rgb(229, 56, 56); border: 1px solid rgb(229, 56, 56); border-radius: 16px; display: flex; justify-content: center; color: rgb(255, 255, 255); z-index: 2147483647; font-size: 8px; min-width: 12px; min-height: 12px; line-height: 11px; align-items: center;">1</span><span style="position: absolute; top: 1px; opacity: 0; pointer-events: none; background-color: rgba(2, 2, 2, 0.9); border-radius: 4px; padding: 4px 10px; display: flex; min-width: 100px; justify-content: center; color: rgb(255, 255, 255); z-index: 2147483647; font-size: 12px; min-height: 12px; line-height: 16px; align-items: center;"></span></div></div></template></div></body><div id="eJOY__extension_ai_adv_root" class="eJOY__extension_ai_adv_root_class"><div class="wrapperAiAssEjoy"><div class="containerSumEjoyIcon "><div class="viewIconEjoy gl-tooltip-ejoy gl-tooltip-ejoy-left" tooltip-data="eJOY AI Assistant"><div class="viewIconEjoyItem"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="26" viewBox="0 0 24 26" fill="none"><mask id="mask0_427_34" maskUnits="userSpaceOnUse" x="16" y="3" width="8" height="8" style="mask-type: luminance;"><path d="M24 3H16V11H24V3Z" fill="white"></path></mask><g mask="url(#mask0_427_34)"><path d="M23.8012 7.00309L21.0136 8.01539L20.0012 10.8031L18.9889 8.01539L16.2012 7.00309L18.9889 5.9908L20.0012 3.20309L21.0136 5.9908L23.8012 7.00309Z" fill="url(#paint0_linear_427_34)"></path></g><mask id="mask1_427_34" maskUnits="userSpaceOnUse" x="0" y="10" width="6" height="6" style="mask-type: luminance;"><path d="M6 10H0V16H6V10Z" fill="white"></path></mask><g mask="url(#mask1_427_34)"><path d="M5.8494 13.0023L3.7587 13.7616L2.9994 15.8523L2.2402 13.7616L0.149399 13.0023L2.2402 12.2431L2.9994 10.1523L3.7587 12.2431L5.8494 13.0023Z" fill="url(#paint1_linear_427_34)"></path></g><mask id="mask2_427_34" maskUnits="userSpaceOnUse" x="16" y="20" width="4" height="4" style="mask-type: luminance;"><path d="M20 20H16V24H20V20Z" fill="white"></path></mask><g mask="url(#mask2_427_34)"><path d="M19.8996 22.0016L18.5058 22.5077L17.9996 23.9016L17.4934 22.5077L16.0996 22.0016L17.4934 21.4954L17.9996 20.1016L18.5058 21.4954L19.8996 22.0016Z" fill="url(#paint2_linear_427_34)"></path></g><g filter="url(#filter0_d_427_34)"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.8671 20.3327C14.8098 20.2537 16.4674 18.0538 16.368 15.5257C15.9553 11.8147 11.5502 10.6201 13.3135 5.666C9.7712 8.7188 7.228 12.6272 7.3363 15.408C7.3847 18.1053 8.9455 20.3327 11.8671 20.3327ZM14.5512 16.5696C15.0045 16.5696 15.3306 16.2001 15.3719 15.7489C15.4799 15.431 15.3719 13.9738 14.2947 13.0395C14.4695 14.2529 13.6329 15.261 13.7305 15.7489C13.7305 16.2022 14.0979 16.5696 14.5512 16.5696Z" fill="#1DA1F2"></path></g><defs><filter id="filter0_d_427_34" x="2.47583" y="0.80886" width="18.7535" height="24.381" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feflood flood-opacity="0" result="BackgroundImageFix"></feflood><fecolormatrix in="SourceAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0" result="hardAlpha"></fecolormatrix><feoffset></feoffset><fegaussianblur stdDeviation="2.42857"></fegaussianblur><fecolormatrix type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.12 0"></fecolormatrix><feblend mode="normal" in2="BackgroundImageFix" result="effect1_dropShadow_427_34"></feblend><feblend mode="normal" in="SourceGraphic" in2="effect1_dropShadow_427_34" result="shape"></feblend></filter><lineargradient id="paint0_linear_427_34" x1="20.0012" y1="3.20309" x2="20.0012" y2="10.8031" gradientUnits="userSpaceOnUse"><stop stop-color="#1DA1F2"></stop><stop offset="1" stop-color="#6CD2FF"></stop></lineargradient><lineargradient id="paint1_linear_427_34" x1="2.9994" y1="10.1523" x2="2.9994" y2="15.8523" gradientUnits="userSpaceOnUse"><stop stop-color="#1DA1F2"></stop><stop offset="1" stop-color="#6CD2FF"></stop></lineargradient><lineargradient id="paint2_linear_427_34" x1="17.9996" y1="20.1016" x2="17.9996" y2="23.9016" gradientUnits="userSpaceOnUse"><stop stop-color="#1DA1F2"></stop><stop offset="1" stop-color="#6CD2FF"></stop></lineargradient></defs></svg></div><div class="moveIconEjoyAi"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M5.45139 0.667969C4.64931 0.667969 4 1.31727 4 2.11936C4 2.92144 4.64931 3.57075 5.45139 3.57075C6.25347 3.57075 6.90278 2.92144 6.90278 2.11936C6.90278 1.31727 6.25347 0.667969 5.45139 0.667969ZM4 8.00868C4 7.2066 4.64931 6.55729 5.45139 6.55729C6.25347 6.55729 6.90278 7.2066 6.90278 8.00868C6.90278 8.81076 6.25347 9.46007 5.45139 9.46007C4.64931 9.46007 4 8.81076 4 8.00868ZM4 13.8837C4 13.0816 4.64931 12.4323 5.45139 12.4323C6.25347 12.4323 6.90278 13.0816 6.90278 13.8837C6.90278 14.6858 6.25347 15.3351 5.45139 15.3351C4.64931 15.3351 4 14.6858 4 13.8837Z" fill="#666666"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.7854 0.667969C9.98329 0.667969 9.33398 1.31727 9.33398 2.11936C9.33398 2.92144 9.98329 3.57075 10.7854 3.57075C11.5875 3.57075 12.2368 2.92144 12.2368 2.11936C12.2368 1.31727 11.5875 0.667969 10.7854 0.667969ZM9.33398 8.00868C9.33398 7.2066 9.98329 6.55729 10.7854 6.55729C11.5875 6.55729 12.2368 7.2066 12.2368 8.00868C12.2368 8.81076 11.5875 9.46007 10.7854 9.46007C9.98329 9.46007 9.33398 8.81076 9.33398 8.00868ZM9.33398 13.8837C9.33398 13.0816 9.98329 12.4323 10.7854 12.4323C11.5875 12.4323 12.2368 13.0816 12.2368 13.8837C12.2368 14.6858 11.5875 15.3351 10.7854 15.3351C9.98329 15.3351 9.33398 14.6858 9.33398 13.8837Z" fill="#666666"></path></svg></div></div><div class="viewCloseIconEjoy"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" fill="none"><circle cx="6" cy="6" r="6" fill="black" fill-opacity="0.25"></circle><path fill-rule="evenodd" clip-rule="evenodd" d="M8.71289 3.58672C8.87135 3.74518 8.87135 4.00209 8.71289 4.16054L6.72363 6.14981L8.71289 8.13907C8.87135 8.29752 8.87135 8.55444 8.71289 8.71289C8.55444 8.87135 8.29752 8.87135 8.13907 8.71289L6.14981 6.72363L4.16054 8.71289C4.00209 8.87135 3.74518 8.87135 3.58672 8.71289C3.42826 8.55443 3.42826 8.29752 3.58672 8.13907L5.57598 6.14981L3.58672 4.16054C3.42826 4.00209 3.42826 3.74518 3.58672 3.58672C3.74518 3.42826 4.00209 3.42826 4.16054 3.58672L6.14981 5.57598L8.13907 3.58672C8.29752 3.42826 8.55444 3.42826 8.71289 3.58672Z" fill="white"></path></svg></div></div><div class="eJOY__container "><div class="btnReportClose"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.0291 2.63758C14.3812 2.98971 14.3812 3.56062 14.0291 3.91275L9.6085 8.33333L14.0291 12.7539C14.3812 13.106 14.3812 13.677 14.0291 14.0291C13.677 14.3812 13.106 14.3812 12.7539 14.0291L8.33333 9.6085L3.91275 14.0291C3.56062 14.3812 2.98971 14.3812 2.63758 14.0291C2.28546 13.677 2.28546 13.106 2.63758 12.7539L7.05817 8.33333L2.63758 3.91275C2.28546 3.56062 2.28546 2.98971 2.63758 2.63758C2.98971 2.28546 3.56062 2.28546 3.91275 2.63758L8.33333 7.05817L12.7539 2.63758C13.106 2.28546 13.677 2.28546 14.0291 2.63758Z" fill="#B3B3B3"></path></svg></div></div></div></div></html>